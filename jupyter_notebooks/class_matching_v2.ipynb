{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rdflib import Graph, RDF, RDFS, OWL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g= Graph()\n",
        "ontology_file = '../Ontologies/materialsmine.ttl'\n",
        "g.parse(ontology_file, format='ttl')\n",
        "\n",
        "classes = set(g.subjects(RDF.type, RDFS.Class)).union(g.subjects(RDF.type, OWL.Class))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for cls in classes:\n",
        "    print (cls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for cls in classes:\n",
        "    # Query for labels\n",
        "    labels = list(g.objects(cls, RDFS.label))\n",
        "    if labels:\n",
        "        for label in labels:\n",
        "            print(f\"Class: {cls}, Label: {label}\")\n",
        "    else:\n",
        "        print(f\"Class: {cls}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rdflib import Graph, RDF, RDFS, OWL\n",
        "\n",
        "def load_and_print_classes(file_path, file_format=\"ttl\"):\n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, RDFS.Class)).union(g.subjects(RDF.type, OWL.Class))\n",
        "\n",
        "    # Print class URIs and labels if available\n",
        "    print(f\"\\nClasses in {file_path}:\")\n",
        "    for cls in classes:\n",
        "        # Query for labels\n",
        "        labels = list(g.objects(cls, RDFS.label))\n",
        "        if labels:\n",
        "            for label in labels:\n",
        "                print(f\"Class: {cls}, Label: {label}\")\n",
        "        else:\n",
        "            print(f\"Class: {cls}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    # \"../Ontologies/bfo.owl\",\n",
        "    # \"../Ontologies/emmo.ttl\",\n",
        "    # '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from rdflib import Graph, RDF, RDFS, OWL\n",
        "\n",
        "def load_and_collect_classes(file_path, file_format=\"ttl\"):\n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, RDFS.Class)).union(g.subjects(RDF.type, OWL.Class))\n",
        "\n",
        "    # Collect class URIs and labels if available\n",
        "    data = []\n",
        "    for cls in classes:\n",
        "        labels = list(g.objects(cls, RDFS.label))\n",
        "        if labels:\n",
        "            for label in labels:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "        else:\n",
        "            data.append([file_path, str(cls), \"\"])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data from all files\n",
        "all_data = []\n",
        "for ontology_file in ontology_files:\n",
        "    all_data.extend(load_and_collect_classes(ontology_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from rdflib import Graph, RDF, RDFS, OWL\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, RDFS.Class)).union(g.subjects(RDF.type, OWL.Class))\n",
        "\n",
        "    # Collect class URIs and labels if available\n",
        "    data = []\n",
        "    for cls in classes:\n",
        "        labels = list(g.objects(cls, RDFS.label))\n",
        "        if labels:\n",
        "            for label in labels:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "        else:\n",
        "            data.append([file_path, str(cls), \"\"])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    # \"../Ontologies/bfo.owl\",\n",
        "    # \"../Ontologies/emmo.ttl\",\n",
        "    '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data from all files\n",
        "all_data = []\n",
        "for ontology_file in ontology_files:\n",
        "    all_data.extend(load_and_collect_classes(ontology_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class URIs and labels if available\n",
        "    data = []\n",
        "    for cls in classes:\n",
        "        # Query for rdfs:label, skos:altLabel, and skos:prefLabel\n",
        "        # labels = list(g.objects(cls, RDFS.label)) + list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel))\n",
        "        labels = list(g.objects(cls, RDFS.label)) + list(g.objects(cls, SKOS.prefLabel))\n",
        "        if labels:\n",
        "            for label in labels:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "        else:\n",
        "            data.append([file_path, str(cls), \"\"])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    \"../Ontologies/bfo.owl\",\n",
        "    # \"../Ontologies/emmo.ttl\",\n",
        "    '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data from all files\n",
        "all_data = []\n",
        "for ontology_file in ontology_files:\n",
        "    all_data.extend(load_and_collect_classes(ontology_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class URIs and labels if available\n",
        "    data = []\n",
        "    for cls in classes:\n",
        "        # Query for rdfs:label, skos:altLabel, and skos:prefLabel\n",
        "        labels = list(g.objects(cls, RDFS.label)) + list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel))\n",
        "        if labels:\n",
        "            for label in labels:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "                print(f\"Class URI: {cls}, Label: {label}\")\n",
        "        else:\n",
        "            data.append([file_path, str(cls), \"\"])\n",
        "            print(f\"Class URI: {cls}\")\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data from all files\n",
        "all_data = []\n",
        "for ontology_file in ontology_files:\n",
        "    all_data.extend(load_and_collect_classes(ontology_file))\n",
        "\n",
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels and subclass relationships if available\n",
        "    data = []\n",
        "    found_class_labels = set()\n",
        "    subclass_relationships = {}\n",
        "    \n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(normalized_label)\n",
        "\n",
        "        # Query for subclasses using rdfs:subClassOf\n",
        "        subclasses = list(g.objects(cls, RDFS.subClassOf))\n",
        "        if subclasses:\n",
        "            subclass_relationships[str(cls)] = [str(sub) for sub in subclasses]\n",
        "\n",
        "    return data, found_class_labels, subclass_relationships"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data, found class labels, and subclass relationships from all files\n",
        "all_data = []\n",
        "all_found_class_labels = set()\n",
        "all_subclass_relationships = {}\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, found_class_labels, subclass_relationships = load_and_collect_classes(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "    all_subclass_relationships.update(subclass_relationships)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels if available\n",
        "    data = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(normalized_label)\n",
        "\n",
        "    return data, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data and found class labels from all files\n",
        "all_data = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, found_class_labels = load_and_collect_classes(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "\n",
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    \"../Ontologies/bfo.owl\",\n",
        "    \"../Ontologies/emmo.ttl\",\n",
        "    # '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data and found class labels from all files\n",
        "all_data = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, found_class_labels = load_and_collect_classes(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "\n",
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('ontology_classes.csv')\n",
        "print(df.head())\n",
        "\n",
        "# Get the number of rows and columns\n",
        "num_rows, num_cols = df.shape\n",
        "\n",
        "print(f\"Number of rows: {num_rows}\")\n",
        "print(f\"Number of columns: {num_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class URIs and labels if available\n",
        "    data = []\n",
        "    found_class_names = set()\n",
        "    for cls in classes:\n",
        "        # Query for rdfs:label, skos:altLabel, and skos:prefLabel\n",
        "        labels = list(g.objects(cls, RDFS.label)) + list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel))\n",
        "        if labels:\n",
        "            for label in labels:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "                found_class_names.add(label)\n",
        "        else:\n",
        "            data.append([file_path, str(cls), \"\"])\n",
        "\n",
        "    return data, found_class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    \"../Ontologies/bfo.owl\",\n",
        "    \"../Ontologies/emmo.ttl\",\n",
        "    \"../Ontologies/owlapi.xrdf\",\n",
        "    # '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data and found class names from all files\n",
        "all_data = []\n",
        "all_found_class_names = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, found_class_names = load_and_collect_classes(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_found_class_names.update(found_class_names)\n",
        "\n",
        "\n",
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class names to check\n",
        "class_names_to_check = ['Software Agent', 'SoftwareAgent', 'AmperePerJoule', 'characteristic','Bundle', '1DGeometry', 'force' , 'Agent Influence' \n",
        "                        , 'thing', 'meter', 'Accreditation-Document', \n",
        "                        'CoulombPerSquareMilliMetre', 'AcademicDiscipline', 'nfdi', 'CompressioN', 'Poissons Ratio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if class names are in found_class_names and print corresponding input files\n",
        "print(\"\\nClass names found in the output:\")\n",
        "for class_name in class_names_to_check:\n",
        "    if class_name in all_found_class_names:\n",
        "        print(f\"Class '{class_name}' found in:\")\n",
        "        for ontology_file in ontology_files:\n",
        "            file_data, found_class_names = load_and_collect_classes(ontology_file)\n",
        "            if class_name in found_class_names:\n",
        "                print(f\"- {ontology_file}\")\n",
        "    else:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels if available\n",
        "    data = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(label)\n",
        "\n",
        "    return data, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data and found class labels from all files\n",
        "all_data = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, found_class_labels = load_and_collect_classes(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "\n",
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class names to check\n",
        "class_names_to_check = ['Software Agent', 'SoftwareAgent', 'AmperePerJoule', 'characteristic','Bundle', '1DGeometry', 'force' , 'Agent Influence' \n",
        "                        , 'thing', 'meter', 'Accreditation-Document', \n",
        "                        'CoulombPerSquareMilliMetre', 'AcademicDiscipline', 'nfdi', 'CompressioN', 'Poissons Ratio' , 'PoissonsRatio' , 'Poissons_Ratio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if class names are in found_class_labels and print corresponding input files\n",
        "print(\"\\nClass names found in the output:\")\n",
        "for class_name in class_names_to_check:\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if class_name.lower() in label.lower():\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, found_class_labels = load_and_collect_classes(ontology_file)\n",
        "                if label in found_class_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels if available\n",
        "    data = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(normalized_label)\n",
        "\n",
        "    return data, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data and found class labels from all files\n",
        "all_data = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, found_class_labels = load_and_collect_classes(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "\n",
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if class names are in found_class_labels and print corresponding input files\n",
        "print(\"\\nClass names found in the output:\")\n",
        "for class_name in class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, found_class_labels = load_and_collect_classes(ontology_file)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels and relations\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(normalized_label)\n",
        "\n",
        "        # Query for relations such as subClassOf and equivalentClass\n",
        "        for obj in g.objects(cls, RDFS.subClassOf):\n",
        "            relations.append([file_path, str(cls), 'subClassOf', str(obj)])\n",
        "        for obj in g.objects(cls, OWL.equivalentClass):\n",
        "            relations.append([file_path, str(cls), 'equivalentClass', str(obj)])\n",
        "\n",
        "    return data, relations, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data, relations, and found class labels from all files\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_relations.extend(file_relations)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "\n",
        "# Write class data to CSV\n",
        "class_output_file = \"ontology_classes.csv\"\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class names to check\n",
        "class_names_to_check = ['Software Agent', 'SoftwareAgent', 'AmperePerJoule', 'characteristic','Bundle', '1DGeometry', 'force' , 'Agent Influence' \n",
        "                        , 'thing', 'meter', 'Accreditation-Document', \n",
        "                        'CoulombPerSquareMilliMetre', 'AcademicDiscipline', 'nfdi', 'CompressioN', 'Poissons Ratio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write class relations to CSV\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Relation\", \"Object Class URI\"])\n",
        "    writer.writerows(all_relations)\n",
        "\n",
        "print(f\"Class data has been saved to {class_output_file}\")\n",
        "print(f\"Class relations have been saved to {relations_output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if class names are in found_class_labels and print corresponding input files\n",
        "print(\"\\nClass names found in the output:\")\n",
        "for class_name in class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Normalize the class names to check for comparison\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels and relations\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(normalized_label)\n",
        "            # Check if the class is in the list of classes to check\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                # Query for relations such as subClassOf and equivalentClass\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    relations.append([file_path, str(cls), 'subClassOf', str(obj)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    relations.append([file_path, str(cls), 'equivalentClass', str(obj)])\n",
        "\n",
        "    return data, relations, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data, relations, and found class labels from all files\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "    all_data.extend(file_data)\n",
        "    all_relations.extend(file_relations)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "\n",
        "# Write class data to CSV\n",
        "class_output_file = \"ontology_classes.csv\"\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write class relations to CSV\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Relation\", \"Object Class URI\"])\n",
        "    writer.writerows(all_relations)\n",
        "\n",
        "print(f\"Class data has been saved to {class_output_file}\")\n",
        "print(f\"Class relations have been saved to {relations_output_file}\")\n",
        "\n",
        "# Check if class names are in found_class_labels and print corresponding input files\n",
        "print(\"\\nClass names found in the output:\")\n",
        "for class_name in class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def get_class_label(g, cls):\n",
        "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "    return labels[0] if labels else None\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Normalize the class names to check for comparison\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels and relations\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(normalized_label)\n",
        "            # Check if the class is in the list of classes to check\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                # Query for relations such as subClassOf and equivalentClass\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label)])\n",
        "\n",
        "    return data, relations, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    \"../Ontologies/bfo.owl\",\n",
        "    \"../Ontologies/emmo.ttl\",\n",
        "    \"../Ontologies/owlapi.xrdf\",\n",
        "    # '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class names to check\n",
        "class_names_to_check = ['Software Agent', 'SoftwareAgent', 'AmperePerJoule', 'characteristic','Bundle', '1DGeometry', 'force' , 'Agent Influence' \n",
        "                        , 'thing', 'meter', 'Accreditation-Document', \n",
        "                        'CoulombPerSquareMilliMetre', 'AcademicDiscipline', 'nfdi', 'CompressioN', 'Poissons Ratio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data, relations, and found class labels from all files\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "    all_data.extend(file_data)\n",
        "    all_relations.extend(file_relations)\n",
        "    all_found_class_labels.update(found_class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class data has been saved to ontology_classes.csv\n",
            "Class relations have been saved to ontology_relations.csv\n"
          ]
        }
      ],
      "source": [
        "# Write class data to CSV\n",
        "class_output_file = \"ontology_classes.csv\"\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "# Write class relations to CSV\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Subject Label\", \"Relation\", \"Object Class URI\", \"Object Label\"])\n",
        "    writer.writerows(all_relations)\n",
        "\n",
        "print(f\"Class data has been saved to {class_output_file}\")\n",
        "print(f\"Class relations have been saved to {relations_output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class names found in the output:\n",
            "Class 'Software Agent' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'SoftwareAgent' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'AmperePerJoule' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'characteristic' found in:\n",
            "Class 'Bundle' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class '1DGeometry' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "Class 'force' found in:\n",
            "- ../Ontologies/pmdco_core.ttl\n",
            "- ../Ontologies/emmo.ttl\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'Agent Influence' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'thing' not found in the output.\n",
            "Class 'meter' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'Accreditation-Document' found in:\n",
            "- ../Ontologies/pmdco_core.ttl\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'CoulombPerSquareMilliMetre' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'AcademicDiscipline' found in:\n",
            "- ../Ontologies/nfdicore_2.ttl\n",
            "Class 'nfdi' not found in the output.\n",
            "Class 'CompressioN' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "Class 'Poissons Ratio' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "- ../Ontologies/emmo.ttl\n"
          ]
        }
      ],
      "source": [
        "# Check if class names are in found_class_labels and print corresponding input files\n",
        "print(\"\\nClass names found in the output:\")\n",
        "for class_name in class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class relationships for the specified classes:\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: http://www.w3.org/ns/prov#SoftwareAgent (SoftwareAgent), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Agent (Agent)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: http://www.w3.org/ns/prov#SoftwareAgent (SoftwareAgent), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Agent (Agent)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (Ampere per Joule), Relation: subClassOf, Object: n59bd354802d04d19baa027abec663fbbb17 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (Ampere per Joule), Relation: subClassOf, Object: n59bd354802d04d19baa027abec663fbbb18 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (Ampere per Joule), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_1273eb34_de48_43a9_925f_104110469dd2 (SICoherentDerivedUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (Ampere per Joule), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_1aaaceb6_c5eb_4cf3_a494_f82d43fda10a (ElectricCurrentPerUnitEnergyUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (AmperePerJoule), Relation: subClassOf, Object: n59bd354802d04d19baa027abec663fbbb17 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (AmperePerJoule), Relation: subClassOf, Object: n59bd354802d04d19baa027abec663fbbb18 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (AmperePerJoule), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_1273eb34_de48_43a9_925f_104110469dd2 (SICoherentDerivedUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (AmperePerJoule), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_1aaaceb6_c5eb_4cf3_a494_f82d43fda10a (ElectricCurrentPerUnitEnergyUnit)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: http://www.w3.org/ns/prov#Bundle (Bundle), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Entity (Entity)\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/1DGeometry (1D Geometry), Relation: subClassOf, Object: http://materialsmine.org/ns/Geometry (Geometry)\n",
            "File: ../Ontologies/pmdco_core.ttl, Subject: https://w3id.org/pmd/co/Force (Force), Relation: subClassOf, Object: https://w3id.org/pmd/co/ValueObject (Value Object)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_1f087811_06cb_42d5_90fb_25d0e7e068ef (Force), Relation: subClassOf, Object: n59bd354802d04d19baa027abec663fbbb2380 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_1f087811_06cb_42d5_90fb_25d0e7e068ef (Force), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_194100e1_e11a_4b7c_bb5a_171655679fc8 (Extensive)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_1f087811_06cb_42d5_90fb_25d0e7e068ef (Force), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 (ISQDerivedQuantity)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: https://w3id.org/pmd/co/Force (Force), Relation: subClassOf, Object: https://w3id.org/pmd/co/ValueObject (Value Object)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: http://www.w3.org/ns/prov#AgentInfluence (AgentInfluence), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Influence (Influence)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#Metre (Meter), Relation: subClassOf, Object: n59bd354802d04d19baa027abec663fbbb2002 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#Metre (Meter), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_b3600e73_3e05_479d_9714_c041c3acf5cc (LengthUnit)\n",
            "File: ../Ontologies/pmdco_core.ttl, Subject: https://w3id.org/pmd/co/AccreditationDocument (Accreditation Document), Relation: subClassOf, Object: https://w3id.org/pmd/co/Document (Document)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: https://w3id.org/pmd/co/AccreditationDocument (Accreditation Document), Relation: subClassOf, Object: https://w3id.org/pmd/co/Document (Document)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (Coulomb Per Square Millimetre), Relation: subClassOf, Object: n59bd354802d04d19baa027abec663fbbb75 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (Coulomb Per Square Millimetre), Relation: subClassOf, Object: n59bd354802d04d19baa027abec663fbbb76 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (Coulomb Per Square Millimetre), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_60b78cc3_6011_4134_95ab_956f56d4bdc1 (SINonCoherentDerivedUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (Coulomb Per Square Millimetre), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_6d753e0c_a967_4de4_ad22_c2fecb3913be (ElectricDisplacementFieldUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (CoulombPerSquareMilliMetre), Relation: subClassOf, Object: n59bd354802d04d19baa027abec663fbbb75 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (CoulombPerSquareMilliMetre), Relation: subClassOf, Object: n59bd354802d04d19baa027abec663fbbb76 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (CoulombPerSquareMilliMetre), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_60b78cc3_6011_4134_95ab_956f56d4bdc1 (SINonCoherentDerivedUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (CoulombPerSquareMilliMetre), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_6d753e0c_a967_4de4_ad22_c2fecb3913be (ElectricDisplacementFieldUnit)\n",
            "File: ../Ontologies/nfdicore_2.ttl, Subject: https://nfdi.fiz-karlsruhe.de/ontology/AcademicDiscipline (academic discipline), Relation: subClassOf, Object: http://purl.obolibrary.org/obo/BFO_0000019 (None)\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/Compression (Compression), Relation: subClassOf, Object: http://materialsmine.org/ns/ViscoelasticProperty (Viscoelastic Property)\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/PoissonsRatio (Poissons Ratio), Relation: subClassOf, Object: http://materialsmine.org/ns/TensileProperty (Tensile Property)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_8fdabd25_01e0_4296_b82a_09d1c34e52d4 (PoissonsRatio), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_be76ad52_2e29_4202_be6f_0a15eb9c1817 (MechanicalQuantity)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_8fdabd25_01e0_4296_b82a_09d1c34e52d4 (PoissonsRatio), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_faab3f84_e475_4a46_af9c_7d249f0b9aef (RatioQuantity)\n"
          ]
        }
      ],
      "source": [
        "# Print class relationships for the specified classes\n",
        "print(\"\\nClass relationships for the specified classes:\")\n",
        "for class_name in class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    for relation in all_relations:\n",
        "        subject_label_normalized = normalize_string(relation[2])\n",
        "        if normalized_class_name == subject_label_normalized:\n",
        "            print(f\"File: {relation[0]}, Subject: {relation[1]} ({relation[2]}), Relation: {relation[3]}, Object: {relation[4]} ({relation[5]})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "01 - DataCollection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('3.8.13')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
