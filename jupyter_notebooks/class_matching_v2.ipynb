{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rdflib import Graph, RDF, RDFS, OWL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g= Graph()\n",
        "ontology_file = '../Ontologies/materialsmine.ttl'\n",
        "g.parse(ontology_file, format='ttl')\n",
        "\n",
        "classes = set(g.subjects(RDF.type, RDFS.Class)).union(g.subjects(RDF.type, OWL.Class))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for cls in classes:\n",
        "    print (cls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for cls in classes:\n",
        "    # Query for labels\n",
        "    labels = list(g.objects(cls, RDFS.label))\n",
        "    if labels:\n",
        "        for label in labels:\n",
        "            print(f\"Class: {cls}, Label: {label}\")\n",
        "    else:\n",
        "        print(f\"Class: {cls}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from rdflib import Graph, RDF, RDFS, OWL\n",
        "\n",
        "def load_and_print_classes(file_path, file_format=\"ttl\"):\n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, RDFS.Class)).union(g.subjects(RDF.type, OWL.Class))\n",
        "\n",
        "    # Print class URIs and labels if available\n",
        "    print(f\"\\nClasses in {file_path}:\")\n",
        "    for cls in classes:\n",
        "        # Query for labels\n",
        "        labels = list(g.objects(cls, RDFS.label))\n",
        "        if labels:\n",
        "            for label in labels:\n",
        "                print(f\"Class: {cls}, Label: {label}\")\n",
        "        else:\n",
        "            print(f\"Class: {cls}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    # \"../Ontologies/bfo.owl\",\n",
        "    # \"../Ontologies/emmo.ttl\",\n",
        "    # '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from rdflib import Graph, RDF, RDFS, OWL\n",
        "\n",
        "def load_and_collect_classes(file_path, file_format=\"ttl\"):\n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, RDFS.Class)).union(g.subjects(RDF.type, OWL.Class))\n",
        "\n",
        "    # Collect class URIs and labels if available\n",
        "    data = []\n",
        "    for cls in classes:\n",
        "        labels = list(g.objects(cls, RDFS.label))\n",
        "        if labels:\n",
        "            for label in labels:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "        else:\n",
        "            data.append([file_path, str(cls), \"\"])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data from all files\n",
        "all_data = []\n",
        "for ontology_file in ontology_files:\n",
        "    all_data.extend(load_and_collect_classes(ontology_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from rdflib import Graph, RDF, RDFS, OWL\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, RDFS.Class)).union(g.subjects(RDF.type, OWL.Class))\n",
        "\n",
        "    # Collect class URIs and labels if available\n",
        "    data = []\n",
        "    for cls in classes:\n",
        "        labels = list(g.objects(cls, RDFS.label))\n",
        "        if labels:\n",
        "            for label in labels:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "        else:\n",
        "            data.append([file_path, str(cls), \"\"])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    # \"../Ontologies/bfo.owl\",\n",
        "    # \"../Ontologies/emmo.ttl\",\n",
        "    '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data from all files\n",
        "all_data = []\n",
        "for ontology_file in ontology_files:\n",
        "    all_data.extend(load_and_collect_classes(ontology_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class URIs and labels if available\n",
        "    data = []\n",
        "    for cls in classes:\n",
        "        # Query for rdfs:label, skos:altLabel, and skos:prefLabel\n",
        "        # labels = list(g.objects(cls, RDFS.label)) + list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel))\n",
        "        labels = list(g.objects(cls, RDFS.label)) + list(g.objects(cls, SKOS.prefLabel))\n",
        "        if labels:\n",
        "            for label in labels:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "        else:\n",
        "            data.append([file_path, str(cls), \"\"])\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    \"../Ontologies/bfo.owl\",\n",
        "    # \"../Ontologies/emmo.ttl\",\n",
        "    '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data from all files\n",
        "all_data = []\n",
        "for ontology_file in ontology_files:\n",
        "    all_data.extend(load_and_collect_classes(ontology_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class URIs and labels if available\n",
        "    data = []\n",
        "    for cls in classes:\n",
        "        # Query for rdfs:label, skos:altLabel, and skos:prefLabel\n",
        "        labels = list(g.objects(cls, RDFS.label)) + list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel))\n",
        "        if labels:\n",
        "            for label in labels:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "                print(f\"Class URI: {cls}, Label: {label}\")\n",
        "        else:\n",
        "            data.append([file_path, str(cls), \"\"])\n",
        "            print(f\"Class URI: {cls}\")\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data from all files\n",
        "all_data = []\n",
        "for ontology_file in ontology_files:\n",
        "    all_data.extend(load_and_collect_classes(ontology_file))\n",
        "\n",
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels and subclass relationships if available\n",
        "    data = []\n",
        "    found_class_labels = set()\n",
        "    subclass_relationships = {}\n",
        "    \n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(normalized_label)\n",
        "\n",
        "        # Query for subclasses using rdfs:subClassOf\n",
        "        subclasses = list(g.objects(cls, RDFS.subClassOf))\n",
        "        if subclasses:\n",
        "            subclass_relationships[str(cls)] = [str(sub) for sub in subclasses]\n",
        "\n",
        "    return data, found_class_labels, subclass_relationships"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data, found class labels, and subclass relationships from all files\n",
        "all_data = []\n",
        "all_found_class_labels = set()\n",
        "all_subclass_relationships = {}\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, found_class_labels, subclass_relationships = load_and_collect_classes(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "    all_subclass_relationships.update(subclass_relationships)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels if available\n",
        "    data = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(normalized_label)\n",
        "\n",
        "    return data, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data and found class labels from all files\n",
        "all_data = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, found_class_labels = load_and_collect_classes(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "\n",
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    \"../Ontologies/bfo.owl\",\n",
        "    \"../Ontologies/emmo.ttl\",\n",
        "    # '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data and found class labels from all files\n",
        "all_data = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, found_class_labels = load_and_collect_classes(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "\n",
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('ontology_classes.csv')\n",
        "print(df.head())\n",
        "\n",
        "# Get the number of rows and columns\n",
        "num_rows, num_cols = df.shape\n",
        "\n",
        "print(f\"Number of rows: {num_rows}\")\n",
        "print(f\"Number of columns: {num_cols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class URIs and labels if available\n",
        "    data = []\n",
        "    found_class_names = set()\n",
        "    for cls in classes:\n",
        "        # Query for rdfs:label, skos:altLabel, and skos:prefLabel\n",
        "        labels = list(g.objects(cls, RDFS.label)) + list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel))\n",
        "        if labels:\n",
        "            for label in labels:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "                found_class_names.add(label)\n",
        "        else:\n",
        "            data.append([file_path, str(cls), \"\"])\n",
        "\n",
        "    return data, found_class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    \"../Ontologies/bfo.owl\",\n",
        "    \"../Ontologies/emmo.ttl\",\n",
        "    \"../Ontologies/owlapi.xrdf\",\n",
        "    # '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data and found class names from all files\n",
        "all_data = []\n",
        "all_found_class_names = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, found_class_names = load_and_collect_classes(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_found_class_names.update(found_class_names)\n",
        "\n",
        "\n",
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class names to check\n",
        "class_names_to_check = ['Software Agent', 'SoftwareAgent', 'AmperePerJoule', 'characteristic','Bundle', '1DGeometry', 'force' , 'Agent Influence' \n",
        "                        , 'thing', 'meter', 'Accreditation-Document', \n",
        "                        'CoulombPerSquareMilliMetre', 'AcademicDiscipline', 'nfdi', 'CompressioN', 'Poissons Ratio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if class names are in found_class_names and print corresponding input files\n",
        "print(\"\\nClass names found in the output:\")\n",
        "for class_name in class_names_to_check:\n",
        "    if class_name in all_found_class_names:\n",
        "        print(f\"Class '{class_name}' found in:\")\n",
        "        for ontology_file in ontology_files:\n",
        "            file_data, found_class_names = load_and_collect_classes(ontology_file)\n",
        "            if class_name in found_class_names:\n",
        "                print(f\"- {ontology_file}\")\n",
        "    else:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels if available\n",
        "    data = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(label)\n",
        "\n",
        "    return data, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data and found class labels from all files\n",
        "all_data = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, found_class_labels = load_and_collect_classes(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "\n",
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class names to check\n",
        "class_names_to_check = ['Software Agent', 'SoftwareAgent', 'AmperePerJoule', 'characteristic','Bundle', '1DGeometry', 'force' , 'Agent Influence' \n",
        "                        , 'thing', 'meter', 'Accreditation-Document', \n",
        "                        'CoulombPerSquareMilliMetre', 'AcademicDiscipline', 'nfdi', 'CompressioN', 'Poissons Ratio' , 'PoissonsRatio' , 'Poissons_Ratio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if class names are in found_class_labels and print corresponding input files\n",
        "print(\"\\nClass names found in the output:\")\n",
        "for class_name in class_names_to_check:\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if class_name.lower() in label.lower():\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, found_class_labels = load_and_collect_classes(ontology_file)\n",
        "                if label in found_class_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def load_and_collect_classes(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels if available\n",
        "    data = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(normalized_label)\n",
        "\n",
        "    return data, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data and found class labels from all files\n",
        "all_data = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, found_class_labels = load_and_collect_classes(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "\n",
        "# Write data to CSV\n",
        "output_file = \"ontology_classes.csv\"\n",
        "with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "print(f\"Data has been saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if class names are in found_class_labels and print corresponding input files\n",
        "print(\"\\nClass names found in the output:\")\n",
        "for class_name in class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, found_class_labels = load_and_collect_classes(ontology_file)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels and relations\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(normalized_label)\n",
        "\n",
        "        # Query for relations such as subClassOf and equivalentClass\n",
        "        for obj in g.objects(cls, RDFS.subClassOf):\n",
        "            relations.append([file_path, str(cls), 'subClassOf', str(obj)])\n",
        "        for obj in g.objects(cls, OWL.equivalentClass):\n",
        "            relations.append([file_path, str(cls), 'equivalentClass', str(obj)])\n",
        "\n",
        "    return data, relations, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data, relations, and found class labels from all files\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file)\n",
        "    all_data.extend(file_data)\n",
        "    all_relations.extend(file_relations)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "\n",
        "# Write class data to CSV\n",
        "class_output_file = \"ontology_classes.csv\"\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class names to check\n",
        "class_names_to_check = ['Software Agent', 'SoftwareAgent', 'AmperePerJoule', 'characteristic','Bundle', '1DGeometry', 'force' , 'Agent Influence' \n",
        "                        , 'thing', 'meter', 'Accreditation-Document', \n",
        "                        'CoulombPerSquareMilliMetre', 'AcademicDiscipline', 'nfdi', 'CompressioN', 'Poissons Ratio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write class relations to CSV\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Relation\", \"Object Class URI\"])\n",
        "    writer.writerows(all_relations)\n",
        "\n",
        "print(f\"Class data has been saved to {class_output_file}\")\n",
        "print(f\"Class relations have been saved to {relations_output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if class names are in found_class_labels and print corresponding input files\n",
        "print(\"\\nClass names found in the output:\")\n",
        "for class_name in class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Normalize the class names to check for comparison\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels and relations\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(normalized_label)\n",
        "            # Check if the class is in the list of classes to check\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                # Query for relations such as subClassOf and equivalentClass\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    relations.append([file_path, str(cls), 'subClassOf', str(obj)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    relations.append([file_path, str(cls), 'equivalentClass', str(obj)])\n",
        "\n",
        "    return data, relations, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data, relations, and found class labels from all files\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "    all_data.extend(file_data)\n",
        "    all_relations.extend(file_relations)\n",
        "    all_found_class_labels.update(found_class_labels)\n",
        "\n",
        "# Write class data to CSV\n",
        "class_output_file = \"ontology_classes.csv\"\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Write class relations to CSV\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Relation\", \"Object Class URI\"])\n",
        "    writer.writerows(all_relations)\n",
        "\n",
        "print(f\"Class data has been saved to {class_output_file}\")\n",
        "print(f\"Class relations have been saved to {relations_output_file}\")\n",
        "\n",
        "# Check if class names are in found_class_labels and print corresponding input files\n",
        "print(\"\\nClass names found in the output:\")\n",
        "for class_name in class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def get_class_label(g, cls):\n",
        "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "    return labels[0] if labels else None\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Normalize the class names to check for comparison\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels and relations\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(normalized_label)\n",
        "            # Check if the class is in the list of classes to check\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                # Query for relations such as subClassOf and equivalentClass\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label)])\n",
        "\n",
        "    return data, relations, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    \"../Ontologies/bfo.owl\",\n",
        "    \"../Ontologies/emmo.ttl\",\n",
        "    \"../Ontologies/owlapi.xrdf\",\n",
        "    # '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class names to check\n",
        "class_names_to_check = ['Software Agent', 'SoftwareAgent', 'AmperePerJoule', 'characteristic','Bundle', '1DGeometry', 'force' , 'Agent Influence' \n",
        "                        , 'thing', 'meter', 'Accreditation-Document', \n",
        "                        'CoulombPerSquareMilliMetre', 'AcademicDiscipline', 'nfdi', 'CompressioN', 'Poissons Ratio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect data, relations, and found class labels from all files\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "for ontology_file in ontology_files:\n",
        "    file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "    all_data.extend(file_data)\n",
        "    all_relations.extend(file_relations)\n",
        "    all_found_class_labels.update(found_class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class data has been saved to ontology_classes.csv\n",
            "Class relations have been saved to ontology_relations.csv\n"
          ]
        }
      ],
      "source": [
        "# Write class data to CSV\n",
        "class_output_file = \"ontology_classes.csv\"\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(all_data)\n",
        "\n",
        "# Write class relations to CSV\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Subject Label\", \"Relation\", \"Object Class URI\", \"Object Label\"])\n",
        "    writer.writerows(all_relations)\n",
        "\n",
        "print(f\"Class data has been saved to {class_output_file}\")\n",
        "print(f\"Class relations have been saved to {relations_output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class names found in the output:\n",
            "Class 'Software Agent' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'SoftwareAgent' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'AmperePerJoule' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'characteristic' found in:\n",
            "Class 'Bundle' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class '1DGeometry' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "Class 'force' found in:\n",
            "- ../Ontologies/pmdco_core.ttl\n",
            "- ../Ontologies/emmo.ttl\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'Agent Influence' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'thing' not found in the output.\n",
            "Class 'meter' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'Accreditation-Document' found in:\n",
            "- ../Ontologies/pmdco_core.ttl\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'CoulombPerSquareMilliMetre' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'AcademicDiscipline' found in:\n",
            "- ../Ontologies/nfdicore_2.ttl\n",
            "Class 'nfdi' not found in the output.\n",
            "Class 'CompressioN' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "Class 'Poissons Ratio' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "- ../Ontologies/emmo.ttl\n"
          ]
        }
      ],
      "source": [
        "# Check if class names are in found_class_labels and print corresponding input files\n",
        "print(\"\\nClass names found in the output:\")\n",
        "for class_name in class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class relationships for the specified classes:\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: http://www.w3.org/ns/prov#SoftwareAgent (SoftwareAgent), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Agent (Agent)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: http://www.w3.org/ns/prov#SoftwareAgent (SoftwareAgent), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Agent (Agent)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (Ampere per Joule), Relation: subClassOf, Object: n3c030a17d8e340ce8ee695d5d4474800b17 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (Ampere per Joule), Relation: subClassOf, Object: n3c030a17d8e340ce8ee695d5d4474800b18 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (Ampere per Joule), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_1273eb34_de48_43a9_925f_104110469dd2 (SICoherentDerivedUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (Ampere per Joule), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_1aaaceb6_c5eb_4cf3_a494_f82d43fda10a (ElectricCurrentPerUnitEnergyUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (AmperePerJoule), Relation: subClassOf, Object: n3c030a17d8e340ce8ee695d5d4474800b17 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (AmperePerJoule), Relation: subClassOf, Object: n3c030a17d8e340ce8ee695d5d4474800b18 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (AmperePerJoule), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_1273eb34_de48_43a9_925f_104110469dd2 (SICoherentDerivedUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (AmperePerJoule), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_1aaaceb6_c5eb_4cf3_a494_f82d43fda10a (ElectricCurrentPerUnitEnergyUnit)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: http://www.w3.org/ns/prov#Bundle (Bundle), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Entity (Entity)\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/1DGeometry (1D Geometry), Relation: subClassOf, Object: http://materialsmine.org/ns/Geometry (Geometry)\n",
            "File: ../Ontologies/pmdco_core.ttl, Subject: https://w3id.org/pmd/co/Force (Force), Relation: subClassOf, Object: https://w3id.org/pmd/co/ValueObject (Value Object)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_1f087811_06cb_42d5_90fb_25d0e7e068ef (Force), Relation: subClassOf, Object: n3c030a17d8e340ce8ee695d5d4474800b2380 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_1f087811_06cb_42d5_90fb_25d0e7e068ef (Force), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_194100e1_e11a_4b7c_bb5a_171655679fc8 (Extensive)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_1f087811_06cb_42d5_90fb_25d0e7e068ef (Force), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 (ISQDerivedQuantity)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: https://w3id.org/pmd/co/Force (Force), Relation: subClassOf, Object: https://w3id.org/pmd/co/ValueObject (Value Object)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: http://www.w3.org/ns/prov#AgentInfluence (AgentInfluence), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Influence (Influence)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#Metre (Meter), Relation: subClassOf, Object: n3c030a17d8e340ce8ee695d5d4474800b2002 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#Metre (Meter), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_b3600e73_3e05_479d_9714_c041c3acf5cc (LengthUnit)\n",
            "File: ../Ontologies/pmdco_core.ttl, Subject: https://w3id.org/pmd/co/AccreditationDocument (Accreditation Document), Relation: subClassOf, Object: https://w3id.org/pmd/co/Document (Document)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: https://w3id.org/pmd/co/AccreditationDocument (Accreditation Document), Relation: subClassOf, Object: https://w3id.org/pmd/co/Document (Document)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (Coulomb Per Square Millimetre), Relation: subClassOf, Object: n3c030a17d8e340ce8ee695d5d4474800b75 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (Coulomb Per Square Millimetre), Relation: subClassOf, Object: n3c030a17d8e340ce8ee695d5d4474800b76 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (Coulomb Per Square Millimetre), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_60b78cc3_6011_4134_95ab_956f56d4bdc1 (SINonCoherentDerivedUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (Coulomb Per Square Millimetre), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_6d753e0c_a967_4de4_ad22_c2fecb3913be (ElectricDisplacementFieldUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (CoulombPerSquareMilliMetre), Relation: subClassOf, Object: n3c030a17d8e340ce8ee695d5d4474800b75 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (CoulombPerSquareMilliMetre), Relation: subClassOf, Object: n3c030a17d8e340ce8ee695d5d4474800b76 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (CoulombPerSquareMilliMetre), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_60b78cc3_6011_4134_95ab_956f56d4bdc1 (SINonCoherentDerivedUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (CoulombPerSquareMilliMetre), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_6d753e0c_a967_4de4_ad22_c2fecb3913be (ElectricDisplacementFieldUnit)\n",
            "File: ../Ontologies/nfdicore_2.ttl, Subject: https://nfdi.fiz-karlsruhe.de/ontology/AcademicDiscipline (academic discipline), Relation: subClassOf, Object: http://purl.obolibrary.org/obo/BFO_0000019 (None)\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/Compression (Compression), Relation: subClassOf, Object: http://materialsmine.org/ns/ViscoelasticProperty (Viscoelastic Property)\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/PoissonsRatio (Poissons Ratio), Relation: subClassOf, Object: http://materialsmine.org/ns/TensileProperty (Tensile Property)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_8fdabd25_01e0_4296_b82a_09d1c34e52d4 (PoissonsRatio), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_be76ad52_2e29_4202_be6f_0a15eb9c1817 (MechanicalQuantity)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_8fdabd25_01e0_4296_b82a_09d1c34e52d4 (PoissonsRatio), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_faab3f84_e475_4a46_af9c_7d249f0b9aef (RatioQuantity)\n"
          ]
        }
      ],
      "source": [
        "# Print class relationships for the specified classes\n",
        "print(\"\\nClass relationships for the specified classes:\")\n",
        "for class_name in class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    for relation in all_relations:\n",
        "        subject_label_normalized = normalize_string(relation[2])\n",
        "        if normalized_class_name == subject_label_normalized:\n",
        "            print(f\"File: {relation[0]}, Subject: {relation[1]} ({relation[2]}), Relation: {relation[3]}, Object: {relation[4]} ({relation[5]})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def get_class_label(g, cls):\n",
        "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "    return labels[0] if labels else None\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Normalize the class names to check for comparison\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels and relations\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            data.append([file_path, str(cls), str(label)])\n",
        "            found_class_labels.add(normalized_label)\n",
        "            # Check if the class is in the list of classes to check\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                # Query for relations such as subClassOf and equivalentClass\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label)])\n",
        "\n",
        "    return data, relations, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    \"../Ontologies/bfo.owl\",\n",
        "    \"../Ontologies/emmo.ttl\",\n",
        "    \"../Ontologies/owlapi.xrdf\",\n",
        "    # '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class names to check\n",
        "initial_class_names_to_check = ['Poissons Ratio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Output file names\n",
        "class_output_file = \"ontology_classes.csv\"\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "\n",
        "# Initialize variables to store all data and relations\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "\n",
        "# Initialize the list of class names to check\n",
        "class_names_to_check = initial_class_names_to_check\n",
        "\n",
        "# Perform iterative process with a maximum of 3 iterations\n",
        "max_iterations = 3\n",
        "iteration_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class data has been saved to ontology_classes.csv\n",
            "Class relations have been saved to ontology_relations.csv\n"
          ]
        }
      ],
      "source": [
        "while class_names_to_check and iteration_count < max_iterations:\n",
        "    iteration_count += 1\n",
        "    new_data = []\n",
        "    new_relations = []\n",
        "    new_found_class_labels = set()\n",
        "\n",
        "    # Collect data, relations, and found class labels from all files\n",
        "    for ontology_file in ontology_files:\n",
        "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "        new_data.extend(file_data)\n",
        "        new_relations.extend(file_relations)\n",
        "        new_found_class_labels.update(found_class_labels)\n",
        "\n",
        "    # Append new data and relations to the overall collection\n",
        "    all_data.extend(new_data)\n",
        "    all_relations.extend(new_relations)\n",
        "    all_found_class_labels.update(new_found_class_labels)\n",
        "\n",
        "    # Write class data to CSV\n",
        "    with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        if file.tell() == 0:\n",
        "            writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "        writer.writerows(new_data)\n",
        "\n",
        "    # Write class relations to CSV\n",
        "    with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        if file.tell() == 0:\n",
        "            writer.writerow([\"File\", \"Subject Class URI\", \"Subject Label\", \"Relation\", \"Object Class URI\", \"Object Label\"])\n",
        "        writer.writerows(new_relations)\n",
        "\n",
        "    # Prepare for next iteration: set new class names to check\n",
        "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
        "\n",
        "    # Normalize new class names to check for consistency\n",
        "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
        "\n",
        "print(f\"Class data has been saved to {class_output_file}\")\n",
        "print(f\"Class relations have been saved to {relations_output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initial class names found in the output:\n",
            "Class 'Poissons Ratio' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "- ../Ontologies/emmo.ttl\n"
          ]
        }
      ],
      "source": [
        "# Check if initial class names are in found_class_labels and print corresponding input files\n",
        "print(\"\\nInitial class names found in the output:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class relationships for the initial specified classes:\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/PoissonsRatio (Poissons Ratio), Relation: subClassOf, Object: http://materialsmine.org/ns/TensileProperty (Tensile Property)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_8fdabd25_01e0_4296_b82a_09d1c34e52d4 (PoissonsRatio), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_be76ad52_2e29_4202_be6f_0a15eb9c1817 (MechanicalQuantity)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_8fdabd25_01e0_4296_b82a_09d1c34e52d4 (PoissonsRatio), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_faab3f84_e475_4a46_af9c_7d249f0b9aef (RatioQuantity)\n"
          ]
        }
      ],
      "source": [
        "# Print class relationships for the initial specified classes\n",
        "print(\"\\nClass relationships for the initial specified classes:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    for relation in all_relations:\n",
        "        subject_label_normalized = normalize_string(relation[2])\n",
        "        if normalized_class_name == subject_label_normalized:\n",
        "            print(f\"File: {relation[0]}, Subject: {relation[1]} ({relation[2]}), Relation: {relation[3]}, Object: {relation[4]} ({relation[5]})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def get_class_label(g, cls):\n",
        "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "    return labels[0] if labels else None\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Normalize the class names to check for comparison\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels and relations\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            found_class_labels.add(normalized_label)\n",
        "            # Check if the class is in the list of classes to check\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "                # Query for relations such as subClassOf and equivalentClass\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label)])\n",
        "\n",
        "    return data, relations, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Output file names\n",
        "class_output_file = \"ontology_classes.csv\"\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "\n",
        "# Initialize variables to store all data and relations\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "\n",
        "# Initialize the list of class names to check\n",
        "class_names_to_check = initial_class_names_to_check\n",
        "\n",
        "# Perform iterative process with a maximum of 3 iterations\n",
        "max_iterations = 5\n",
        "iteration_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "while class_names_to_check and iteration_count < max_iterations:\n",
        "    iteration_count += 1\n",
        "    new_data = []\n",
        "    new_relations = []\n",
        "    new_found_class_labels = set()\n",
        "\n",
        "    # Collect data, relations, and found class labels from all files\n",
        "    for ontology_file in ontology_files:\n",
        "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "        new_data.extend(file_data)\n",
        "        new_relations.extend(file_relations)\n",
        "        new_found_class_labels.update(found_class_labels)\n",
        "\n",
        "    # Append new data and relations to the overall collection\n",
        "    all_data.extend(new_data)\n",
        "    all_relations.extend(new_relations)\n",
        "    all_found_class_labels.update(new_found_class_labels)\n",
        "\n",
        "    # Prepare for next iteration: set new class names to check\n",
        "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
        "\n",
        "    # Normalize new class names to check for consistency\n",
        "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered class data has been saved to ontology_classes.csv\n",
            "Filtered class relations have been saved to ontology_relations.csv\n"
          ]
        }
      ],
      "source": [
        "# Write class data to CSV only if the class is in the initial list\n",
        "filtered_data = [row for row in all_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(filtered_data)\n",
        "\n",
        "# Write class relations to CSV only if the class is in the initial list\n",
        "filtered_relations = [row for row in all_relations if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Subject Label\", \"Relation\", \"Object Class URI\", \"Object Label\"])\n",
        "    writer.writerows(filtered_relations)\n",
        "\n",
        "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
        "print(f\"Filtered class relations have been saved to {relations_output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initial class names found in the output:\n",
            "Class 'Software Agent' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'SoftwareAgent' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'AmperePerJoule' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'characteristic' found in:\n",
            "Class 'Bundle' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class '1DGeometry' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "Class 'force' found in:\n",
            "- ../Ontologies/pmdco_core.ttl\n",
            "- ../Ontologies/emmo.ttl\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'Agent Influence' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'thing' not found in the output.\n",
            "Class 'meter' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'Accreditation-Document' found in:\n",
            "- ../Ontologies/pmdco_core.ttl\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'CoulombPerSquareMilliMetre' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'AcademicDiscipline' found in:\n",
            "- ../Ontologies/nfdicore_2.ttl\n",
            "Class 'nfdi' not found in the output.\n",
            "Class 'CompressioN' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "Class 'Poissons Ratio' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "- ../Ontologies/emmo.ttl\n"
          ]
        }
      ],
      "source": [
        "# Check if initial class names are in found_class_labels and print corresponding input files\n",
        "print(\"\\nInitial class names found in the output:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class relationships for the initial specified classes:\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: http://www.w3.org/ns/prov#SoftwareAgent (SoftwareAgent), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Agent (Agent)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: http://www.w3.org/ns/prov#SoftwareAgent (SoftwareAgent), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Agent (Agent)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (Ampere per Joule), Relation: subClassOf, Object: nf3bace6dc38d47a19a8738229158a351b17 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (Ampere per Joule), Relation: subClassOf, Object: nf3bace6dc38d47a19a8738229158a351b18 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (Ampere per Joule), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_1273eb34_de48_43a9_925f_104110469dd2 (SICoherentDerivedUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (Ampere per Joule), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_1aaaceb6_c5eb_4cf3_a494_f82d43fda10a (ElectricCurrentPerUnitEnergyUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (AmperePerJoule), Relation: subClassOf, Object: nf3bace6dc38d47a19a8738229158a351b17 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (AmperePerJoule), Relation: subClassOf, Object: nf3bace6dc38d47a19a8738229158a351b18 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (AmperePerJoule), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_1273eb34_de48_43a9_925f_104110469dd2 (SICoherentDerivedUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#AmperePerJoule (AmperePerJoule), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_1aaaceb6_c5eb_4cf3_a494_f82d43fda10a (ElectricCurrentPerUnitEnergyUnit)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: http://www.w3.org/ns/prov#Bundle (Bundle), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Entity (Entity)\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/1DGeometry (1D Geometry), Relation: subClassOf, Object: http://materialsmine.org/ns/Geometry (Geometry)\n",
            "File: ../Ontologies/pmdco_core.ttl, Subject: https://w3id.org/pmd/co/Force (Force), Relation: subClassOf, Object: https://w3id.org/pmd/co/ValueObject (Value Object)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_1f087811_06cb_42d5_90fb_25d0e7e068ef (Force), Relation: subClassOf, Object: nf3bace6dc38d47a19a8738229158a351b2380 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_1f087811_06cb_42d5_90fb_25d0e7e068ef (Force), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_194100e1_e11a_4b7c_bb5a_171655679fc8 (Extensive)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_1f087811_06cb_42d5_90fb_25d0e7e068ef (Force), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 (ISQDerivedQuantity)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: https://w3id.org/pmd/co/Force (Force), Relation: subClassOf, Object: https://w3id.org/pmd/co/ValueObject (Value Object)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: http://www.w3.org/ns/prov#AgentInfluence (AgentInfluence), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Influence (Influence)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#Metre (Meter), Relation: subClassOf, Object: nf3bace6dc38d47a19a8738229158a351b2002 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#Metre (Meter), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_b3600e73_3e05_479d_9714_c041c3acf5cc (LengthUnit)\n",
            "File: ../Ontologies/pmdco_core.ttl, Subject: https://w3id.org/pmd/co/AccreditationDocument (Accreditation Document), Relation: subClassOf, Object: https://w3id.org/pmd/co/Document (Document)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: https://w3id.org/pmd/co/AccreditationDocument (Accreditation Document), Relation: subClassOf, Object: https://w3id.org/pmd/co/Document (Document)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (Coulomb Per Square Millimetre), Relation: subClassOf, Object: nf3bace6dc38d47a19a8738229158a351b75 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (Coulomb Per Square Millimetre), Relation: subClassOf, Object: nf3bace6dc38d47a19a8738229158a351b76 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (Coulomb Per Square Millimetre), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_60b78cc3_6011_4134_95ab_956f56d4bdc1 (SINonCoherentDerivedUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (Coulomb Per Square Millimetre), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_6d753e0c_a967_4de4_ad22_c2fecb3913be (ElectricDisplacementFieldUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (CoulombPerSquareMilliMetre), Relation: subClassOf, Object: nf3bace6dc38d47a19a8738229158a351b75 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (CoulombPerSquareMilliMetre), Relation: subClassOf, Object: nf3bace6dc38d47a19a8738229158a351b76 (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (CoulombPerSquareMilliMetre), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_60b78cc3_6011_4134_95ab_956f56d4bdc1 (SINonCoherentDerivedUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#CoulombPerSquareMilliMetre (CoulombPerSquareMilliMetre), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_6d753e0c_a967_4de4_ad22_c2fecb3913be (ElectricDisplacementFieldUnit)\n",
            "File: ../Ontologies/nfdicore_2.ttl, Subject: https://nfdi.fiz-karlsruhe.de/ontology/AcademicDiscipline (academic discipline), Relation: subClassOf, Object: http://purl.obolibrary.org/obo/BFO_0000019 (None)\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/Compression (Compression), Relation: subClassOf, Object: http://materialsmine.org/ns/ViscoelasticProperty (Viscoelastic Property)\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/PoissonsRatio (Poissons Ratio), Relation: subClassOf, Object: http://materialsmine.org/ns/TensileProperty (Tensile Property)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_8fdabd25_01e0_4296_b82a_09d1c34e52d4 (PoissonsRatio), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_be76ad52_2e29_4202_be6f_0a15eb9c1817 (MechanicalQuantity)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_8fdabd25_01e0_4296_b82a_09d1c34e52d4 (PoissonsRatio), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_faab3f84_e475_4a46_af9c_7d249f0b9aef (RatioQuantity)\n"
          ]
        }
      ],
      "source": [
        "# Print class relationships for the initial specified classes\n",
        "print(\"\\nClass relationships for the initial specified classes:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    for relation in all_relations:\n",
        "        subject_label_normalized = normalize_string(relation[2])\n",
        "        if normalized_class_name == subject_label_normalized:\n",
        "            print(f\"File: {relation[0]}, Subject: {relation[1]} ({relation[2]}), Relation: {relation[3]}, Object: {relation[4]} ({relation[5]})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class names to check\n",
        "initial_class_names_to_check = ['Software Agent', 'SoftwareAgent', 'AmperePerJoule', 'characteristic','Bundle', '1DGeometry', 'force' , 'Agent Influence' \n",
        "                        , 'thing', 'meter', 'Accreditation-Document', \n",
        "                        'CoulombPerSquareMilliMetre', 'AcademicDiscipline', 'nfdi', 'CompressioN', 'Poissons Ratio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of ontology files to process\n",
        "ontology_files = [\n",
        "    \"../Ontologies/materialsmine.ttl\",\n",
        "    \"../Ontologies/pmdco_core.ttl\",\n",
        "    \"../Ontologies/nfdicore_2.ttl\",\n",
        "    \"../Ontologies/bfo.owl\",\n",
        "    \"../Ontologies/emmo.ttl\",\n",
        "    \"../Ontologies/owlapi.xrdf\",\n",
        "    # '../Ontologies/emmo.owl',\n",
        "    # Add more file paths as needed\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    # Normalize string by converting to lowercase and removing special characters\n",
        "    s = s.lower()\n",
        "    # Remove characters: '_', '-', '+', space, and '...'\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def get_class_label(g, cls):\n",
        "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "    return labels[0] if labels else None\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    # Determine the file format based on the file extension\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    # Load the ontology file\n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    # Normalize the class names to check for comparison\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    # Define the custom namespace (replace 'ex' with your custom namespace prefix)\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    # Query for all classes in the ontology\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    # Collect class labels and relations\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        # Query for skos:altLabel, skos:prefLabel, and rdfs:label\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            found_class_labels.add(normalized_label)\n",
        "            # Check if the class is in the list of classes to check\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "                # Query for relations such as subClassOf and equivalentClass\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label)])\n",
        "\n",
        "    return data, relations, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered class data has been saved to ontology_classes.csv\n",
            "Filtered class relations have been saved to ontology_relations.csv\n",
            "\n",
            "Initial class names found in the output:\n",
            "Class 'Tensile Property' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "Class 'Viscoelastic Property' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "Class 'Geometry' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "Class 'Document' found in:\n",
            "- ../Ontologies/pmdco_core.ttl\n",
            "- ../Ontologies/emmo.ttl\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'Value Object' found in:\n",
            "- ../Ontologies/pmdco_core.ttl\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'LengthUnit' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "\n",
            "Class relationships for the initial specified classes:\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/TensileProperty (Tensile Property), Relation: subClassOf, Object: http://materialsmine.org/ns/MechanicalProperty (Mechanical Property)\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/ViscoelasticProperty (Viscoelastic Property), Relation: subClassOf, Object: http://semanticscience.org/resource/Quantity (Amount)\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/Geometry (Geometry), Relation: subClassOf, Object: http://semanticscience.org/resource/GeometricEntity (None)\n",
            "File: ../Ontologies/pmdco_core.ttl, Subject: https://w3id.org/pmd/co/Document (Document), Relation: subClassOf, Object: https://w3id.org/pmd/co/ValueObject (Value Object)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_ccdc1a41_6e96_416b_92ec_efe67917434a (Document), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_c74da218_9147_4f03_92d1_8894abca55f3 (Graphical)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: https://w3id.org/pmd/co/Document (Document), Relation: subClassOf, Object: https://w3id.org/pmd/co/ValueObject (Value Object)\n",
            "File: ../Ontologies/pmdco_core.ttl, Subject: https://w3id.org/pmd/co/ValueObject (Value Object), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Entity (None)\n",
            "File: ../Ontologies/pmdco_core.ttl, Subject: https://w3id.org/pmd/co/ValueObject (Value Object), Relation: equivalentClass, Object: ne28e240ed3504e68b699908dfb0a06b3b106 (None)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: https://w3id.org/pmd/co/ValueObject (Value Object), Relation: subClassOf, Object: http://www.w3.org/ns/prov#Entity (Entity)\n",
            "File: ../Ontologies/owlapi.xrdf, Subject: https://w3id.org/pmd/co/ValueObject (Value Object), Relation: equivalentClass, Object: N39f885120ff245d1ac1ac9e2b2b42b6a (None)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_b3600e73_3e05_479d_9714_c041c3acf5cc (LengthUnit), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_9895a1b4_f0a5_4167_ac5e_97db40b8bfcc (SIDimensionalUnit)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_b3600e73_3e05_479d_9714_c041c3acf5cc (LengthUnit), Relation: equivalentClass, Object: n0d0a4079751f4a66a3b4183b2d03b434b2502 (None)\n"
          ]
        }
      ],
      "source": [
        "# Output file names\n",
        "class_output_file = \"ontology_classes.csv\"\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "\n",
        "# Initialize variables to store all data and relations\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "\n",
        "# Initialize the list of class names to check\n",
        "class_names_to_check = initial_class_names_to_check\n",
        "\n",
        "# Perform iterative process with a maximum of 3 iterations\n",
        "max_iterations = 3\n",
        "iteration_count = 0\n",
        "while class_names_to_check and iteration_count < max_iterations:\n",
        "    iteration_count += 1\n",
        "    new_data = []\n",
        "    new_relations = []\n",
        "    new_found_class_labels = set()\n",
        "\n",
        "    # Collect data, relations, and found class labels from all files\n",
        "    for ontology_file in ontology_files:\n",
        "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "        new_data.extend(file_data)\n",
        "        new_relations.extend(file_relations)\n",
        "        new_found_class_labels.update(found_class_labels)\n",
        "\n",
        "    # Append new data and relations to the overall collection\n",
        "    all_data.extend(new_data)\n",
        "    all_relations.extend(new_relations)\n",
        "    all_found_class_labels.update(new_found_class_labels)\n",
        "\n",
        "    # Prepare for next iteration: set new class names to check\n",
        "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
        "\n",
        "    # Normalize new class names to check for consistency\n",
        "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
        "# Write class data to CSV only if the class is in the initial list\n",
        "filtered_data = [row for row in all_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(filtered_data)\n",
        "\n",
        "# Write class relations to CSV only if the class is in the initial list\n",
        "filtered_relations = [row for row in all_relations if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Subject Label\", \"Relation\", \"Object Class URI\", \"Object Label\"])\n",
        "    writer.writerows(filtered_relations)\n",
        "\n",
        "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
        "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
        "# Check if initial class names are in found_class_labels and print corresponding input files\n",
        "print(\"\\nInitial class names found in the output:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")\n",
        "# Print class relationships for the initial specified classes\n",
        "print(\"\\nClass relationships for the initial specified classes:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    for relation in all_relations:\n",
        "        subject_label_normalized = normalize_string(relation[2])\n",
        "        if normalized_class_name == subject_label_normalized:\n",
        "            print(f\"File: {relation[0]}, Subject: {relation[1]} ({relation[2]}), Relation: {relation[3]}, Object: {relation[4]} ({relation[5]})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class names to check\n",
        "initial_class_names_to_check = ['Tensile Property', 'Viscoelastic Property', 'Geometry', 'Document','Value Object', 'LengthUnit']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = s.lower()\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def get_class_label(g, cls):\n",
        "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "    return labels[0] if labels else None\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            found_class_labels.add(normalized_label)\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label)])\n",
        "\n",
        "    return data, relations, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_output_file = \"ontology_classes.csv\"\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "\n",
        "class_names_to_check = initial_class_names_to_check\n",
        "\n",
        "max_iterations = 3\n",
        "iteration_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class names to check\n",
        "initial_class_names_to_check = ['Poissons Ratio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered class data has been saved to ontology_classes.csv\n",
            "Filtered class relations have been saved to ontology_relations.csv\n"
          ]
        }
      ],
      "source": [
        "while class_names_to_check and iteration_count < max_iterations:\n",
        "    iteration_count += 1\n",
        "    new_data = []\n",
        "    new_relations = []\n",
        "    new_found_class_labels = set()\n",
        "\n",
        "    for ontology_file in ontology_files:\n",
        "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "        new_data.extend(file_data)\n",
        "        new_relations.extend(file_relations)\n",
        "        new_found_class_labels.update(found_class_labels)\n",
        "\n",
        "    all_data.extend(new_data)\n",
        "    all_relations.extend(new_relations)\n",
        "    all_found_class_labels.update(new_found_class_labels)\n",
        "\n",
        "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
        "\n",
        "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
        "\n",
        "filtered_data = [row for row in all_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(filtered_data)\n",
        "\n",
        "filtered_relations = [row for row in all_relations if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Subject Label\", \"Relation\", \"Object Class URI\", \"Object Label\"])\n",
        "    writer.writerows(filtered_relations)\n",
        "\n",
        "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
        "print(f\"Filtered class relations have been saved to {relations_output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initial class names found in the output:\n",
            "Class 'Poissons Ratio' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "- ../Ontologies/emmo.ttl\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nInitial class names found in the output:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class relationships for the initial specified classes:\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/PoissonsRatio (Poissons Ratio), Relation: subClassOf, Object: http://materialsmine.org/ns/TensileProperty (Tensile Property)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_8fdabd25_01e0_4296_b82a_09d1c34e52d4 (PoissonsRatio), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_be76ad52_2e29_4202_be6f_0a15eb9c1817 (MechanicalQuantity)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_8fdabd25_01e0_4296_b82a_09d1c34e52d4 (PoissonsRatio), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_faab3f84_e475_4a46_af9c_7d249f0b9aef (RatioQuantity)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nClass relationships for the initial specified classes:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    for relation in all_relations:\n",
        "        subject_label_normalized = normalize_string(relation[2])\n",
        "        if normalized_class_name == subject_label_normalized:\n",
        "            print(f\"File: {relation[0]}, Subject: {relation[1]} ({relation[2]}), Relation: {relation[3]}, Object: {relation[4]} ({relation[5]})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = s.lower()\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def get_class_label(g, cls):\n",
        "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "    return labels[0] if labels else None\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            found_class_labels.add(normalized_label)\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label)])\n",
        "\n",
        "    return data, relations, found_class_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_relations(all_relations, initial_class_names_to_check):\n",
        "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
        "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
        "\n",
        "class_output_file = \"ontology_classes.csv\"\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "\n",
        "class_names_to_check = initial_class_names_to_check\n",
        "\n",
        "max_iterations = 6\n",
        "iteration_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered class data has been saved to ontology_classes.csv\n",
            "Filtered class relations have been saved to ontology_relations.csv\n"
          ]
        }
      ],
      "source": [
        "while class_names_to_check and iteration_count < max_iterations:\n",
        "    iteration_count += 1\n",
        "    new_data = []\n",
        "    new_relations = []\n",
        "    new_found_class_labels = set()\n",
        "\n",
        "    for ontology_file in ontology_files:\n",
        "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "        new_data.extend(file_data)\n",
        "        new_relations.extend(file_relations)\n",
        "        new_found_class_labels.update(found_class_labels)\n",
        "\n",
        "    all_data.extend(new_data)\n",
        "    all_relations.extend(new_relations)\n",
        "    all_found_class_labels.update(new_found_class_labels)\n",
        "\n",
        "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
        "\n",
        "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
        "\n",
        "filtered_data = [row for row in all_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(filtered_data)\n",
        "\n",
        "filtered_relations = filter_relations(all_relations, initial_class_names_to_check)\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Subject Label\", \"Relation\", \"Object Class URI\", \"Object Label\"])\n",
        "    writer.writerows(filtered_relations)\n",
        "\n",
        "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
        "print(f\"Filtered class relations have been saved to {relations_output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initial class names found in the output:\n",
            "Class 'Poissons Ratio' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "- ../Ontologies/emmo.ttl\n",
            "\n",
            "Class relationships for the initial specified classes and their hierarchy:\n",
            "File: ../Ontologies/materialsmine.ttl, Subject: http://materialsmine.org/ns/PoissonsRatio (Poissons Ratio), Relation: subClassOf, Object: http://materialsmine.org/ns/TensileProperty (Tensile Property)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_8fdabd25_01e0_4296_b82a_09d1c34e52d4 (PoissonsRatio), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_be76ad52_2e29_4202_be6f_0a15eb9c1817 (MechanicalQuantity)\n",
            "File: ../Ontologies/emmo.ttl, Subject: https://w3id.org/emmo#EMMO_8fdabd25_01e0_4296_b82a_09d1c34e52d4 (PoissonsRatio), Relation: subClassOf, Object: https://w3id.org/emmo#EMMO_faab3f84_e475_4a46_af9c_7d249f0b9aef (RatioQuantity)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nInitial class names found in the output:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")\n",
        "\n",
        "print(\"\\nClass relationships for the initial specified classes and their hierarchy:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    for relation in all_relations:\n",
        "        subject_label_normalized = normalize_string(relation[2])\n",
        "        if normalized_class_name == subject_label_normalized:\n",
        "            print(f\"File: {relation[0]}, Subject: {relation[1]} ({relation[2]}), Relation: {relation[3]}, Object: {relation[4]} ({relation[5]})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = s.lower()\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def get_class_label(g, cls):\n",
        "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "    return labels[0] if labels else None\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            found_class_labels.add(normalized_label)\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label)])\n",
        "\n",
        "    return data, relations, found_class_labels\n",
        "\n",
        "def filter_relations(all_relations, initial_class_names_to_check):\n",
        "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
        "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
        "\n",
        "def print_hierarchy(class_name, relations, depth=0):\n",
        "    for relation in relations:\n",
        "        if normalize_string(relation[2]) == normalize_string(class_name):\n",
        "            indent = '  ' * depth\n",
        "            print(f\"{indent}{class_name} is {relation[3]} {relation[5]}\")\n",
        "            print_hierarchy(relation[5], relations, depth + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "class_output_file = \"ontology_classes.csv\"\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "\n",
        "class_names_to_check = initial_class_names_to_check\n",
        "\n",
        "max_iterations = 2\n",
        "iteration_count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "while class_names_to_check and iteration_count < max_iterations:\n",
        "    iteration_count += 1\n",
        "    new_data = []\n",
        "    new_relations = []\n",
        "    new_found_class_labels = set()\n",
        "\n",
        "    for ontology_file in ontology_files:\n",
        "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "        new_data.extend(file_data)\n",
        "        new_relations.extend(file_relations)\n",
        "        new_found_class_labels.update(found_class_labels)\n",
        "\n",
        "    all_data.extend(new_data)\n",
        "    all_relations.extend(new_relations)\n",
        "    all_found_class_labels.update(new_found_class_labels)\n",
        "\n",
        "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
        "\n",
        "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered class data has been saved to ontology_classes.csv\n",
            "Filtered class relations have been saved to ontology_relations.csv\n"
          ]
        }
      ],
      "source": [
        "filtered_data = [row for row in all_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(filtered_data)\n",
        "\n",
        "filtered_relations = filter_relations(all_relations, initial_class_names_to_check)\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Subject Label\", \"Relation\", \"Object Class URI\", \"Object Label\"])\n",
        "    writer.writerows(filtered_relations)\n",
        "\n",
        "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
        "print(f\"Filtered class relations have been saved to {relations_output_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Initial class names found in the output:\n",
            "Class 'Poissons Ratio' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "- ../Ontologies/emmo.ttl\n",
            "\n",
            "Class relationships for the initial specified classes and their hierarchy:\n",
            "poissonsratio is subClassOf Tensile Property\n",
            "  Tensile Property is subClassOf Mechanical Property\n",
            "    Mechanical Property is subClassOf Amount\n",
            "      Amount is subClassOf None\n",
            "poissonsratio is subClassOf MechanicalQuantity\n",
            "  MechanicalQuantity is subClassOf ISO80000Categorised\n",
            "    ISO80000Categorised is subClassOf CategorizedPhysicalQuantity\n",
            "      CategorizedPhysicalQuantity is subClassOf PhysicalQuantity\n",
            "        PhysicalQuantity is subClassOf None\n",
            "poissonsratio is subClassOf RatioQuantity\n",
            "  RatioQuantity is subClassOf ISQDimensionlessQuantity\n",
            "    ISQDimensionlessQuantity is subClassOf None\n",
            "    ISQDimensionlessQuantity is subClassOf ISQDerivedQuantity\n",
            "      ISQDerivedQuantity is subClassOf DerivedQuantity\n",
            "      ISQDerivedQuantity is subClassOf InternationalSystemOfQuantity\n",
            "        InternationalSystemOfQuantity is subClassOf StandardizedPhysicalQuantity\n",
            "          StandardizedPhysicalQuantity is subClassOf PhysicalQuantity\n",
            "            PhysicalQuantity is subClassOf None\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nInitial class names found in the output:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")\n",
        "\n",
        "print(\"\\nClass relationships for the initial specified classes and their hierarchy:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    print_hierarchy(normalized_class_name, all_relations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered class data has been saved to ontology_classes.csv\n",
            "Filtered class relations have been saved to ontology_relations.csv\n",
            "\n",
            "Initial class names found in the output:\n",
            "Class 'Poissons Ratio' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "- ../Ontologies/emmo.ttl\n",
            "\n",
            "Class relationships for the initial specified classes and their hierarchy:\n",
            "poissonsratio is subClassOf Tensile Property (from ../Ontologies/materialsmine.ttl)\n",
            "  Tensile Property is subClassOf Mechanical Property (from ../Ontologies/materialsmine.ttl)\n",
            "    Mechanical Property is subClassOf Amount (from ../Ontologies/materialsmine.ttl)\n",
            "      Amount is subClassOf None (from ../Ontologies/materialsmine.ttl)\n",
            "poissonsratio is subClassOf MechanicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "  MechanicalQuantity is subClassOf ISO80000Categorised (from ../Ontologies/emmo.ttl)\n",
            "    ISO80000Categorised is subClassOf CategorizedPhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "      CategorizedPhysicalQuantity is subClassOf PhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "        PhysicalQuantity is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "poissonsratio is subClassOf RatioQuantity (from ../Ontologies/emmo.ttl)\n",
            "  RatioQuantity is subClassOf ISQDimensionlessQuantity (from ../Ontologies/emmo.ttl)\n",
            "    ISQDimensionlessQuantity is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "    ISQDimensionlessQuantity is subClassOf ISQDerivedQuantity (from ../Ontologies/emmo.ttl)\n",
            "      ISQDerivedQuantity is subClassOf DerivedQuantity (from ../Ontologies/emmo.ttl)\n",
            "      ISQDerivedQuantity is subClassOf InternationalSystemOfQuantity (from ../Ontologies/emmo.ttl)\n",
            "        InternationalSystemOfQuantity is subClassOf StandardizedPhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "          StandardizedPhysicalQuantity is subClassOf PhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "            PhysicalQuantity is subClassOf None (from ../Ontologies/emmo.ttl)\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = s.lower()\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def get_class_label(g, cls):\n",
        "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "    return labels[0] if labels else None\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            found_class_labels.add(normalized_label)\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label)])\n",
        "\n",
        "    return data, relations, found_class_labels\n",
        "\n",
        "def filter_relations(all_relations, initial_class_names_to_check):\n",
        "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
        "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
        "\n",
        "def print_hierarchy(class_name, relations, ontology_files, depth=0):\n",
        "    for relation in relations:\n",
        "        if normalize_string(relation[2]) == normalize_string(class_name):\n",
        "            indent = '  ' * depth\n",
        "            print(f\"{indent}{class_name} is {relation[3]} {relation[5]} (from {relation[0]})\")\n",
        "            print_hierarchy(relation[5], relations, ontology_files, depth + 1)\n",
        "\n",
        "\n",
        "class_output_file = \"ontology_classes.csv\"\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "\n",
        "class_names_to_check = initial_class_names_to_check\n",
        "\n",
        "max_iterations = 2\n",
        "iteration_count = 0\n",
        "\n",
        "while class_names_to_check and iteration_count < max_iterations:\n",
        "    iteration_count += 1\n",
        "    new_data = []\n",
        "    new_relations = []\n",
        "    new_found_class_labels = set()\n",
        "\n",
        "    for ontology_file in ontology_files:\n",
        "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "        new_data.extend(file_data)\n",
        "        new_relations.extend(file_relations)\n",
        "        new_found_class_labels.update(found_class_labels)\n",
        "\n",
        "    all_data.extend(new_data)\n",
        "    all_relations.extend(new_relations)\n",
        "    all_found_class_labels.update(new_found_class_labels)\n",
        "\n",
        "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
        "\n",
        "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
        "\n",
        "filtered_data = [row for row in all_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(filtered_data)\n",
        "\n",
        "filtered_relations = filter_relations(all_relations, initial_class_names_to_check)\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Subject Label\", \"Relation\", \"Object Class URI\", \"Object Label\"])\n",
        "    writer.writerows(filtered_relations)\n",
        "\n",
        "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
        "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
        "\n",
        "print(\"\\nInitial class names found in the output:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")\n",
        "\n",
        "print(\"\\nClass relationships for the initial specified classes and their hierarchy:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    print_hierarchy(normalized_class_name, all_relations, ontology_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List of class names to check\n",
        "initial_class_names_to_check = [ 'SoftwareAgent', 'AmperePerJoule',\n",
        "                        'CoulombPerSquareMilliMetre', 'AcademicDiscipline', 'nfdi', 'CompressioN', 'Poissons Ratio']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered class data has been saved to ontology_classes.csv\n",
            "Filtered class relations have been saved to ontology_relations.csv\n",
            "\n",
            "Initial class names found in the output:\n",
            "Class 'SoftwareAgent' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'AmperePerJoule' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'CoulombPerSquareMilliMetre' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'AcademicDiscipline' found in:\n",
            "- ../Ontologies/nfdicore_2.ttl\n",
            "Class 'nfdi' not found in the output.\n",
            "Class 'CompressioN' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "Class 'Poissons Ratio' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "- ../Ontologies/emmo.ttl\n",
            "\n",
            "Class relationships for the initial specified classes and their hierarchy:\n",
            "softwareagent is subClassOf Agent (from ../Ontologies/owlapi.xrdf)\n",
            "  Agent is subClassOf None (from ../Ontologies/nfdicore_2.ttl)\n",
            "  Agent is subClassOf Participant (from ../Ontologies/emmo.ttl)\n",
            "    Participant is subClassOf Continuant (from ../Ontologies/emmo.ttl)\n",
            "      Continuant is subClassOf entity (from ../Ontologies/bfo.owl)\n",
            "        entity is subClassOf None (from ../Ontologies/bfo.owl)\n",
            "        entity is subClassOf None (from ../Ontologies/owlapi.xrdf)\n",
            "    Participant is subClassOf HolisticSpatialPart (from ../Ontologies/emmo.ttl)\n",
            "  Agent is subClassOf None (from ../Ontologies/owlapi.xrdf)\n",
            "ampereperjoule is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf SICoherentDerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "  SICoherentDerivedUnit is subClassOf DerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf ElectricCurrentPerUnitEnergyUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricCurrentPerUnitEnergyUnit is subClassOf SIDimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "    SIDimensionalUnit is subClassOf DimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricCurrentPerUnitEnergyUnit is equivalentClass None (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf SICoherentDerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "  SICoherentDerivedUnit is subClassOf DerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf ElectricCurrentPerUnitEnergyUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricCurrentPerUnitEnergyUnit is subClassOf SIDimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "    SIDimensionalUnit is subClassOf DimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricCurrentPerUnitEnergyUnit is equivalentClass None (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf SINonCoherentDerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "  SINonCoherentDerivedUnit is subClassOf DerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf ElectricDisplacementFieldUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricDisplacementFieldUnit is subClassOf SIDimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "    SIDimensionalUnit is subClassOf DimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricDisplacementFieldUnit is equivalentClass None (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf SINonCoherentDerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "  SINonCoherentDerivedUnit is subClassOf DerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf ElectricDisplacementFieldUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricDisplacementFieldUnit is subClassOf SIDimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "    SIDimensionalUnit is subClassOf DimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricDisplacementFieldUnit is equivalentClass None (from ../Ontologies/emmo.ttl)\n",
            "academicdiscipline is subClassOf None (from ../Ontologies/nfdicore_2.ttl)\n",
            "compression is subClassOf Viscoelastic Property (from ../Ontologies/materialsmine.ttl)\n",
            "  Viscoelastic Property is subClassOf Amount (from ../Ontologies/materialsmine.ttl)\n",
            "    Amount is subClassOf None (from ../Ontologies/materialsmine.ttl)\n",
            "poissonsratio is subClassOf Tensile Property (from ../Ontologies/materialsmine.ttl)\n",
            "  Tensile Property is subClassOf Mechanical Property (from ../Ontologies/materialsmine.ttl)\n",
            "    Mechanical Property is subClassOf Amount (from ../Ontologies/materialsmine.ttl)\n",
            "      Amount is subClassOf None (from ../Ontologies/materialsmine.ttl)\n",
            "poissonsratio is subClassOf MechanicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "  MechanicalQuantity is subClassOf ISO80000Categorised (from ../Ontologies/emmo.ttl)\n",
            "    ISO80000Categorised is subClassOf CategorizedPhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "      CategorizedPhysicalQuantity is subClassOf PhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "        PhysicalQuantity is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "poissonsratio is subClassOf RatioQuantity (from ../Ontologies/emmo.ttl)\n",
            "  RatioQuantity is subClassOf ISQDimensionlessQuantity (from ../Ontologies/emmo.ttl)\n",
            "    ISQDimensionlessQuantity is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "    ISQDimensionlessQuantity is subClassOf ISQDerivedQuantity (from ../Ontologies/emmo.ttl)\n",
            "      ISQDerivedQuantity is subClassOf DerivedQuantity (from ../Ontologies/emmo.ttl)\n",
            "      ISQDerivedQuantity is subClassOf InternationalSystemOfQuantity (from ../Ontologies/emmo.ttl)\n",
            "        InternationalSystemOfQuantity is subClassOf StandardizedPhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "          StandardizedPhysicalQuantity is subClassOf PhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "            PhysicalQuantity is subClassOf None (from ../Ontologies/emmo.ttl)\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = s.lower()\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def get_class_label(g, cls):\n",
        "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "    return labels[0] if labels else None\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            found_class_labels.add(normalized_label)\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label)])\n",
        "\n",
        "    return data, relations, found_class_labels\n",
        "\n",
        "def filter_relations(all_relations, initial_class_names_to_check):\n",
        "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
        "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
        "\n",
        "def print_hierarchy(class_name, relations, ontology_files, depth=0):\n",
        "    for relation in relations:\n",
        "        if normalize_string(relation[2]) == normalize_string(class_name):\n",
        "            indent = '  ' * depth\n",
        "            print(f\"{indent}{class_name} is {relation[3]} {relation[5]} (from {relation[0]})\")\n",
        "            print_hierarchy(relation[5], relations, ontology_files, depth + 1)\n",
        "\n",
        "\n",
        "class_output_file = \"ontology_classes.csv\"\n",
        "relations_output_file = \"ontology_relations.csv\"\n",
        "\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "\n",
        "class_names_to_check = initial_class_names_to_check\n",
        "\n",
        "max_iterations = 2\n",
        "iteration_count = 0\n",
        "\n",
        "while class_names_to_check and iteration_count < max_iterations:\n",
        "    iteration_count += 1\n",
        "    new_data = []\n",
        "    new_relations = []\n",
        "    new_found_class_labels = set()\n",
        "\n",
        "    for ontology_file in ontology_files:\n",
        "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "        new_data.extend(file_data)\n",
        "        new_relations.extend(file_relations)\n",
        "        new_found_class_labels.update(found_class_labels)\n",
        "\n",
        "    all_data.extend(new_data)\n",
        "    all_relations.extend(new_relations)\n",
        "    all_found_class_labels.update(new_found_class_labels)\n",
        "\n",
        "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
        "\n",
        "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
        "\n",
        "filtered_data = [row for row in all_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(filtered_data)\n",
        "\n",
        "filtered_relations = filter_relations(all_relations, initial_class_names_to_check)\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Subject Label\", \"Relation\", \"Object Class URI\", \"Object Label\"])\n",
        "    writer.writerows(filtered_relations)\n",
        "\n",
        "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
        "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
        "\n",
        "print(\"\\nInitial class names found in the output:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")\n",
        "\n",
        "print(\"\\nClass relationships for the initial specified classes and their hierarchy:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    print_hierarchy(normalized_class_name, all_relations, ontology_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Class relationships for the initial specified classes and their hierarchy:\n",
            "softwareagent is subClassOf Agent (from ../Ontologies/owlapi.xrdf)\n",
            "  Agent is subClassOf None (from ../Ontologies/nfdicore_2.ttl)\n",
            "  Agent is subClassOf Participant (from ../Ontologies/emmo.ttl)\n",
            "    Participant is subClassOf Continuant (from ../Ontologies/emmo.ttl)\n",
            "      Continuant is subClassOf entity (from ../Ontologies/bfo.owl)\n",
            "        entity is subClassOf None (from ../Ontologies/bfo.owl)\n",
            "        entity is subClassOf None (from ../Ontologies/owlapi.xrdf)\n",
            "    Participant is subClassOf HolisticSpatialPart (from ../Ontologies/emmo.ttl)\n",
            "  Agent is subClassOf None (from ../Ontologies/owlapi.xrdf)\n",
            "ampereperjoule is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf SICoherentDerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "  SICoherentDerivedUnit is subClassOf DerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf ElectricCurrentPerUnitEnergyUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricCurrentPerUnitEnergyUnit is subClassOf SIDimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "    SIDimensionalUnit is subClassOf DimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricCurrentPerUnitEnergyUnit is equivalentClass None (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf SICoherentDerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "  SICoherentDerivedUnit is subClassOf DerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "ampereperjoule is subClassOf ElectricCurrentPerUnitEnergyUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricCurrentPerUnitEnergyUnit is subClassOf SIDimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "    SIDimensionalUnit is subClassOf DimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricCurrentPerUnitEnergyUnit is equivalentClass None (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf SINonCoherentDerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "  SINonCoherentDerivedUnit is subClassOf DerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf ElectricDisplacementFieldUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricDisplacementFieldUnit is subClassOf SIDimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "    SIDimensionalUnit is subClassOf DimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricDisplacementFieldUnit is equivalentClass None (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf SINonCoherentDerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "  SINonCoherentDerivedUnit is subClassOf DerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "coulombpersquaremillimetre is subClassOf ElectricDisplacementFieldUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricDisplacementFieldUnit is subClassOf SIDimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "    SIDimensionalUnit is subClassOf DimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricDisplacementFieldUnit is equivalentClass None (from ../Ontologies/emmo.ttl)\n",
            "academicdiscipline is subClassOf None (from ../Ontologies/nfdicore_2.ttl)\n",
            "compression is subClassOf Viscoelastic Property (from ../Ontologies/materialsmine.ttl)\n",
            "  Viscoelastic Property is subClassOf Amount (from ../Ontologies/materialsmine.ttl)\n",
            "    Amount is subClassOf None (from ../Ontologies/materialsmine.ttl)\n",
            "poissonsratio is subClassOf Tensile Property (from ../Ontologies/materialsmine.ttl)\n",
            "  Tensile Property is subClassOf Mechanical Property (from ../Ontologies/materialsmine.ttl)\n",
            "    Mechanical Property is subClassOf Amount (from ../Ontologies/materialsmine.ttl)\n",
            "      Amount is subClassOf None (from ../Ontologies/materialsmine.ttl)\n",
            "poissonsratio is subClassOf MechanicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "  MechanicalQuantity is subClassOf ISO80000Categorised (from ../Ontologies/emmo.ttl)\n",
            "    ISO80000Categorised is subClassOf CategorizedPhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "      CategorizedPhysicalQuantity is subClassOf PhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "        PhysicalQuantity is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "poissonsratio is subClassOf RatioQuantity (from ../Ontologies/emmo.ttl)\n",
            "  RatioQuantity is subClassOf ISQDimensionlessQuantity (from ../Ontologies/emmo.ttl)\n",
            "    ISQDimensionlessQuantity is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "    ISQDimensionlessQuantity is subClassOf ISQDerivedQuantity (from ../Ontologies/emmo.ttl)\n",
            "      ISQDerivedQuantity is subClassOf DerivedQuantity (from ../Ontologies/emmo.ttl)\n",
            "      ISQDerivedQuantity is subClassOf InternationalSystemOfQuantity (from ../Ontologies/emmo.ttl)\n",
            "        InternationalSystemOfQuantity is subClassOf StandardizedPhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "          StandardizedPhysicalQuantity is subClassOf PhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "            PhysicalQuantity is subClassOf None (from ../Ontologies/emmo.ttl)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nClass relationships for the initial specified classes and their hierarchy:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    print_hierarchy(normalized_class_name, all_relations, ontology_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered class data has been saved to ontology_classes.csv\n",
            "Filtered class relations have been saved to ontology_relations.csv\n",
            "\n",
            "Initial class names found in the output:\n",
            "Class 'SoftwareAgent' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'AmperePerJoule' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'CoulombPerSquareMilliMetre' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'AcademicDiscipline' found in:\n",
            "- ../Ontologies/nfdicore_2.ttl\n",
            "Class 'nfdi' not found in the output.\n",
            "Class 'CompressioN' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "Class 'Poissons Ratio' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "- ../Ontologies/emmo.ttl\n",
            "\n",
            "Saving class hierarchy to CSV file:\n",
            "Class hierarchy has been saved to class_hierarchy.csv\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = s.lower()\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def get_class_label(g, cls):\n",
        "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "    return labels[0] if labels else None\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            found_class_labels.add(normalized_label)\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label)])\n",
        "\n",
        "    return data, relations, found_class_labels\n",
        "\n",
        "def filter_relations(all_relations, initial_class_names_to_check):\n",
        "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
        "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
        "\n",
        "def print_hierarchy(class_name, relations, ontology_files, output_file):\n",
        "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Class Name\", \"Relation Type\", \"Related Class\", \"From File\"])\n",
        "\n",
        "        for relation in relations:\n",
        "            if normalize_string(relation[2]) == normalize_string(class_name):\n",
        "                writer.writerow([relation[2], relation[3], relation[5], relation[0]])\n",
        "                print_hierarchy(relation[5], relations, ontology_files, output_file)\n",
        "\n",
        "output_hierarchy_file = \"class_hierarchy.csv\"\n",
        "\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "\n",
        "class_names_to_check = initial_class_names_to_check\n",
        "\n",
        "max_iterations = 2\n",
        "iteration_count = 0\n",
        "\n",
        "while class_names_to_check and iteration_count < max_iterations:\n",
        "    iteration_count += 1\n",
        "    new_data = []\n",
        "    new_relations = []\n",
        "    new_found_class_labels = set()\n",
        "\n",
        "    for ontology_file in ontology_files:\n",
        "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "        new_data.extend(file_data)\n",
        "        new_relations.extend(file_relations)\n",
        "        new_found_class_labels.update(found_class_labels)\n",
        "\n",
        "    all_data.extend(new_data)\n",
        "    all_relations.extend(new_relations)\n",
        "    all_found_class_labels.update(new_found_class_labels)\n",
        "\n",
        "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
        "\n",
        "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
        "\n",
        "filtered_data = [row for row in all_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(filtered_data)\n",
        "\n",
        "filtered_relations = filter_relations(all_relations, initial_class_names_to_check)\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Subject Label\", \"Relation\", \"Object Class URI\", \"Object Label\"])\n",
        "    writer.writerows(filtered_relations)\n",
        "\n",
        "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
        "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
        "\n",
        "print(\"\\nInitial class names found in the output:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")\n",
        "\n",
        "print(\"\\nSaving class hierarchy to CSV file:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    print_hierarchy(normalized_class_name, all_relations, ontology_files, output_hierarchy_file)\n",
        "\n",
        "print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Filtered class data has been saved to ontology_classes.csv\n",
            "Filtered class relations have been saved to ontology_relations.csv\n",
            "\n",
            "Initial class names found in the output:\n",
            "Class 'SoftwareAgent' found in:\n",
            "- ../Ontologies/owlapi.xrdf\n",
            "Class 'AmperePerJoule' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'CoulombPerSquareMilliMetre' found in:\n",
            "- ../Ontologies/emmo.ttl\n",
            "Class 'AcademicDiscipline' found in:\n",
            "- ../Ontologies/nfdicore_2.ttl\n",
            "Class 'nfdi' not found in the output.\n",
            "Class 'CompressioN' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "Class 'Poissons Ratio' found in:\n",
            "- ../Ontologies/materialsmine.ttl\n",
            "- ../Ontologies/emmo.ttl\n",
            "\n",
            "Saving class hierarchy to CSV file:\n",
            "SoftwareAgent is subClassOf Agent (from ../Ontologies/owlapi.xrdf)\n",
            "  agent is subClassOf None (from ../Ontologies/nfdicore_2.ttl)\n",
            "  Agent is subClassOf Participant (from ../Ontologies/emmo.ttl)\n",
            "    Participant is subClassOf Continuant (from ../Ontologies/emmo.ttl)\n",
            "      continuant is subClassOf entity (from ../Ontologies/bfo.owl)\n",
            "        entity is subClassOf None (from ../Ontologies/bfo.owl)\n",
            "        Entity is subClassOf None (from ../Ontologies/owlapi.xrdf)\n",
            "    Participant is subClassOf HolisticSpatialPart (from ../Ontologies/emmo.ttl)\n",
            "  Agent is subClassOf None (from ../Ontologies/owlapi.xrdf)\n",
            "Ampere per Joule is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "Ampere per Joule is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "Ampere per Joule is subClassOf SICoherentDerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "  SICoherentDerivedUnit is subClassOf DerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "Ampere per Joule is subClassOf ElectricCurrentPerUnitEnergyUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricCurrentPerUnitEnergyUnit is subClassOf SIDimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "    SIDimensionalUnit is subClassOf DimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricCurrentPerUnitEnergyUnit is equivalentClass None (from ../Ontologies/emmo.ttl)\n",
            "AmperePerJoule is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "AmperePerJoule is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "AmperePerJoule is subClassOf SICoherentDerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "  SICoherentDerivedUnit is subClassOf DerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "AmperePerJoule is subClassOf ElectricCurrentPerUnitEnergyUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricCurrentPerUnitEnergyUnit is subClassOf SIDimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "    SIDimensionalUnit is subClassOf DimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricCurrentPerUnitEnergyUnit is equivalentClass None (from ../Ontologies/emmo.ttl)\n",
            "Coulomb Per Square Millimetre is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "Coulomb Per Square Millimetre is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "Coulomb Per Square Millimetre is subClassOf SINonCoherentDerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "  SINonCoherentDerivedUnit is subClassOf DerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "Coulomb Per Square Millimetre is subClassOf ElectricDisplacementFieldUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricDisplacementFieldUnit is subClassOf SIDimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "    SIDimensionalUnit is subClassOf DimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricDisplacementFieldUnit is equivalentClass None (from ../Ontologies/emmo.ttl)\n",
            "CoulombPerSquareMilliMetre is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "CoulombPerSquareMilliMetre is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "CoulombPerSquareMilliMetre is subClassOf SINonCoherentDerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "  SINonCoherentDerivedUnit is subClassOf DerivedUnit (from ../Ontologies/emmo.ttl)\n",
            "CoulombPerSquareMilliMetre is subClassOf ElectricDisplacementFieldUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricDisplacementFieldUnit is subClassOf SIDimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "    SIDimensionalUnit is subClassOf DimensionalUnit (from ../Ontologies/emmo.ttl)\n",
            "  ElectricDisplacementFieldUnit is equivalentClass None (from ../Ontologies/emmo.ttl)\n",
            "academic discipline is subClassOf None (from ../Ontologies/nfdicore_2.ttl)\n",
            "Compression is subClassOf Viscoelastic Property (from ../Ontologies/materialsmine.ttl)\n",
            "  Viscoelastic Property is subClassOf Amount (from ../Ontologies/materialsmine.ttl)\n",
            "    Amount is subClassOf None (from ../Ontologies/materialsmine.ttl)\n",
            "Poissons Ratio is subClassOf Tensile Property (from ../Ontologies/materialsmine.ttl)\n",
            "  Tensile Property is subClassOf Mechanical Property (from ../Ontologies/materialsmine.ttl)\n",
            "    Mechanical Property is subClassOf Amount (from ../Ontologies/materialsmine.ttl)\n",
            "      Amount is subClassOf None (from ../Ontologies/materialsmine.ttl)\n",
            "PoissonsRatio is subClassOf MechanicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "  MechanicalQuantity is subClassOf ISO80000Categorised (from ../Ontologies/emmo.ttl)\n",
            "    ISO80000Categorised is subClassOf CategorizedPhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "      CategorizedPhysicalQuantity is subClassOf PhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "        PhysicalQuantity is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "PoissonsRatio is subClassOf RatioQuantity (from ../Ontologies/emmo.ttl)\n",
            "  RatioQuantity is subClassOf ISQDimensionlessQuantity (from ../Ontologies/emmo.ttl)\n",
            "    ISQDimensionlessQuantity is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "    ISQDimensionlessQuantity is subClassOf ISQDerivedQuantity (from ../Ontologies/emmo.ttl)\n",
            "      ISQDerivedQuantity is subClassOf DerivedQuantity (from ../Ontologies/emmo.ttl)\n",
            "      ISQDerivedQuantity is subClassOf InternationalSystemOfQuantity (from ../Ontologies/emmo.ttl)\n",
            "        InternationalSystemOfQuantity is subClassOf StandardizedPhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "          StandardizedPhysicalQuantity is subClassOf PhysicalQuantity (from ../Ontologies/emmo.ttl)\n",
            "            PhysicalQuantity is subClassOf None (from ../Ontologies/emmo.ttl)\n",
            "Class hierarchy has been saved to class_hierarchy.csv\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import re\n",
        "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace\n",
        "\n",
        "def normalize_string(s):\n",
        "    s = s.lower()\n",
        "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
        "    s = s.replace('...', '')\n",
        "    return s\n",
        "\n",
        "def get_class_label(g, cls):\n",
        "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "    return labels[0] if labels else None\n",
        "\n",
        "def load_and_collect_classes_and_relations(file_path, class_names_to_check):\n",
        "    if file_path.endswith('.ttl'):\n",
        "        file_format = 'ttl'\n",
        "    elif file_path.endswith('.owl'):\n",
        "        file_format = 'xml'\n",
        "    elif file_path.endswith('.xrdf'):\n",
        "        file_format = 'xml'\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
        "    \n",
        "    g = Graph()\n",
        "    g.parse(file_path, format=file_format)\n",
        "\n",
        "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
        "\n",
        "    ex = Namespace(\"http://example.org/ontology/\")\n",
        "\n",
        "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
        "\n",
        "    data = []\n",
        "    relations = []\n",
        "    found_class_labels = set()\n",
        "    for cls in classes:\n",
        "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
        "        for label in labels:\n",
        "            normalized_label = normalize_string(label)\n",
        "            found_class_labels.add(normalized_label)\n",
        "            if normalized_label in normalized_class_names_to_check:\n",
        "                data.append([file_path, str(cls), str(label)])\n",
        "                for obj in g.objects(cls, RDFS.subClassOf):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label)])\n",
        "                for obj in g.objects(cls, OWL.equivalentClass):\n",
        "                    obj_label = get_class_label(g, obj)\n",
        "                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label)])\n",
        "\n",
        "    return data, relations, found_class_labels\n",
        "\n",
        "def filter_relations(all_relations, initial_class_names_to_check):\n",
        "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
        "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
        "\n",
        "def print_hierarchy(class_name, relations, ontology_files, output_file):\n",
        "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.writer(file)\n",
        "        writer.writerow([\"Class Name\", \"Relation Type\", \"Related Class\", \"From File\"])\n",
        "\n",
        "        def recursive_print(class_name, depth=0):\n",
        "            for relation in relations:\n",
        "                if normalize_string(relation[2]) == normalize_string(class_name):\n",
        "                    writer.writerow([relation[2], relation[3], relation[5], relation[0]])\n",
        "                    indent = '  ' * depth\n",
        "                    print(f\"{indent}{relation[2]} is {relation[3]} {relation[5]} (from {relation[0]})\")\n",
        "                    recursive_print(relation[5], depth + 1)\n",
        "\n",
        "        recursive_print(class_name)\n",
        "\n",
        "output_hierarchy_file = \"class_hierarchy.csv\"\n",
        "\n",
        "all_data = []\n",
        "all_relations = []\n",
        "all_found_class_labels = set()\n",
        "\n",
        "class_names_to_check = initial_class_names_to_check\n",
        "\n",
        "max_iterations = 2\n",
        "iteration_count = 0\n",
        "\n",
        "while class_names_to_check and iteration_count < max_iterations:\n",
        "    iteration_count += 1\n",
        "    new_data = []\n",
        "    new_relations = []\n",
        "    new_found_class_labels = set()\n",
        "\n",
        "    for ontology_file in ontology_files:\n",
        "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check)\n",
        "        new_data.extend(file_data)\n",
        "        new_relations.extend(file_relations)\n",
        "        new_found_class_labels.update(found_class_labels)\n",
        "\n",
        "    all_data.extend(new_data)\n",
        "    all_relations.extend(new_relations)\n",
        "    all_found_class_labels.update(new_found_class_labels)\n",
        "\n",
        "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
        "\n",
        "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
        "\n",
        "filtered_data = [row for row in all_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
        "with open(class_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Class URI\", \"Label\"])\n",
        "    writer.writerows(filtered_data)\n",
        "\n",
        "filtered_relations = filter_relations(all_relations, initial_class_names_to_check)\n",
        "with open(relations_output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"File\", \"Subject Class URI\", \"Subject Label\", \"Relation\", \"Object Class URI\", \"Object Label\"])\n",
        "    writer.writerows(filtered_relations)\n",
        "\n",
        "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
        "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
        "\n",
        "print(\"\\nInitial class names found in the output:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    found = False\n",
        "    for label in all_found_class_labels:\n",
        "        if normalized_class_name in label:\n",
        "            found = True\n",
        "            print(f\"Class '{class_name}' found in:\")\n",
        "            for ontology_file in ontology_files:\n",
        "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check)\n",
        "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
        "                if normalized_class_name in normalized_labels:\n",
        "                    print(f\"- {ontology_file}\")\n",
        "            break\n",
        "    if not found:\n",
        "        print(f\"Class '{class_name}' not found in the output.\")\n",
        "\n",
        "print(\"\\nSaving class hierarchy to CSV file:\")\n",
        "for class_name in initial_class_names_to_check:\n",
        "    normalized_class_name = normalize_string(class_name)\n",
        "    print_hierarchy(normalized_class_name, all_relations, ontology_files, output_hierarchy_file)\n",
        "\n",
        "print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "01 - DataCollection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('3.8.13')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
