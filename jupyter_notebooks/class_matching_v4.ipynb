{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Starting v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class names to check\n",
    "initial_class_names_to_check = [ 'Compression','AmperePerJoule','nfdi','stress', 'Advertiser+content_Article', 'Tensiletest']\n",
    "# initial_class_names_to_check = [ 'TermVariant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of ontology files to process\n",
    "ontology_files = [\n",
    "    # \"../Ontologies/materialsmine.ttl\", ### is not complete!\n",
    "    \"../Ontologies/materialsmine_converted.ttl\",\n",
    "    \"../Ontologies/pmdco_core.ttl\",\n",
    "    \"../Ontologies/nfdicore_2.ttl\",\n",
    "    # \"../Ontologies/bfo.owl\", #### using this ---->  long time to proccess!\n",
    "    # \"../Ontologies/emmo.ttl\",\n",
    "    # \"../Ontologies/owlapi.xrdf\",\n",
    "    # \"../Ontologies/schemaorg.owl\",\n",
    "    # \"../Ontologies/MaterialsMine.xrdf\",\n",
    "    # '../Ontologies/emmo.owl', ### has problem of reading file\n",
    "    # \"../Ontologies/Physical_Activity_Ontology_V2.owl\",\n",
    "    # \"../Ontologies/Physical_Activity_Ontology_V2.xrdf\",\n",
    "    # \"../Ontologies/oboe.owl\",\n",
    "    # Add more file paths as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace, URIRef, Literal, BNode\n",
    "\n",
    "\n",
    "directory = '.'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        os.remove(os.path.join(directory, filename))\n",
    "\n",
    "\n",
    "# Define namespaces (assuming these are already defined in your script)\n",
    "ex = Namespace(\"http://example.org/ontology/\")\n",
    "sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "materialsmine = Namespace(\"http://materialsmine.org/ns/\")\n",
    "bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "xml = Namespace(\"http://www.w3.org/XML/1998/namespace\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "isPartOf = dcterms.isPartOf\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
    "    s = s.replace('...', '')\n",
    "    return s\n",
    "\n",
    "def get_class_label(g, cls):\n",
    "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "    return labels[0] if labels else None\n",
    "\n",
    "def get_class_descriptions(g, cls):\n",
    "    descriptions = list(g.objects(cls, DCTERMS.description)) + list(g.objects(cls, SKOS.definition)) + list(g.objects(cls, RDFS.comment))\n",
    "    return \" \".join([str(desc) for desc in descriptions if desc is not None]) if descriptions else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_complex_expression_label(g, node):\n",
    "    if (node, RDF.type, OWL.Restriction) in g:\n",
    "        prop = list(g.objects(node, OWL.onProperty))\n",
    "        val = list(g.objects(node, OWL.someValuesFrom))\n",
    "        if prop and val:\n",
    "            prop_label = get_class_label(g, prop[0])\n",
    "            val_label = get_class_label(g, val[0])\n",
    "            return f\"Restriction on {prop_label} some {val_label}\"\n",
    "    elif (node, RDF.type, OWL.Class) in g:\n",
    "        intersection = list(g.objects(node, OWL.intersectionOf))\n",
    "        if intersection:\n",
    "            components = []\n",
    "            for item in g.items(intersection[0]):\n",
    "                if isinstance(item, URIRef):\n",
    "                    component_label = get_class_label(g, item)\n",
    "                    if component_label:\n",
    "                        components.append(component_label)\n",
    "                elif isinstance(item, BNode):\n",
    "                    restriction_label = get_complex_expression_label(g, item)\n",
    "                    if restriction_label:\n",
    "                        components.append(restriction_label)\n",
    "            if components:\n",
    "                return f\"Intersection of {' and '.join(components)}\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "    if file_path.endswith('.ttl'):\n",
    "        file_format = 'ttl'\n",
    "    elif file_path.endswith('.owl'):\n",
    "        file_format = 'xml'\n",
    "    elif file_path.endswith('.xrdf'):\n",
    "        file_format = 'xml'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "    \n",
    "    g.parse(file_path, format=file_format)\n",
    "\n",
    "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "    data = []\n",
    "    relations = []\n",
    "    found_class_labels = set()\n",
    "\n",
    "    for cls in classes:\n",
    "        if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "            labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "            description = get_class_descriptions(g, cls)\n",
    "\n",
    "            for label in labels:\n",
    "                if label is not None:\n",
    "                    normalized_label = normalize_string(label)\n",
    "                    found_class_labels.add(normalized_label)\n",
    "\n",
    "                    if normalized_label in normalized_class_names_to_check:\n",
    "                        # Check if already processed in this iteration\n",
    "                        if str(cls) not in processed_classes:\n",
    "                            processed_classes.add(str(cls))\n",
    "                            data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, RDFS.subClassOf):\n",
    "                            if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, OWL.equivalentClass):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                            else:\n",
    "                                # Handle blank nodes for equivalentClass\n",
    "                                obj_label = get_complex_expression_label(g, obj)\n",
    "                                obj_description = \"Complex class expression\"\n",
    "\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "            # Check for owl:intersectionOf\n",
    "            intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "            for intersection in intersections:\n",
    "                if isinstance(intersection, BNode):\n",
    "                    components = []\n",
    "                    for item in g.items(intersection):\n",
    "                        if isinstance(item, URIRef):\n",
    "                            component_label = get_class_label(g, item)\n",
    "                            if component_label:\n",
    "                                components.append(component_label)\n",
    "                        elif isinstance(item, BNode):\n",
    "                            restriction_labels = []\n",
    "                            for restriction_item in g.items(item):\n",
    "                                if isinstance(restriction_item, BNode):\n",
    "                                    restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                    if restriction_label:\n",
    "                                        restriction_labels.append(restriction_label)\n",
    "                            if restriction_labels:\n",
    "                                components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                    \n",
    "                    if components:\n",
    "                        data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])\n",
    "\n",
    "    return data, relations, found_class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_relations(all_relations, initial_class_names_to_check):\n",
    "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hierarchy(class_name, relations, g, writer):\n",
    "    def recursive_print(class_name, depth=0):\n",
    "        for relation in relations:\n",
    "            if normalize_string(relation[2]) == normalize_string(class_name):\n",
    "                subject_description = get_class_descriptions(g, URIRef(relation[1]))\n",
    "                object_description = get_class_descriptions(g, URIRef(relation[4]))\n",
    "                writer.writerow([relation[1], relation[2], subject_description if subject_description is not None else \"\", relation[3], relation[4], relation[5], object_description if object_description is not None else \"\", relation[0]])\n",
    "                indent = '  ' * depth\n",
    "                print(f\"{indent}{relation[1]} {relation[2]} is {relation[3]} {relation[4]} {relation[5]} (from {relation[0]})\")\n",
    "                recursive_print(relation[5], depth + 1)\n",
    "\n",
    "    recursive_print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "class_output_file = \"ontology_classes.csv\"\n",
    "relations_output_file = \"ontology_relations.csv\"\n",
    "\n",
    "all_data = []\n",
    "all_relations = []\n",
    "all_found_class_labels = set()\n",
    "\n",
    "class_names_to_check = initial_class_names_to_check\n",
    "\n",
    "max_iterations = 2\n",
    "iteration_count = 0\n",
    "g = Graph()\n",
    "processed_classes = set()\n",
    "processed_relations = set()\n",
    "last_class_name_written = None  # Track the last class name written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "while class_names_to_check and iteration_count < max_iterations:\n",
    "    iteration_count += 1\n",
    "    new_data = []\n",
    "    new_relations = []\n",
    "    new_found_class_labels = set()\n",
    "\n",
    "    for ontology_file in ontology_files:\n",
    "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check, g, processed_classes, processed_relations)\n",
    "        new_data.extend(file_data)\n",
    "        new_relations.extend(file_relations)\n",
    "        new_found_class_labels.update(found_class_labels)\n",
    "\n",
    "    all_data.extend(new_data)\n",
    "    all_relations.extend(new_relations)\n",
    "    all_found_class_labels.update(new_found_class_labels)\n",
    "\n",
    "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
    "\n",
    "    # Filter and save class data\n",
    "    filtered_data = [row for row in new_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
    "    with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_data:\n",
    "            current_class_name = filtered_data[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_data)\n",
    "\n",
    "    # Filter and save class relations\n",
    "    filtered_relations = filter_relations(new_relations, initial_class_names_to_check)\n",
    "    with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_relations:\n",
    "            current_class_name = filtered_relations[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered class data has been saved to ontology_classes.csv\n",
      "Filtered class relations have been saved to ontology_relations.csv\n",
      "\n",
      "Initial class names found in the output:\n",
      "Class 'Compression' found in:\n",
      "- ../Ontologies/materialsmine_converted.ttl\n",
      "- ../Ontologies/pmdco_core.ttl\n",
      "- ../Ontologies/nfdicore_2.ttl\n",
      "Class 'AmperePerJoule' not found in the output.\n",
      "Class 'nfdi' not found in the output.\n",
      "Class 'stress' found in:\n",
      "- ../Ontologies/materialsmine_converted.ttl\n",
      "- ../Ontologies/pmdco_core.ttl\n",
      "- ../Ontologies/nfdicore_2.ttl\n",
      "Class 'Advertiser+content_Article' not found in the output.\n",
      "Class 'Tensiletest' found in:\n",
      "- ../Ontologies/materialsmine_converted.ttl\n",
      "- ../Ontologies/pmdco_core.ttl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ../Ontologies/nfdicore_2.ttl\n",
      "\n",
      "Saving class hierarchy to CSV file:\n",
      "http://materialsmine.org/ns/Compression Compression is subClassOf http://materialsmine.org/ns/ViscoelasticProperty Viscoelastic Property (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://materialsmine.org/ns/ViscoelasticProperty Viscoelastic Property is subClassOf http://semanticscience.org/resource/Quantity Amount (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/Quantity Amount is subClassOf http://semanticscience.org/resource/MeasurementValue measurement value (from ../Ontologies/materialsmine_converted.ttl)\n",
      "      http://semanticscience.org/resource/MeasurementValue measurement value is subClassOf http://semanticscience.org/resource/Number number (from ../Ontologies/materialsmine_converted.ttl)\n",
      "        http://semanticscience.org/resource/Number number is subClassOf http://semanticscience.org/resource/Scalar scalar (from ../Ontologies/materialsmine_converted.ttl)\n",
      "          http://semanticscience.org/resource/Scalar scalar is subClassOf http://semanticscience.org/resource/Tensor tensor (from ../Ontologies/materialsmine_converted.ttl)\n",
      "            http://semanticscience.org/resource/Tensor tensor is subClassOf http://semanticscience.org/resource/MathematicalEntity mathematical entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "              http://semanticscience.org/resource/MathematicalEntity mathematical entity is subClassOf http://semanticscience.org/resource/InformationContentEntity information content entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                http://semanticscience.org/resource/InformationContentEntity information content entity is subClassOf http://semanticscience.org/resource/Object object (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                  https://w3id.org/pmd/co/Object Object is subClassOf http://www.w3.org/ns/prov#Entity  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                  http://semanticscience.org/resource/Object object is subClassOf http://semanticscience.org/resource/Entity entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                    http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/Quantity Amount is equivalentClass Complex class expression  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/Quantity Amount is equivalentClass Complex class expression  (from ../Ontologies/materialsmine_converted.ttl)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://materialsmine.org/ns/Stress Stress is subClassOf http://materialsmine.org/ns/MechanicalProperty Mechanical Property (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://materialsmine.org/ns/MechanicalProperty Mechanical Property is subClassOf http://semanticscience.org/resource/Quantity Amount (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/Quantity Amount is subClassOf http://semanticscience.org/resource/MeasurementValue measurement value (from ../Ontologies/materialsmine_converted.ttl)\n",
      "      http://semanticscience.org/resource/MeasurementValue measurement value is subClassOf http://semanticscience.org/resource/Number number (from ../Ontologies/materialsmine_converted.ttl)\n",
      "        http://semanticscience.org/resource/Number number is subClassOf http://semanticscience.org/resource/Scalar scalar (from ../Ontologies/materialsmine_converted.ttl)\n",
      "          http://semanticscience.org/resource/Scalar scalar is subClassOf http://semanticscience.org/resource/Tensor tensor (from ../Ontologies/materialsmine_converted.ttl)\n",
      "            http://semanticscience.org/resource/Tensor tensor is subClassOf http://semanticscience.org/resource/MathematicalEntity mathematical entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "              http://semanticscience.org/resource/MathematicalEntity mathematical entity is subClassOf http://semanticscience.org/resource/InformationContentEntity information content entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                http://semanticscience.org/resource/InformationContentEntity information content entity is subClassOf http://semanticscience.org/resource/Object object (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                  https://w3id.org/pmd/co/Object Object is subClassOf http://www.w3.org/ns/prov#Entity  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                  http://semanticscience.org/resource/Object object is subClassOf http://semanticscience.org/resource/Entity entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                    http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/Quantity Amount is equivalentClass Complex class expression  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/Quantity Amount is equivalentClass Complex class expression  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "https://w3id.org/pmd/co/Stress Stress is subClassOf https://w3id.org/pmd/co/ValueObject Value Object (from ../Ontologies/pmdco_core.ttl)\n",
      "  https://w3id.org/pmd/co/ValueObject Value Object is subClassOf http://www.w3.org/ns/prov#Entity  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  https://w3id.org/pmd/co/ValueObject Value Object is equivalentClass Complex class expression  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  https://w3id.org/pmd/co/ValueObject Value Object is equivalentClass Complex class expression  (from ../Ontologies/pmdco_core.ttl)\n",
      "https://w3id.org/pmd/co/Stress Stress is equivalentClass Complex class expression Intersection of Restriction on relates to some Area and Restriction on relates to some Force (from ../Ontologies/pmdco_core.ttl)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/pmd/co/TensileTest Tensile Test is subClassOf https://w3id.org/pmd/co/MechanicalTestingProcess Mechanical Testing Process (from ../Ontologies/pmdco_core.ttl)\n",
      "  https://w3id.org/pmd/co/MechanicalTestingProcess Mechanical Testing Process is subClassOf https://w3id.org/pmd/co/AnalysingProcess Analyseprozess (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    https://w3id.org/pmd/co/AnalysingProcess Analyseprozess is subClassOf https://w3id.org/pmd/co/Process Process (from ../Ontologies/materialsmine_converted.ttl)\n",
      "      http://semanticscience.org/resource/Process process is subClassOf http://semanticscience.org/resource/Entity entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "        http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "      https://w3id.org/pmd/co/Process Process is subClassOf http://www.w3.org/ns/prov#Activity  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "https://w3id.org/pmd/co/TensileTest Tensile Test is equivalentClass Complex class expression Restriction on has participant some Tensile Testing Machine (from ../Ontologies/pmdco_core.ttl)\n",
      "https://w3id.org/pmd/co/TensileTest Tensile Test is equivalentClass Complex class expression Restriction on has participant some Prüfkörper (from ../Ontologies/pmdco_core.ttl)\n",
      "Class hierarchy has been saved to class_hierarchy.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
    "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
    "\n",
    "print(\"\\nInitial class names found in the output:\")\n",
    "for class_name in initial_class_names_to_check:\n",
    "    normalized_class_name = normalize_string(class_name)\n",
    "    found = False\n",
    "    for label in all_found_class_labels:\n",
    "        if normalized_class_name in label:\n",
    "            found = True\n",
    "            print(f\"Class '{class_name}' found in:\")\n",
    "            for ontology_file in ontology_files:\n",
    "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check, g, processed_classes, processed_relations)\n",
    "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
    "                if normalized_class_name in normalized_labels:\n",
    "                    print(f\"- {ontology_file}\")\n",
    "            break\n",
    "    if not found:\n",
    "        print(f\"Class '{class_name}' not found in the output.\")\n",
    "\n",
    "print(\"\\nSaving class hierarchy to CSV file:\")\n",
    "with open(output_hierarchy_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Class URI\", \"Class Name\", \"Class Description\", \"Relation Type\", \"Related Class URI\", \"Related Class Name\", \"Related Class Description\", \"File\"])\n",
    "    for class_name in initial_class_names_to_check:\n",
    "        normalized_class_name = normalize_string(class_name)\n",
    "        print_hierarchy(normalized_class_name, all_relations, g, writer)\n",
    "\n",
    "print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n",
    "\n",
    "def save_intersection_info_to_csv(data, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Inside your main loop where you process ontology files:\n",
    "intersection_data = [row for row in all_data if row[3].startswith(\"Intersection of\")]\n",
    "save_intersection_info_to_csv(intersection_data, \"intersection_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
