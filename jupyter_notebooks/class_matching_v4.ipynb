{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Starting v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace, URIRef, Literal, BNode\n",
    "\n",
    "\n",
    "directory = '.'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        os.remove(os.path.join(directory, filename))\n",
    "\n",
    "\n",
    "# Define namespaces (assuming these are already defined in your script)\n",
    "ex = Namespace(\"http://example.org/ontology/\")\n",
    "sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "materialsmine = Namespace(\"http://materialsmine.org/ns/\")\n",
    "bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "xml = Namespace(\"http://www.w3.org/XML/1998/namespace\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "isPartOf = dcterms.isPartOf\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
    "    s = s.replace('...', '')\n",
    "    return s\n",
    "\n",
    "def get_class_label(g, cls):\n",
    "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "    return labels[0] if labels else None\n",
    "\n",
    "def get_class_descriptions(g, cls):\n",
    "    descriptions = list(g.objects(cls, DCTERMS.description)) + list(g.objects(cls, SKOS.definition)) + list(g.objects(cls, RDFS.comment))\n",
    "    return \" \".join([str(desc) for desc in descriptions if desc is not None]) if descriptions else None\n",
    "\n",
    "\n",
    "def get_complex_expression_label(g, node):\n",
    "    if (node, RDF.type, OWL.Restriction) in g:\n",
    "        prop = list(g.objects(node, OWL.onProperty))\n",
    "        val = list(g.objects(node, OWL.someValuesFrom))\n",
    "        if prop and val:\n",
    "            prop_label = get_class_label(g, prop[0])\n",
    "            val_label = get_class_label(g, val[0])\n",
    "            return f\"Restriction on {prop_label} some {val_label}\"\n",
    "    elif (node, RDF.type, OWL.Class) in g:\n",
    "        intersection = list(g.objects(node, OWL.intersectionOf))\n",
    "        if intersection:\n",
    "            components = []\n",
    "            for item in g.items(intersection[0]):\n",
    "                if isinstance(item, URIRef):\n",
    "                    component_label = get_class_label(g, item)\n",
    "                    if component_label:\n",
    "                        components.append(component_label)\n",
    "                elif isinstance(item, BNode):\n",
    "                    restriction_label = get_complex_expression_label(g, item)\n",
    "                    if restriction_label:\n",
    "                        components.append(restriction_label)\n",
    "            if components:\n",
    "                return f\"Intersection of {' and '.join(components)}\"\n",
    "    return None\n",
    "\n",
    "def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "    if file_path.endswith('.ttl'):\n",
    "        file_format = 'ttl'\n",
    "    elif file_path.endswith('.owl'):\n",
    "        file_format = 'xml'\n",
    "    elif file_path.endswith('.xrdf'):\n",
    "        file_format = 'xml'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "    \n",
    "    g.parse(file_path, format=file_format)\n",
    "\n",
    "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "    data = []\n",
    "    relations = []\n",
    "    found_class_labels = set()\n",
    "\n",
    "    for cls in classes:\n",
    "        if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "            labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "            description = get_class_descriptions(g, cls)\n",
    "\n",
    "            for label in labels:\n",
    "                if label is not None:\n",
    "                    normalized_label = normalize_string(label)\n",
    "                    found_class_labels.add(normalized_label)\n",
    "\n",
    "                    if normalized_label in normalized_class_names_to_check:\n",
    "                        # Check if already processed in this iteration\n",
    "                        if str(cls) not in processed_classes:\n",
    "                            processed_classes.add(str(cls))\n",
    "                            data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, RDFS.subClassOf):\n",
    "                            if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, OWL.equivalentClass):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])                           \n",
    "                            else:\n",
    "                                # Handle blank nodes for equivalentClass\n",
    "                                obj_label = get_complex_expression_label(g, obj)\n",
    "                                obj_description = \"Complex class expression\"\n",
    "\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])\n",
    "\n",
    "                        for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "            \n",
    "\n",
    "    return data, relations, found_class_labels\n",
    "\n",
    "\n",
    "def filter_relations(all_relations, initial_class_names_to_check):\n",
    "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
    "\n",
    "\n",
    "def print_hierarchy(class_name, relations, g, writer):\n",
    "    def recursive_print(class_name, depth=0):\n",
    "        for relation in relations:\n",
    "            if normalize_string(relation[2]) == normalize_string(class_name):\n",
    "                subject_description = get_class_descriptions(g, URIRef(relation[1]))\n",
    "                object_description = get_class_descriptions(g, URIRef(relation[4]))\n",
    "                writer.writerow([relation[1], relation[2], subject_description if subject_description is not None else \"\", relation[3], relation[4], relation[5], object_description if object_description is not None else \"\", relation[0]])\n",
    "                indent = '  ' * depth\n",
    "                print(f\"{indent}{relation[1]} {relation[2]} is {relation[3]} {relation[4]} {relation} {relation[5]} (from {relation[0]})\")\n",
    "                recursive_print(relation[5], depth + 1)\n",
    "\n",
    "    recursive_print(class_name)\n",
    "\n",
    "\n",
    "output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "class_output_file = \"ontology_classes.csv\"\n",
    "relations_output_file = \"ontology_relations.csv\"\n",
    "\n",
    "all_data = []\n",
    "all_relations = []\n",
    "all_found_class_labels = set()\n",
    "\n",
    "class_names_to_check = initial_class_names_to_check\n",
    "\n",
    "max_iterations = 2\n",
    "iteration_count = 0\n",
    "g = Graph()\n",
    "processed_classes = set()\n",
    "processed_relations = set()\n",
    "last_class_name_written = None  # Track the last class name written\n",
    "\n",
    "\n",
    "while class_names_to_check and iteration_count < max_iterations:\n",
    "    iteration_count += 1\n",
    "    new_data = []\n",
    "    new_relations = []\n",
    "    new_found_class_labels = set()\n",
    "\n",
    "    for ontology_file in ontology_files:\n",
    "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check, g, processed_classes, processed_relations)\n",
    "        new_data.extend(file_data)\n",
    "        new_relations.extend(file_relations)\n",
    "        new_found_class_labels.update(found_class_labels)\n",
    "\n",
    "    all_data.extend(new_data)\n",
    "    all_relations.extend(new_relations)\n",
    "    all_found_class_labels.update(new_found_class_labels)\n",
    "\n",
    "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
    "\n",
    "    # Filter and save class data\n",
    "    filtered_data = [row for row in new_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
    "    with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_data:\n",
    "            current_class_name = filtered_data[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_data)\n",
    "\n",
    "    # Filter and save class relations\n",
    "    filtered_relations = filter_relations(new_relations, initial_class_names_to_check)\n",
    "    with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_relations:\n",
    "            current_class_name = filtered_relations[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_relations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
    "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
    "\n",
    "print(\"\\nInitial class names found in the output:\")\n",
    "for class_name in initial_class_names_to_check:\n",
    "    normalized_class_name = normalize_string(class_name)\n",
    "    found = False\n",
    "    for label in all_found_class_labels:\n",
    "        if normalized_class_name in label:\n",
    "            found = True\n",
    "            print(f\"Class '{class_name}' found in:\")\n",
    "            for ontology_file in ontology_files:\n",
    "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check, g, processed_classes, processed_relations)\n",
    "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
    "                if normalized_class_name in normalized_labels:\n",
    "                    print(f\"- {ontology_file}\")\n",
    "            break\n",
    "    if not found:\n",
    "        print(f\"Class '{class_name}' not found in the output.\")\n",
    "\n",
    "print(\"\\nSaving class hierarchy to CSV file:\")\n",
    "with open(output_hierarchy_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Class URI\", \"Class Name\", \"Class Description\", \"Relation Type\", \"Related Class URI\", \"Related Class Name\", \"Related Class Description\", \"File\"])\n",
    "    for class_name in initial_class_names_to_check:\n",
    "        normalized_class_name = normalize_string(class_name)\n",
    "        print_hierarchy(normalized_class_name, all_relations, g, writer)\n",
    "\n",
    "print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n",
    "\n",
    "def save_intersection_info_to_csv(data, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Inside your main loop where you process ontology files:\n",
    "intersection_data = [row for row in all_data if row[3].startswith(\"Intersection of\")]\n",
    "save_intersection_info_to_csv(intersection_data, \"intersection_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace, URIRef, Literal, BNode\n",
    "\n",
    "\n",
    "directory = '.'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        os.remove(os.path.join(directory, filename))\n",
    "\n",
    "\n",
    "# Define namespaces (assuming these are already defined in your script)\n",
    "ex = Namespace(\"http://example.org/ontology/\")\n",
    "sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "materialsmine = Namespace(\"http://materialsmine.org/ns/\")\n",
    "bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "xml = Namespace(\"http://www.w3.org/XML/1998/namespace\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "isPartOf = dcterms.isPartOf\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
    "    s = s.replace('...', '')\n",
    "    return s\n",
    "\n",
    "def get_class_label(g, cls):\n",
    "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "    return labels[0] if labels else None\n",
    "\n",
    "def get_class_descriptions(g, cls):\n",
    "    descriptions = list(g.objects(cls, DCTERMS.description)) + list(g.objects(cls, SKOS.definition)) + list(g.objects(cls, RDFS.comment))\n",
    "    return \" \".join([str(desc) for desc in descriptions if desc is not None]) if descriptions else None\n",
    "\n",
    "\n",
    "def get_complex_expression_label(g, node):\n",
    "    if (node, RDF.type, OWL.Restriction) in g:\n",
    "        prop = list(g.objects(node, OWL.onProperty))\n",
    "        val = list(g.objects(node, OWL.someValuesFrom))\n",
    "        if prop and val:\n",
    "            prop_label = get_class_label(g, prop[0])\n",
    "            val_label = get_class_label(g, val[0])\n",
    "            return f\"Restriction on {prop_label} some {val_label}\"\n",
    "    elif (node, RDF.type, OWL.Class) in g:\n",
    "        intersection = list(g.objects(node, OWL.intersectionOf))\n",
    "        if intersection:\n",
    "            components = []\n",
    "            for item in g.items(intersection[0]):\n",
    "                if isinstance(item, URIRef):\n",
    "                    component_label = get_class_label(g, item)\n",
    "                    if component_label:\n",
    "                        components.append(component_label)\n",
    "                elif isinstance(item, BNode):\n",
    "                    restriction_label = get_complex_expression_label(g, item)\n",
    "                    if restriction_label:\n",
    "                        components.append(restriction_label)\n",
    "            if components:\n",
    "                return f\"Intersection of {' and '.join(components)}\"\n",
    "    return None\n",
    "\n",
    "def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "    if file_path.endswith('.ttl'):\n",
    "        file_format = 'ttl'\n",
    "    elif file_path.endswith('.owl'):\n",
    "        file_format = 'xml'\n",
    "    elif file_path.endswith('.xrdf'):\n",
    "        file_format = 'xml'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "    \n",
    "    g.parse(file_path, format=file_format)\n",
    "\n",
    "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "    data = []\n",
    "    relations = []\n",
    "    found_class_labels = set()\n",
    "\n",
    "    for cls in classes:\n",
    "        if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "            labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "            description = get_class_descriptions(g, cls)\n",
    "\n",
    "            for label in labels:\n",
    "                if label is not None:\n",
    "                    normalized_label = normalize_string(label)\n",
    "                    found_class_labels.add(normalized_label)\n",
    "\n",
    "                    if normalized_label in normalized_class_names_to_check:\n",
    "                        # Check if already processed in this iteration\n",
    "                        if str(cls) not in processed_classes:\n",
    "                            processed_classes.add(str(cls))\n",
    "                            data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, RDFS.subClassOf):\n",
    "                            if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, OWL.equivalentClass):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])                           \n",
    "                            else:\n",
    "                                # Handle blank nodes for equivalentClass\n",
    "                                obj_label = get_complex_expression_label(g, obj)\n",
    "                                obj_description = \"Complex class expression\"\n",
    "\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])\n",
    "\n",
    "                        for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "            \n",
    "\n",
    "    return data, relations, found_class_labels\n",
    "\n",
    "\n",
    "def filter_relations(all_relations, initial_class_names_to_check):\n",
    "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
    "\n",
    "\n",
    "def print_hierarchy(class_name, relations, g, writer):\n",
    "    def recursive_print(class_name, depth=0):\n",
    "        for relation in relations:\n",
    "            if normalize_string(relation[2]) == normalize_string(class_name):\n",
    "                subject_description = get_class_descriptions(g, URIRef(relation[1]))\n",
    "                object_description = get_class_descriptions(g, URIRef(relation[4]))\n",
    "                writer.writerow([relation[1], relation[2], subject_description if subject_description is not None else \"\", relation[3], relation[4], relation[5], object_description if object_description is not None else \"\", relation[0]])\n",
    "                indent = '  ' * depth\n",
    "                print(f\"{indent}{relation[1]} {relation[2]} is {relation[3]} {relation[4]} {relation} {relation[5]} (from {relation[0]})\")\n",
    "                recursive_print(relation[5], depth + 1)\n",
    "\n",
    "    recursive_print(class_name)\n",
    "\n",
    "\n",
    "output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "class_output_file = \"ontology_classes.csv\"\n",
    "relations_output_file = \"ontology_relations.csv\"\n",
    "\n",
    "all_data = []\n",
    "all_relations = []\n",
    "all_found_class_labels = set()\n",
    "\n",
    "class_names_to_check = initial_class_names_to_check\n",
    "\n",
    "max_iterations = 2\n",
    "iteration_count = 0\n",
    "g = Graph()\n",
    "processed_classes = set()\n",
    "processed_relations = set()\n",
    "last_class_name_written = None  # Track the last class name written\n",
    "\n",
    "\n",
    "while class_names_to_check and iteration_count < max_iterations:\n",
    "    iteration_count += 1\n",
    "    new_data = []\n",
    "    new_relations = []\n",
    "    new_found_class_labels = set()\n",
    "\n",
    "    for ontology_file in ontology_files:\n",
    "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check, g, processed_classes, processed_relations)\n",
    "        new_data.extend(file_data)\n",
    "        new_relations.extend(file_relations)\n",
    "        new_found_class_labels.update(found_class_labels)\n",
    "\n",
    "    all_data.extend(new_data)\n",
    "    all_relations.extend(new_relations)\n",
    "    all_found_class_labels.update(new_found_class_labels)\n",
    "\n",
    "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
    "\n",
    "    # Filter and save class data\n",
    "    filtered_data = [row for row in new_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
    "    with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_data:\n",
    "            current_class_name = filtered_data[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_data)\n",
    "\n",
    "    # Filter and save class relations\n",
    "    filtered_relations = filter_relations(new_relations, initial_class_names_to_check)\n",
    "    with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_relations:\n",
    "            current_class_name = filtered_relations[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_relations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
    "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
    "\n",
    "print(\"\\nInitial class names found in the output:\")\n",
    "for class_name in initial_class_names_to_check:\n",
    "    normalized_class_name = normalize_string(class_name)\n",
    "    found = False\n",
    "    for label in all_found_class_labels:\n",
    "        if normalized_class_name in label:\n",
    "            found = True\n",
    "            print(f\"Class '{class_name}' found in:\")\n",
    "            for ontology_file in ontology_files:\n",
    "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check, g, processed_classes, processed_relations)\n",
    "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
    "                if normalized_class_name in normalized_labels:\n",
    "                    print(f\"- {ontology_file}\")\n",
    "            break\n",
    "    if not found:\n",
    "        print(f\"Class '{class_name}' not found in the output.\")\n",
    "\n",
    "print(\"\\nSaving class hierarchy to CSV file:\")\n",
    "with open(output_hierarchy_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Class URI\", \"Class Name\", \"Class Description\", \"Relation Type\", \"Related Class URI\", \"Related Class Name\", \"Related Class Description\", \"File\"])\n",
    "    for class_name in initial_class_names_to_check:\n",
    "        normalized_class_name = normalize_string(class_name)\n",
    "        print_hierarchy(normalized_class_name, all_relations, g, writer)\n",
    "\n",
    "print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n",
    "\n",
    "def save_intersection_info_to_csv(data, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Inside your main loop where you process ontology files:\n",
    "intersection_data = [row for row in all_data if row[3].startswith(\"Intersection of\")]\n",
    "save_intersection_info_to_csv(intersection_data, \"intersection_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class names to check\n",
    "initial_class_names_to_check = [ 'Compression','AmperePerJoule','nfdi','stress', 'Advertiser+content_Article', 'Tensiletest']\n",
    "# initial_class_names_to_check = [ 'TermVariant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of ontology files to process\n",
    "ontology_files = [\n",
    "    # \"../Ontologies/materialsmine.ttl\", ### is not complete!\n",
    "    \"../Ontologies/materialsmine_converted.ttl\",\n",
    "    \"../Ontologies/pmdco_core.ttl\",\n",
    "    \"../Ontologies/nfdicore_2.ttl\",\n",
    "    # \"../Ontologies/bfo.owl\", #### using this ---->  long time to proccess!\n",
    "    # \"../Ontologies/emmo.ttl\",\n",
    "    # \"../Ontologies/owlapi.xrdf\",\n",
    "    # \"../Ontologies/schemaorg.owl\",\n",
    "    # \"../Ontologies/MaterialsMine.xrdf\",\n",
    "    # '../Ontologies/emmo.owl', ### has problem of reading file\n",
    "    # \"../Ontologies/Physical_Activity_Ontology_V2.owl\",\n",
    "    # \"../Ontologies/Physical_Activity_Ontology_V2.xrdf\",\n",
    "    # \"../Ontologies/oboe.owl\",\n",
    "    \"../Ontologies/fabio.ttl\",\n",
    "    # Add more file paths as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace, URIRef, Literal, BNode\n",
    "\n",
    "\n",
    "directory = '.'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        os.remove(os.path.join(directory, filename))\n",
    "\n",
    "\n",
    "# Define namespaces (assuming these are already defined in your script)\n",
    "ex = Namespace(\"http://example.org/ontology/\")\n",
    "sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "materialsmine = Namespace(\"http://materialsmine.org/ns/\")\n",
    "bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "xml = Namespace(\"http://www.w3.org/XML/1998/namespace\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "isPartOf = dcterms.isPartOf\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
    "    s = s.replace('...', '')\n",
    "    return s\n",
    "\n",
    "def get_class_label(g, cls):\n",
    "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "    return labels[0] if labels else None\n",
    "\n",
    "def get_class_descriptions(g, cls):\n",
    "    descriptions = list(g.objects(cls, DCTERMS.description)) + list(g.objects(cls, SKOS.definition)) + list(g.objects(cls, RDFS.comment))\n",
    "    return \" \".join([str(desc) for desc in descriptions if desc is not None]) if descriptions else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_complex_expression_label(g, node):\n",
    "#     if (node, RDF.type, OWL.Restriction) in g:\n",
    "#         prop = list(g.objects(node, OWL.onProperty))\n",
    "#         val = list(g.objects(node, OWL.someValuesFrom))\n",
    "#         if prop and val:\n",
    "#             prop_label = get_class_label(g, prop[0])\n",
    "#             val_label = get_class_label(g, val[0])\n",
    "#             return f\"Restriction on {prop_label} some {val_label}\"\n",
    "#     elif (node, RDF.type, OWL.Class) in g:\n",
    "#         intersection = list(g.objects(node, OWL.intersectionOf))\n",
    "#         if intersection:\n",
    "#             components = []\n",
    "#             for item in g.items(intersection[0]):\n",
    "#                 if isinstance(item, URIRef):\n",
    "#                     component_label = get_class_label(g, item)\n",
    "#                     if component_label:\n",
    "#                         components.append(component_label)\n",
    "#                 elif isinstance(item, BNode):\n",
    "#                     restriction_label = get_complex_expression_label(g, item)\n",
    "#                     if restriction_label:\n",
    "#                         components.append(restriction_label)\n",
    "#             if components:\n",
    "#                 return f\"Intersection of {' and '.join(components)}\"\n",
    "#     return None\n",
    "\n",
    "def get_complex_expression_label(g, node):\n",
    "    if (node, RDF.type, OWL.Restriction) in g:\n",
    "        prop = list(g.objects(node, OWL.onProperty))\n",
    "        val = list(g.objects(node, OWL.someValuesFrom))\n",
    "        if prop and val:\n",
    "            prop_label = get_class_label(g, prop[0])\n",
    "            val_label = get_class_label(g, val[0])\n",
    "            return f\"Restriction on {prop_label} some {val_label}\"\n",
    "    elif (node, RDF.type, OWL.Class) in g:\n",
    "        equivalent_classes = list(g.objects(node, OWL.equivalentClass))\n",
    "        if equivalent_classes:\n",
    "            for equivalent_class in equivalent_classes:\n",
    "                if isinstance(equivalent_class, BNode):\n",
    "                    intersections = list(g.objects(equivalent_class, OWL.intersectionOf))\n",
    "                    if intersections:\n",
    "                        components = []\n",
    "                        for intersection in g.items(intersections[0]):\n",
    "                            if isinstance(intersection, URIRef):\n",
    "                                component_label = get_class_label(g, intersection)\n",
    "                                if component_label:\n",
    "                                    components.append(component_label)\n",
    "                            elif isinstance(intersection, BNode):\n",
    "                                restriction_labels = []\n",
    "                                for restriction_item in g.items(intersection):\n",
    "                                    if isinstance(restriction_item, BNode):\n",
    "                                        restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                        if restriction_label:\n",
    "                                            restriction_labels.append(restriction_label)\n",
    "                                if restriction_labels:\n",
    "                                    components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                        if components:\n",
    "                            return f\"Equivalent to {' and '.join(components)}\"\n",
    "                else:\n",
    "                    return get_complex_expression_label(g, equivalent_class)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "#     if file_path.endswith('.ttl'):\n",
    "#         file_format = 'ttl'\n",
    "#     elif file_path.endswith('.owl'):\n",
    "#         file_format = 'xml'\n",
    "#     elif file_path.endswith('.xrdf'):\n",
    "#         file_format = 'xml'\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "    \n",
    "#     g.parse(file_path, format=file_format)\n",
    "\n",
    "#     normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "#     classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "#     data = []\n",
    "#     relations = []\n",
    "#     found_class_labels = set()\n",
    "\n",
    "#     for cls in classes:\n",
    "#         if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "#             labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "#             description = get_class_descriptions(g, cls)\n",
    "\n",
    "#             for label in labels:\n",
    "#                 if label is not None:\n",
    "#                     normalized_label = normalize_string(label)\n",
    "#                     found_class_labels.add(normalized_label)\n",
    "\n",
    "#                     if normalized_label in normalized_class_names_to_check:\n",
    "#                         # Check if already processed in this iteration\n",
    "#                         if str(cls) not in processed_classes:\n",
    "#                             processed_classes.add(str(cls))\n",
    "#                             data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "#                         for obj in g.objects(cls, RDFS.subClassOf):\n",
    "#                             if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "#                                 obj_label = get_class_label(g, obj)\n",
    "#                                 obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "#                                 # Check if already processed in this iteration\n",
    "#                                 if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "#                                     processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "#                                     relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "#                         for obj in g.objects(cls, OWL.equivalentClass):\n",
    "#                             if isinstance(obj, URIRef):\n",
    "#                                 obj_label = get_class_label(g, obj)\n",
    "#                                 obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "#                                 # Check if already processed in this iteration\n",
    "#                                 if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "#                                     processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "#                                     relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "#                             else:\n",
    "#                                 # Handle blank nodes for equivalentClass\n",
    "#                                 obj_label = get_complex_expression_label(g, obj)\n",
    "#                                 obj_description = \"Complex class expression\"\n",
    "\n",
    "#                                 if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "#                                     processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "#                                     relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "#                         for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "#                             if isinstance(obj, URIRef):\n",
    "#                                 obj_label = get_class_label(g, obj)\n",
    "#                                 obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "#                                 # Check if already processed in this iteration\n",
    "#                                 if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "#                                     processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "#                                     relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "#             # Check for owl:intersectionOf\n",
    "#             intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "#             for intersection in intersections:\n",
    "#                 if isinstance(intersection, BNode):\n",
    "#                     components = []\n",
    "#                     for item in g.items(intersection):\n",
    "#                         if isinstance(item, URIRef):\n",
    "#                             component_label = get_class_label(g, item)\n",
    "#                             if component_label:\n",
    "#                                 components.append(component_label)\n",
    "#                         elif isinstance(item, BNode):\n",
    "#                             restriction_labels = []\n",
    "#                             for restriction_item in g.items(item):\n",
    "#                                 if isinstance(restriction_item, BNode):\n",
    "#                                     restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "#                                     if restriction_label:\n",
    "#                                         restriction_labels.append(restriction_label)\n",
    "#                             if restriction_labels:\n",
    "#                                 components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                    \n",
    "#                     if components:\n",
    "#                         data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])\n",
    "\n",
    "#     return data, relations, found_class_labels\n",
    "\n",
    "\n",
    "def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "    if file_path.endswith('.ttl'):\n",
    "        file_format = 'ttl'\n",
    "    elif file_path.endswith('.owl'):\n",
    "        file_format = 'xml'\n",
    "    elif file_path.endswith('.xrdf'):\n",
    "        file_format = 'xml'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "    \n",
    "    g.parse(file_path, format=file_format)\n",
    "\n",
    "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "    data = []\n",
    "    relations = []\n",
    "    found_class_labels = set()\n",
    "\n",
    "    for cls in classes:\n",
    "        if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "            labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "            description = get_class_descriptions(g, cls)\n",
    "\n",
    "            for label in labels:\n",
    "                if label is not None:\n",
    "                    normalized_label = normalize_string(label)\n",
    "                    found_class_labels.add(normalized_label)\n",
    "\n",
    "                    if normalized_label in normalized_class_names_to_check:\n",
    "                        # Check if already processed in this iteration\n",
    "                        if str(cls) not in processed_classes:\n",
    "                            processed_classes.add(str(cls))\n",
    "                            data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, RDFS.subClassOf):\n",
    "                            if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, OWL.equivalentClass):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                                    # Handle owl:intersectionOf\n",
    "                                    intersections = list(g.objects(obj, OWL.intersectionOf))\n",
    "                                    if intersections:\n",
    "                                        components = []\n",
    "                                        for intersection in g.items(intersections[0]):\n",
    "                                            if isinstance(intersection, URIRef):\n",
    "                                                component_label = get_class_label(g, intersection)\n",
    "                                                if component_label:\n",
    "                                                    components.append(component_label)\n",
    "                                            elif isinstance(intersection, BNode):\n",
    "                                                restriction_labels = []\n",
    "                                                for restriction_item in g.items(intersection):\n",
    "                                                    if isinstance(restriction_item, BNode):\n",
    "                                                        restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                        if restriction_label:\n",
    "                                                            restriction_labels.append(restriction_label)\n",
    "                                                if restriction_labels:\n",
    "                                                    components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "\n",
    "                                        if components:\n",
    "                                            data.append([file_path, str(cls), \"\", f\"Equivalent to {' and '.join(components)}\"])\n",
    "\n",
    "                            else:\n",
    "                                # Handle blank nodes for equivalentClass\n",
    "                                obj_label = get_complex_expression_label(g, obj)\n",
    "                                obj_description = \"Complex class expression\"\n",
    "\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                                    # Handle owl:intersectionOf\n",
    "                                    intersections = list(g.objects(obj, OWL.intersectionOf))\n",
    "                                    if intersections:\n",
    "                                        components = []\n",
    "                                        for intersection in g.items(intersections[0]):\n",
    "                                            if isinstance(intersection, URIRef):\n",
    "                                                component_label = get_class_label(g, intersection)\n",
    "                                                if component_label:\n",
    "                                                    components.append(component_label)\n",
    "                                            elif isinstance(intersection, BNode):\n",
    "                                                restriction_labels = []\n",
    "                                                for restriction_item in g.items(intersection):\n",
    "                                                    if isinstance(restriction_item, BNode):\n",
    "                                                        restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                        if restriction_label:\n",
    "                                                            restriction_labels.append(restriction_label)\n",
    "                                                if restriction_labels:\n",
    "                                                    components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "\n",
    "                                        if components:\n",
    "                                            data.append([file_path, str(cls), \"\", f\"Equivalent to {' and '.join(components)}\"])\n",
    "\n",
    "                        for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "    return data, relations, found_class_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_relations(all_relations, initial_class_names_to_check):\n",
    "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hierarchy(class_name, relations, g, writer):\n",
    "    def recursive_print(class_name, depth=0):\n",
    "        for relation in relations:\n",
    "            if normalize_string(relation[2]) == normalize_string(class_name):\n",
    "                subject_description = get_class_descriptions(g, URIRef(relation[1]))\n",
    "                object_description = get_class_descriptions(g, URIRef(relation[4]))\n",
    "                writer.writerow([relation[1], relation[2], subject_description if subject_description is not None else \"\", relation[3], relation[4], relation[5], object_description if object_description is not None else \"\", relation[0]])\n",
    "                indent = '  ' * depth\n",
    "                print(f\"{indent}{relation[1]} {relation[2]} is {relation[3]} {relation[4]} {relation[5]} (from {relation[0]})\")\n",
    "                recursive_print(relation[5], depth + 1)\n",
    "\n",
    "    recursive_print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "class_output_file = \"ontology_classes.csv\"\n",
    "relations_output_file = \"ontology_relations.csv\"\n",
    "\n",
    "all_data = []\n",
    "all_relations = []\n",
    "all_found_class_labels = set()\n",
    "\n",
    "class_names_to_check = initial_class_names_to_check\n",
    "\n",
    "max_iterations = 2\n",
    "iteration_count = 0\n",
    "g = Graph()\n",
    "processed_classes = set()\n",
    "processed_relations = set()\n",
    "last_class_name_written = None  # Track the last class name written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while class_names_to_check and iteration_count < max_iterations:\n",
    "    iteration_count += 1\n",
    "    new_data = []\n",
    "    new_relations = []\n",
    "    new_found_class_labels = set()\n",
    "\n",
    "    for ontology_file in ontology_files:\n",
    "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check, g, processed_classes, processed_relations)\n",
    "        new_data.extend(file_data)\n",
    "        new_relations.extend(file_relations)\n",
    "        new_found_class_labels.update(found_class_labels)\n",
    "\n",
    "    all_data.extend(new_data)\n",
    "    all_relations.extend(new_relations)\n",
    "    all_found_class_labels.update(new_found_class_labels)\n",
    "\n",
    "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
    "\n",
    "    # Filter and save class data\n",
    "    filtered_data = [row for row in new_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
    "    with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_data:\n",
    "            current_class_name = filtered_data[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_data)\n",
    "\n",
    "    # Filter and save class relations\n",
    "    filtered_relations = filter_relations(new_relations, initial_class_names_to_check)\n",
    "    with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_relations:\n",
    "            current_class_name = filtered_relations[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
    "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
    "\n",
    "print(\"\\nInitial class names found in the output:\")\n",
    "for class_name in initial_class_names_to_check:\n",
    "    normalized_class_name = normalize_string(class_name)\n",
    "    found = False\n",
    "    for label in all_found_class_labels:\n",
    "        if normalized_class_name in label:\n",
    "            found = True\n",
    "            print(f\"Class '{class_name}' found in:\")\n",
    "            for ontology_file in ontology_files:\n",
    "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check, g, processed_classes, processed_relations)\n",
    "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
    "                if normalized_class_name in normalized_labels:\n",
    "                    print(f\"- {ontology_file}\")\n",
    "            break\n",
    "    if not found:\n",
    "        print(f\"Class '{class_name}' not found in the output.\")\n",
    "\n",
    "print(\"\\nSaving class hierarchy to CSV file:\")\n",
    "with open(output_hierarchy_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Class URI\", \"Class Name\", \"Class Description\", \"Relation Type\", \"Related Class URI\", \"Related Class Name\", \"Related Class Description\", \"File\"])\n",
    "    for class_name in initial_class_names_to_check:\n",
    "        normalized_class_name = normalize_string(class_name)\n",
    "        print_hierarchy(normalized_class_name, all_relations, g, writer)\n",
    "\n",
    "print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n",
    "\n",
    "# def save_intersection_info_to_csv(data, output_file):\n",
    "#     with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "#         for row in data:\n",
    "#             writer.writerow(row)\n",
    "\n",
    "def save_intersection_info_to_csv(data, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "        for row in data:\n",
    "            if row[3].startswith(\"Intersection of\"):\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "\n",
    "# Inside your main loop where you process ontology files:\n",
    "intersection_data = [row for row in all_data if row[3].startswith(\"Intersection of\")]\n",
    "save_intersection_info_to_csv(intersection_data, \"intersection_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class names to check\n",
    "# initial_class_names_to_check = [ 'Compression','AmperePerJoule','nfdi','stress', 'Advertiser+content_Article', 'Tensiletest']\n",
    "initial_class_names_to_check = [ 'Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of ontology files to process\n",
    "ontology_files = [\n",
    "    # \"../Ontologies/materialsmine.ttl\", ### is not complete!\n",
    "    \"../Ontologies/materialsmine_converted.ttl\",\n",
    "    \"../Ontologies/pmdco_core.ttl\",\n",
    "    \"../Ontologies/nfdicore_2.ttl\",\n",
    "    # \"../Ontologies/bfo.owl\", #### using this ---->  long time to proccess!\n",
    "    # \"../Ontologies/emmo.ttl\",\n",
    "    # \"../Ontologies/owlapi.xrdf\",\n",
    "    # \"../Ontologies/schemaorg.owl\",\n",
    "    # \"../Ontologies/MaterialsMine.xrdf\",\n",
    "    # '../Ontologies/emmo.owl', ### has problem of reading file\n",
    "    # \"../Ontologies/Physical_Activity_Ontology_V2.owl\",\n",
    "    # \"../Ontologies/Physical_Activity_Ontology_V2.xrdf\",\n",
    "    \"../Ontologies/oboe.owl\",\n",
    "    \"../Ontologies/fabio.ttl\",\n",
    "    # Add more file paths as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace, URIRef, Literal, BNode\n",
    "\n",
    "\n",
    "directory = '.'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        os.remove(os.path.join(directory, filename))\n",
    "\n",
    "\n",
    "# Define namespaces (assuming these are already defined in your script)\n",
    "ex = Namespace(\"http://example.org/ontology/\")\n",
    "sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "materialsmine = Namespace(\"http://materialsmine.org/ns/\")\n",
    "bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "xml = Namespace(\"http://www.w3.org/XML/1998/namespace\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "isPartOf = dcterms.isPartOf\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
    "    s = s.replace('...', '')\n",
    "    return s\n",
    "\n",
    "def get_class_label(g, cls):\n",
    "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "    return labels[0] if labels else None\n",
    "\n",
    "def get_class_descriptions(g, cls):\n",
    "    descriptions = list(g.objects(cls, DCTERMS.description)) + list(g.objects(cls, SKOS.definition)) + list(g.objects(cls, RDFS.comment))\n",
    "    return \" \".join([str(desc) for desc in descriptions if desc is not None]) if descriptions else None\n",
    "\n",
    "\n",
    "def get_complex_expression_label(g, node):\n",
    "    if (node, RDF.type, OWL.Restriction) in g:\n",
    "        prop = list(g.objects(node, OWL.onProperty))\n",
    "        val = list(g.objects(node, OWL.someValuesFrom))\n",
    "        if prop and val:\n",
    "            prop_label = get_class_label(g, prop[0])\n",
    "            val_label = get_class_label(g, val[0])\n",
    "            return f\"Restriction on {prop_label} some {val_label}\"\n",
    "    elif (node, RDF.type, OWL.Class) in g:\n",
    "        intersection = list(g.objects(node, OWL.intersectionOf))\n",
    "        if intersection:\n",
    "            components = []\n",
    "            for item in g.items(intersection[0]):\n",
    "                if isinstance(item, URIRef):\n",
    "                    component_label = get_class_label(g, item)\n",
    "                    if component_label:\n",
    "                        components.append(component_label)\n",
    "                elif isinstance(item, BNode):\n",
    "                    restriction_label = get_complex_expression_label(g, item)\n",
    "                    if restriction_label:\n",
    "                        components.append(restriction_label)\n",
    "            if components:\n",
    "                return f\"Intersection of {' and '.join(components)}\"\n",
    "    return None\n",
    "\n",
    "def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "    if file_path.endswith('.ttl'):\n",
    "        file_format = 'ttl'\n",
    "    elif file_path.endswith('.owl'):\n",
    "        file_format = 'xml'\n",
    "    elif file_path.endswith('.xrdf'):\n",
    "        file_format = 'xml'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "    \n",
    "    g.parse(file_path, format=file_format)\n",
    "\n",
    "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "    data = []\n",
    "    relations = []\n",
    "    found_class_labels = set()\n",
    "\n",
    "    for cls in classes:\n",
    "        if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "            labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "            description = get_class_descriptions(g, cls)\n",
    "\n",
    "            for label in labels:\n",
    "                if label is not None:\n",
    "                    normalized_label = normalize_string(label)\n",
    "                    found_class_labels.add(normalized_label)\n",
    "\n",
    "                    if normalized_label in normalized_class_names_to_check:\n",
    "                        # Check if already processed in this iteration\n",
    "                        if str(cls) not in processed_classes:\n",
    "                            processed_classes.add(str(cls))\n",
    "                            data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, RDFS.subClassOf):\n",
    "                            if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, OWL.equivalentClass):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])                           \n",
    "                            else:\n",
    "                                # Handle blank nodes for equivalentClass\n",
    "                                obj_label = get_complex_expression_label(g, obj)\n",
    "                                obj_description = \"Complex class expression\"\n",
    "\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])\n",
    "\n",
    "                        for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "            \n",
    "\n",
    "    return data, relations, found_class_labels\n",
    "\n",
    "\n",
    "def filter_relations(all_relations, initial_class_names_to_check):\n",
    "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
    "\n",
    "\n",
    "def print_hierarchy(class_name, relations, g, writer):\n",
    "    def recursive_print(class_name, depth=0):\n",
    "        for relation in relations:\n",
    "            if normalize_string(relation[2]) == normalize_string(class_name):\n",
    "                subject_description = get_class_descriptions(g, URIRef(relation[1]))\n",
    "                object_description = get_class_descriptions(g, URIRef(relation[4]))\n",
    "                writer.writerow([relation[1], relation[2], subject_description if subject_description is not None else \"\", relation[3], relation[4], relation[5], object_description if object_description is not None else \"\", relation[0]])\n",
    "                indent = '  ' * depth\n",
    "                print(f\"{indent}{relation[1]} {relation[2]} is {relation[3]} {relation[4]} {relation} {relation[5]} (from {relation[0]})\")\n",
    "                recursive_print(relation[5], depth + 1)\n",
    "\n",
    "    recursive_print(class_name)\n",
    "\n",
    "\n",
    "output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "class_output_file = \"ontology_classes.csv\"\n",
    "relations_output_file = \"ontology_relations.csv\"\n",
    "\n",
    "all_data = []\n",
    "all_relations = []\n",
    "all_found_class_labels = set()\n",
    "\n",
    "class_names_to_check = initial_class_names_to_check\n",
    "\n",
    "max_iterations = 2\n",
    "iteration_count = 0\n",
    "g = Graph()\n",
    "processed_classes = set()\n",
    "processed_relations = set()\n",
    "last_class_name_written = None  # Track the last class name written\n",
    "\n",
    "\n",
    "while class_names_to_check and iteration_count < max_iterations:\n",
    "    iteration_count += 1\n",
    "    new_data = []\n",
    "    new_relations = []\n",
    "    new_found_class_labels = set()\n",
    "\n",
    "    for ontology_file in ontology_files:\n",
    "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check, g, processed_classes, processed_relations)\n",
    "        new_data.extend(file_data)\n",
    "        new_relations.extend(file_relations)\n",
    "        new_found_class_labels.update(found_class_labels)\n",
    "\n",
    "    all_data.extend(new_data)\n",
    "    all_relations.extend(new_relations)\n",
    "    all_found_class_labels.update(new_found_class_labels)\n",
    "\n",
    "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
    "\n",
    "    # Filter and save class data\n",
    "    filtered_data = [row for row in new_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
    "    with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_data:\n",
    "            current_class_name = filtered_data[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_data)\n",
    "\n",
    "    # Filter and save class relations\n",
    "    filtered_relations = filter_relations(new_relations, initial_class_names_to_check)\n",
    "    with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_relations:\n",
    "            current_class_name = filtered_relations[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_relations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
    "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
    "\n",
    "print(\"\\nInitial class names found in the output:\")\n",
    "for class_name in initial_class_names_to_check:\n",
    "    normalized_class_name = normalize_string(class_name)\n",
    "    found = False\n",
    "    for label in all_found_class_labels:\n",
    "        if normalized_class_name in label:\n",
    "            found = True\n",
    "            print(f\"Class '{class_name}' found in:\")\n",
    "            for ontology_file in ontology_files:\n",
    "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check, g, processed_classes, processed_relations)\n",
    "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
    "                if normalized_class_name in normalized_labels:\n",
    "                    print(f\"- {ontology_file}\")\n",
    "            break\n",
    "    if not found:\n",
    "        print(f\"Class '{class_name}' not found in the output.\")\n",
    "\n",
    "print(\"\\nSaving class hierarchy to CSV file:\")\n",
    "with open(output_hierarchy_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Class URI\", \"Class Name\", \"Class Description\", \"Relation Type\", \"Related Class URI\", \"Related Class Name\", \"Related Class Description\", \"File\"])\n",
    "    for class_name in initial_class_names_to_check:\n",
    "        normalized_class_name = normalize_string(class_name)\n",
    "        print_hierarchy(normalized_class_name, all_relations, g, writer)\n",
    "\n",
    "print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n",
    "\n",
    "def save_intersection_info_to_csv(data, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Inside your main loop where you process ontology files:\n",
    "intersection_data = [row for row in all_data if row[3].startswith(\"Intersection of\")]\n",
    "save_intersection_info_to_csv(intersection_data, \"intersection_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace, URIRef, Literal, BNode\n",
    "\n",
    "# Define namespaces and helper functions here (same as in your original code)...\n",
    "\n",
    "def process_ontology(ontology_files, initial_class_names_to_check, output_hierarchy_file, class_output_file, relations_output_file):\n",
    "    \n",
    "\n",
    "    directory = '.'\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            os.remove(os.path.join(directory, filename))\n",
    "\n",
    "\n",
    "    # Define namespaces (assuming these are already defined in your script)\n",
    "    ex = Namespace(\"http://example.org/ontology/\")\n",
    "    sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "    skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "    owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "    rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "    materialsmine = Namespace(\"http://materialsmine.org/ns/\")\n",
    "    bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "    rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "    xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "    xml = Namespace(\"http://www.w3.org/XML/1998/namespace\")\n",
    "    foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "    dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "    isPartOf = dcterms.isPartOf\n",
    "    DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "\n",
    "    def normalize_string(s):\n",
    "        s = s.lower()\n",
    "        s = re.sub(r'[_\\-+\\s]+', '', s)\n",
    "        s = s.replace('...', '')\n",
    "        return s\n",
    "\n",
    "    def get_class_label(g, cls):\n",
    "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "        return labels[0] if labels else None\n",
    "\n",
    "    def get_class_descriptions(g, cls):\n",
    "        descriptions = list(g.objects(cls, DCTERMS.description)) + list(g.objects(cls, SKOS.definition)) + list(g.objects(cls, RDFS.comment))\n",
    "        return \" \".join([str(desc) for desc in descriptions if desc is not None]) if descriptions else None\n",
    "\n",
    "\n",
    "    def get_complex_expression_label(g, node):\n",
    "        if (node, RDF.type, OWL.Restriction) in g:\n",
    "            prop = list(g.objects(node, OWL.onProperty))\n",
    "            val = list(g.objects(node, OWL.someValuesFrom))\n",
    "            if prop and val:\n",
    "                prop_label = get_class_label(g, prop[0])\n",
    "                val_label = get_class_label(g, val[0])\n",
    "                return f\"Restriction on {prop_label} some {val_label}\"\n",
    "        elif (node, RDF.type, OWL.Class) in g:\n",
    "            intersection = list(g.objects(node, OWL.intersectionOf))\n",
    "            if intersection:\n",
    "                components = []\n",
    "                for item in g.items(intersection[0]):\n",
    "                    if isinstance(item, URIRef):\n",
    "                        component_label = get_class_label(g, item)\n",
    "                        if component_label:\n",
    "                            components.append(component_label)\n",
    "                    elif isinstance(item, BNode):\n",
    "                        restriction_label = get_complex_expression_label(g, item)\n",
    "                        if restriction_label:\n",
    "                            components.append(restriction_label)\n",
    "                if components:\n",
    "                    return f\"Intersection of {' and '.join(components)}\"\n",
    "        return None\n",
    "\n",
    "    def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "        if file_path.endswith('.ttl'):\n",
    "            file_format = 'ttl'\n",
    "        elif file_path.endswith('.owl'):\n",
    "            file_format = 'xml'\n",
    "        elif file_path.endswith('.xrdf'):\n",
    "            file_format = 'xml'\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "        \n",
    "        g.parse(file_path, format=file_format)\n",
    "\n",
    "        normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "        classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "        data = []\n",
    "        relations = []\n",
    "        found_class_labels = set()\n",
    "\n",
    "        for cls in classes:\n",
    "            if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "                labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "                description = get_class_descriptions(g, cls)\n",
    "\n",
    "                for label in labels:\n",
    "                    if label is not None:\n",
    "                        normalized_label = normalize_string(label)\n",
    "                        found_class_labels.add(normalized_label)\n",
    "\n",
    "                        if normalized_label in normalized_class_names_to_check:\n",
    "                            # Check if already processed in this iteration\n",
    "                            if str(cls) not in processed_classes:\n",
    "                                processed_classes.add(str(cls))\n",
    "                                data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "                            for obj in g.objects(cls, RDFS.subClassOf):\n",
    "                                if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "                                    obj_label = get_class_label(g, obj)\n",
    "                                    obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                    # Check if already processed in this iteration\n",
    "                                    if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "                                        processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "                                        relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                            for obj in g.objects(cls, OWL.equivalentClass):\n",
    "                                if isinstance(obj, URIRef):\n",
    "                                    obj_label = get_class_label(g, obj)\n",
    "                                    obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                    # Check if already processed in this iteration\n",
    "                                    if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                        processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                        relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                        # Check for owl:intersectionOf\n",
    "                                        intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                        for intersection in intersections:\n",
    "                                            if isinstance(intersection, BNode):\n",
    "                                                components = []\n",
    "                                                for item in g.items(intersection):\n",
    "                                                    if isinstance(item, URIRef):\n",
    "                                                        component_label = get_class_label(g, item)\n",
    "                                                        if component_label:\n",
    "                                                            components.append(component_label)\n",
    "                                                    elif isinstance(item, BNode):\n",
    "                                                        restriction_labels = []\n",
    "                                                        for restriction_item in g.items(item):\n",
    "                                                            if isinstance(restriction_item, BNode):\n",
    "                                                                restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                                if restriction_label:\n",
    "                                                                    restriction_labels.append(restriction_label)\n",
    "                                                        if restriction_labels:\n",
    "                                                            components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                                \n",
    "                                                if components:\n",
    "                                                    data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])                           \n",
    "                                else:\n",
    "                                    # Handle blank nodes for equivalentClass\n",
    "                                    obj_label = get_complex_expression_label(g, obj)\n",
    "                                    obj_description = \"Complex class expression\"\n",
    "\n",
    "                                    if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                        processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                        relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                        # Check for owl:intersectionOf\n",
    "                                        intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                        for intersection in intersections:\n",
    "                                            if isinstance(intersection, BNode):\n",
    "                                                components = []\n",
    "                                                for item in g.items(intersection):\n",
    "                                                    if isinstance(item, URIRef):\n",
    "                                                        component_label = get_class_label(g, item)\n",
    "                                                        if component_label:\n",
    "                                                            components.append(component_label)\n",
    "                                                    elif isinstance(item, BNode):\n",
    "                                                        restriction_labels = []\n",
    "                                                        for restriction_item in g.items(item):\n",
    "                                                            if isinstance(restriction_item, BNode):\n",
    "                                                                restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                                if restriction_label:\n",
    "                                                                    restriction_labels.append(restriction_label)\n",
    "                                                        if restriction_labels:\n",
    "                                                            components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                                \n",
    "                                                if components:\n",
    "                                                    data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])\n",
    "\n",
    "                            for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "                                if isinstance(obj, URIRef):\n",
    "                                    obj_label = get_class_label(g, obj)\n",
    "                                    obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                    # Check if already processed in this iteration\n",
    "                                    if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "                                        processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "                                        relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                \n",
    "\n",
    "        return data, relations, found_class_labels\n",
    "\n",
    "\n",
    "    def filter_relations(all_relations, initial_class_names_to_check):\n",
    "        normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
    "        return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
    "\n",
    "\n",
    "    def print_hierarchy(class_name, relations, g, writer):\n",
    "        def recursive_print(class_name, depth=0):\n",
    "            for relation in relations:\n",
    "                if normalize_string(relation[2]) == normalize_string(class_name):\n",
    "                    subject_description = get_class_descriptions(g, URIRef(relation[1]))\n",
    "                    object_description = get_class_descriptions(g, URIRef(relation[4]))\n",
    "                    writer.writerow([relation[1], relation[2], subject_description if subject_description is not None else \"\", relation[3], relation[4], relation[5], object_description if object_description is not None else \"\", relation[0]])\n",
    "                    indent = '  ' * depth\n",
    "                    print(f\"{indent}{relation[1]} {relation[2]} is {relation[3]} {relation[4]} {relation} {relation[5]} (from {relation[0]})\")\n",
    "                    recursive_print(relation[5], depth + 1)\n",
    "\n",
    "        recursive_print(class_name)\n",
    "\n",
    "\n",
    "    output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "    class_output_file = \"ontology_classes.csv\"\n",
    "    relations_output_file = \"ontology_relations.csv\"\n",
    "\n",
    "    all_data = []\n",
    "    all_relations = []\n",
    "    all_found_class_labels = set()\n",
    "\n",
    "    class_names_to_check = initial_class_names_to_check\n",
    "\n",
    "    max_iterations = 2\n",
    "    iteration_count = 0\n",
    "    g = Graph()\n",
    "    processed_classes = set()\n",
    "    processed_relations = set()\n",
    "    last_class_name_written = None  # Track the last class name written\n",
    "\n",
    "\n",
    "    while class_names_to_check and iteration_count < max_iterations:\n",
    "        iteration_count += 1\n",
    "        new_data = []\n",
    "        new_relations = []\n",
    "        new_found_class_labels = set()\n",
    "\n",
    "        for ontology_file in ontology_files:\n",
    "            file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check, g, processed_classes, processed_relations)\n",
    "            new_data.extend(file_data)\n",
    "            new_relations.extend(file_relations)\n",
    "            new_found_class_labels.update(found_class_labels)\n",
    "\n",
    "        all_data.extend(new_data)\n",
    "        all_relations.extend(new_relations)\n",
    "        all_found_class_labels.update(new_found_class_labels)\n",
    "\n",
    "        class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
    "        class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
    "\n",
    "        # Filter and save class data\n",
    "        filtered_data = [row for row in new_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
    "        with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            if filtered_data:\n",
    "                current_class_name = filtered_data[0][2]  # Get the class name from the first row\n",
    "                if current_class_name != last_class_name_written:\n",
    "                    # writer.writerow(['------'])  # Write separator\n",
    "                    last_class_name_written = current_class_name\n",
    "            writer.writerows(filtered_data)\n",
    "\n",
    "        # Filter and save class relations\n",
    "        filtered_relations = filter_relations(new_relations, initial_class_names_to_check)\n",
    "        with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            if filtered_relations:\n",
    "                current_class_name = filtered_relations[0][2]  # Get the class name from the first row\n",
    "                if current_class_name != last_class_name_written:\n",
    "                    # writer.writerow(['------'])  # Write separator\n",
    "                    last_class_name_written = current_class_name\n",
    "            writer.writerows(filtered_relations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Filtered class data has been saved to {class_output_file}\")\n",
    "    print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
    "\n",
    "    print(\"\\nInitial class names found in the output:\")\n",
    "    for class_name in initial_class_names_to_check:\n",
    "        normalized_class_name = normalize_string(class_name)\n",
    "        found = False\n",
    "        for label in all_found_class_labels:\n",
    "            if normalized_class_name in label:\n",
    "                found = True\n",
    "                print(f\"Class '{class_name}' found in:\")\n",
    "                for ontology_file in ontology_files:\n",
    "                    file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check, g, processed_classes, processed_relations)\n",
    "                    normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
    "                    if normalized_class_name in normalized_labels:\n",
    "                        print(f\"- {ontology_file}\")\n",
    "                break\n",
    "        if not found:\n",
    "            print(f\"Class '{class_name}' not found in the output.\")\n",
    "\n",
    "    print(\"\\nSaving class hierarchy to CSV file:\")\n",
    "    with open(output_hierarchy_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Class URI\", \"Class Name\", \"Class Description\", \"Relation Type\", \"Related Class URI\", \"Related Class Name\", \"Related Class Description\", \"File\"])\n",
    "        for class_name in initial_class_names_to_check:\n",
    "            normalized_class_name = normalize_string(class_name)\n",
    "            print_hierarchy(normalized_class_name, all_relations, g, writer)\n",
    "\n",
    "    print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n",
    "\n",
    "    def save_intersection_info_to_csv(data, output_file):\n",
    "        with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "            for row in data:\n",
    "                writer.writerow(row)\n",
    "\n",
    "    # Inside your main loop where you process ontology files:\n",
    "    intersection_data = [row for row in all_data if row[3].startswith(\"Intersection of\")]\n",
    "    save_intersection_info_to_csv(intersection_data, \"intersection_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of ontology files to process\n",
    "ontology_files = [\n",
    "    # # \"../Ontologies/materialsmine.ttl\", ### is not complete!\n",
    "    \"../Ontologies/materialsmine_converted.ttl\",\n",
    "    # \"../Ontologies/pmdco_core.ttl\",\n",
    "    # \"../Ontologies/nfdicore_2.ttl\",\n",
    "    # # # \"../Ontologies/bfo.owl\", #### using this ---->  long time to proccess!\n",
    "    # \"../Ontologies/emmo.ttl\",\n",
    "    # # # \"../Ontologies/owlapi.xrdf\",\n",
    "    # # \"../Ontologies/schemaorg.owl\",\n",
    "    # # # \"../Ontologies/MaterialsMine.xrdf\",\n",
    "    # # # '../Ontologies/emmo.owl', ### has problem of reading file\n",
    "    # # # \"../Ontologies/Physical_Activity_Ontology_V2.owl\",\n",
    "    # # # \"../Ontologies/Physical_Activity_Ontology_V2.xrdf\",\n",
    "    # # # \"../Ontologies/oboe.owl\",\n",
    "    # \"../Ontologies/fabio.ttl\",\n",
    "    # \"../Ontologies/MatWerk.xrdf\",\n",
    "    # \"../Ontologies/Materials_Data_Science.xrdf\",\n",
    "    # \"../Ontologies/Materials_Data_Science.ttl\",\n",
    "    # \"../Ontologies/ncit.owl\",\n",
    "    # Add more file paths as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class names to check\n",
    "# initial_class_names_to_check = [ 'Compression','AmperePerJoule','nfdi','stress', 'Advertiser+content_Article', 'Tensiletest']\n",
    "initial_class_names_to_check = [ 'stiffness']\n",
    "# initial_class_names_to_check = [\n",
    "#     \"Material\",\n",
    "#     \"Self-Healing Material\",\n",
    "#     # \"Polymer\",\n",
    "#     \"Elastomer\",\n",
    "#     \"Metal\",\n",
    "#     \"Ceramic Matrix Composite\",\n",
    "#     \"Cementitious Material\",\n",
    "#     \"Repair Mechanism\",\n",
    "#     \"Self-Sealing Phase\",\n",
    "#     \"Self-Healing Phase\",\n",
    "#     \"Mechanical Functionality\",\n",
    "#     \"Mechanical Properties\",\n",
    "#     \"Stiffness\",\n",
    "#     \"Strength\",\n",
    "#     \"Stimulus\",\n",
    "#     \"Adhesive\",\n",
    "#     # \"Repair Agent\",\n",
    "#     # \"Particle\",\n",
    "#     # \"Bacterial Spore\",\n",
    "#     # \"Chemical Reaction\",\n",
    "#     # \"Biomimetic Material System\",\n",
    "#     # \"Self-Sealing Principle\",\n",
    "#     # \"Self-Healing Principle\",\n",
    "#     # \"Plant\",\n",
    "#     # \"External Wound\",\n",
    "#     # \"Internal Incision\",\n",
    "#     # \"Delosperma Cooperi\",\n",
    "#     # \"Leaf\",\n",
    "#     # \"Numerical Model\",\n",
    "#     # \"Analytical Model\",\n",
    "#     # \"Polymer\",\n",
    "#     # \"Self-Healing Polymer\",\n",
    "#     # \"Actuator\",\n",
    "#     # \"Multilayer Actuator\",\n",
    "#     # \"Mechanical Metamaterial\",\n",
    "#     # \"Unit Cell\",\n",
    "#     # \"Crack\",\n",
    "#     # \"Damage\",\n",
    "#     # \"Stress\",\n",
    "#     # \"Strain\",\n",
    "#     # \"Fluidic Feature\",\n",
    "#     # \"Porosity\",\n",
    "#     # \"Permeability\",\n",
    "#     # \"Mechanical Property\",\n",
    "#     # \"Geometrical Parameter\",\n",
    "#     # \"Nonlinear Finite Element Analysis\"\n",
    "# ]\n",
    "\n",
    "#### Define the output files\n",
    "output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "class_output_file = \"ontology_classes.csv\"\n",
    "relations_output_file = \"ontology_relations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered class data has been saved to ontology_classes.csv\n",
      "Filtered class relations have been saved to ontology_relations.csv\n",
      "\n",
      "Initial class names found in the output:\n",
      "Class 'stiffness' found in:\n",
      "- ../Ontologies/materialsmine_converted.ttl\n",
      "- ../Ontologies/pmdco_core.ttl\n",
      "- ../Ontologies/nfdicore_2.ttl\n",
      "- ../Ontologies/oboe.owl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ../Ontologies/fabio.ttl\n",
      "\n",
      "Saving class hierarchy to CSV file:\n",
      "https://w3id.org/pmd/co/Stiffness Stiffness is subClassOf https://w3id.org/pmd/co/ValueObject ['../Ontologies/pmdco_core.ttl', 'https://w3id.org/pmd/co/Stiffness', 'Stiffness', 'subClassOf', 'https://w3id.org/pmd/co/ValueObject', 'Value Object', 'A :ValueObject is a simple entity which represents a specific value. This value can be a numerical, textual, or a more complex data structure. If a literal value is to be specified, the :value datatype property has to be used. In cases where the value is represented by a resource (e.g. URI), the :resource object property has to be used.\\n\\nA value object, respectively its value, is always associated with an entity of type :Process, :ProcessingNode, or :Object (e.g. :Specimen). The value is meant to be a charactaristic of the associated entity. To express this association it is indended to use the :participant object property.\\n\\nA value object might also refer to a certain unit. The :unit property might be used (e.g. with QUDT ontology).\\n\\nInstances of a value object might be specified as a specific Parameter, namely a SetPoint (nominal value), or Measurement. With :Setpoint the intend is to express, that the value is meant to be some preset, setting or nominal value. :Measurement expresses, that the value has been measured or determined somehow (see example).\\n\\nInstances of a value object might also be specified in a specific DataScope (:Metadata, :PrimaryData, :SecondaryData).'] Value Object (from ../Ontologies/pmdco_core.ttl)\n",
      "  https://w3id.org/pmd/co/ValueObject Value Object is subClassOf http://www.w3.org/ns/prov#Entity ['../Ontologies/materialsmine_converted.ttl', 'https://w3id.org/pmd/co/ValueObject', 'Value Object', 'subClassOf', 'http://www.w3.org/ns/prov#Entity', '', '']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  https://w3id.org/pmd/co/ValueObject Value Object is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'https://w3id.org/pmd/co/ValueObject', 'Value Object', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  https://w3id.org/pmd/co/ValueObject Value Object is equivalentClass Complex class expression ['../Ontologies/pmdco_core.ttl', 'https://w3id.org/pmd/co/ValueObject', 'Value Object', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/pmdco_core.ttl)\n",
      "Class hierarchy has been saved to class_hierarchy.csv\n"
     ]
    }
   ],
   "source": [
    "process_ontology(ontology_files, initial_class_names_to_check, output_hierarchy_file, class_output_file, relations_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace, URIRef, Literal, BNode\n",
    "\n",
    "def process_ontology(ontology_files, initial_class_names_to_check, output_hierarchy_file, class_output_file, relations_output_file):\n",
    "    \n",
    "    # Clear any existing CSV files\n",
    "    directory = '.'\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            os.remove(os.path.join(directory, filename))\n",
    "\n",
    "    # Define namespaces\n",
    "    ex = Namespace(\"http://example.org/ontology/\")\n",
    "    sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "    skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "    owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "    rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "    materialsmine = Namespace(\"http://materialsmine.org/ns/\")\n",
    "    bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "    rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "    xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "    xml = Namespace(\"http://www.w3.org/XML/1998/namespace\")\n",
    "    foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "    dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "    isPartOf = dcterms.isPartOf\n",
    "    DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "\n",
    "    def normalize_string(s):\n",
    "        s = s.lower()\n",
    "        s = re.sub(r'[_\\-+\\s]+', '', s)\n",
    "        s = s.replace('...', '')\n",
    "        return s\n",
    "\n",
    "    def get_class_label(g, cls):\n",
    "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "        return labels[0] if labels else None\n",
    "\n",
    "    def get_class_descriptions(g, cls):\n",
    "        descriptions = list(g.objects(cls, DCTERMS.description)) + list(g.objects(cls, SKOS.definition)) + list(g.objects(cls, RDFS.comment))\n",
    "        return \" \".join([str(desc) for desc in descriptions if desc is not None]) if descriptions else None\n",
    "\n",
    "    def get_complex_expression_label(g, node):\n",
    "        if (node, RDF.type, OWL.Restriction) in g:\n",
    "            prop = list(g.objects(node, OWL.onProperty))\n",
    "            val = list(g.objects(node, OWL.someValuesFrom))\n",
    "            if prop and val:\n",
    "                prop_label = get_class_label(g, prop[0])\n",
    "                val_label = get_class_label(g, val[0])\n",
    "                return f\"Restriction on {prop_label} some {val_label}\"\n",
    "        elif (node, RDF.type, OWL.Class) in g:\n",
    "            intersection = list(g.objects(node, OWL.intersectionOf))\n",
    "            if intersection:\n",
    "                components = []\n",
    "                for item in g.items(intersection[0]):\n",
    "                    if isinstance(item, URIRef):\n",
    "                        component_label = get_class_label(g, item)\n",
    "                        if component_label:\n",
    "                            components.append(component_label)\n",
    "                    elif isinstance(item, BNode):\n",
    "                        restriction_label = get_complex_expression_label(g, item)\n",
    "                        if restriction_label:\n",
    "                            components.append(restriction_label)\n",
    "                if components:\n",
    "                    return f\"Intersection of {' and '.join(components)}\"\n",
    "        return None\n",
    "\n",
    "    def load_and_collect_classes_and_relations(g, class_names_to_check):\n",
    "        normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "        classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "        data = []\n",
    "        relations = []\n",
    "        found_class_labels = set()\n",
    "\n",
    "        for cls in classes:\n",
    "            if isinstance(cls, URIRef):\n",
    "                labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "                description = get_class_descriptions(g, cls)\n",
    "\n",
    "                for label in labels:\n",
    "                    if label is not None:\n",
    "                        normalized_label = normalize_string(label)\n",
    "                        found_class_labels.add(normalized_label)\n",
    "\n",
    "                        if normalized_label in normalized_class_names_to_check:\n",
    "                            if str(cls) not in processed_classes:\n",
    "                                processed_classes.add(str(cls))\n",
    "                                data.append([str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "                            for obj in g.objects(cls, RDFS.subClassOf):\n",
    "                                if isinstance(obj, URIRef):\n",
    "                                    obj_label = get_class_label(g, obj)\n",
    "                                    obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                    if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "                                        processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "                                        relations.append([str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                            for obj in g.objects(cls, OWL.equivalentClass):\n",
    "                                if isinstance(obj, URIRef):\n",
    "                                    obj_label = get_class_label(g, obj)\n",
    "                                    obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                    if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                        processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                        relations.append([str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                else:\n",
    "                                    obj_label = get_complex_expression_label(g, obj)\n",
    "                                    obj_description = \"Complex class expression\"\n",
    "\n",
    "                                    if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                        processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                        relations.append([str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                            for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "                                if isinstance(obj, URIRef):\n",
    "                                    obj_label = get_class_label(g, obj)\n",
    "                                    obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                    if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "                                        processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "                                        relations.append([str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "        return data, relations, found_class_labels\n",
    "\n",
    "    def filter_relations(all_relations, initial_class_names_to_check):\n",
    "        normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
    "        return [relation for relation in all_relations if normalize_string(relation[1]) in normalized_initial_class_names or normalize_string(relation[4]) in normalized_initial_class_names]\n",
    "\n",
    "    def print_hierarchy(class_name, relations, g, writer):\n",
    "        def recursive_print(class_name, depth=0):\n",
    "            for relation in relations:\n",
    "                if normalize_string(relation[1]) == normalize_string(class_name):\n",
    "                    subject_description = get_class_descriptions(g, URIRef(relation[0]))\n",
    "                    object_description = get_class_descriptions(g, URIRef(relation[3]))\n",
    "                    writer.writerow([relation[0], relation[1], subject_description if subject_description is not None else \"\", relation[2], relation[3], relation[4], object_description if object_description is not None else \"\", relation[5]])\n",
    "                    indent = '  ' * depth\n",
    "                    print(f\"{indent}{relation[0]} {relation[1]} is {relation[2]} {relation[3]} {relation[4]} (from {relation[5]})\")\n",
    "                    recursive_print(relation[4], depth + 1)\n",
    "\n",
    "        recursive_print(class_name)\n",
    "\n",
    "    # Load the RDF graph once\n",
    "    g = Graph()\n",
    "    for ontology_file in ontology_files:\n",
    "        if ontology_file.endswith('.ttl'):\n",
    "            file_format = 'ttl'\n",
    "        elif ontology_file.endswith('.owl'):\n",
    "            file_format = 'xml'\n",
    "        elif ontology_file.endswith('.xrdf'):\n",
    "            file_format = 'xml'\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "        g.parse(ontology_file, format=file_format)\n",
    "\n",
    "    all_data = []\n",
    "    all_relations = []\n",
    "    all_found_class_labels = set()\n",
    "\n",
    "    class_names_to_check = initial_class_names_to_check\n",
    "\n",
    "    max_iterations = 2\n",
    "    iteration_count = 0\n",
    "    processed_classes = set()\n",
    "    processed_relations = set()\n",
    "    last_class_name_written = None  # Track the last class name written\n",
    "\n",
    "    while class_names_to_check and iteration_count < max_iterations:\n",
    "        iteration_count += 1\n",
    "        new_data, new_relations, new_found_class_labels = load_and_collect_classes_and_relations(g, class_names_to_check)\n",
    "\n",
    "        all_data.extend(new_data)\n",
    "        all_relations.extend(new_relations)\n",
    "        all_found_class_labels.update(new_found_class_labels)\n",
    "\n",
    "        class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
    "        class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
    "\n",
    "        # Filter and save class data\n",
    "        filtered_data = [row for row in new_data if normalize_string(row[1]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
    "        with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            if filtered_data:\n",
    "                current_class_name = filtered_data[0][1]  # Get the class name from the first row\n",
    "                if current_class_name != last_class_name_written:\n",
    "                    last_class_name_written = current_class_name\n",
    "            writer.writerows(filtered_data)\n",
    "\n",
    "        # Filter and save class relations\n",
    "        filtered_relations = filter_relations(new_relations, initial_class_names_to_check)\n",
    "        with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            if filtered_relations:\n",
    "                current_class_name = filtered_relations[0][1]  # Get the class name from the first row\n",
    "                if current_class_name != last_class_name_written:\n",
    "                    last_class_name_written = current_class_name\n",
    "            writer.writerows(filtered_relations)\n",
    "\n",
    "    print(f\"Filtered class data has been saved to {class_output_file}\")\n",
    "    print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
    "\n",
    "    print(\"\\nInitial class names found in the output:\")\n",
    "    for class_name in initial_class_names_to_check:\n",
    "        normalized_class_name = normalize_string(class_name)\n",
    "        found = False\n",
    "        for label in all_found_class_labels:\n",
    "            if normalized_class_name in label:\n",
    "                found = True\n",
    "                print(f\"Class '{class_name}' found in:\")\n",
    "                break\n",
    "        if not found:\n",
    "            print(f\"Class '{class_name}' not found in the output.\")\n",
    "\n",
    "    print(\"\\nSaving class hierarchy to CSV file:\")\n",
    "    with open(output_hierarchy_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Class URI\", \"Class Name\", \"Class Description\", \"Relation Type\", \"Related Class URI\", \"Related Class Name\", \"Related Class Description\", \"File\"])\n",
    "        for class_name in initial_class_names_to_check:\n",
    "            normalized_class_name = normalize_string(class_name)\n",
    "            print_hierarchy(normalized_class_name, all_relations, g, writer)\n",
    "\n",
    "    print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n",
    "\n",
    "    def save_intersection_info_to_csv(data, output_file):\n",
    "        with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "            for row in data:\n",
    "                writer.writerow(row)\n",
    "\n",
    "    # Save intersection information\n",
    "    intersection_data = [row for row in all_data if row[2].startswith(\"Intersection of\")]\n",
    "    save_intersection_info_to_csv(intersection_data, \"intersection_info.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of ontology files to process\n",
    "ontology_files = [\n",
    "    # # \"../Ontologies/materialsmine.ttl\", ### is not complete!\n",
    "    \"../Ontologies/materialsmine_converted.ttl\",\n",
    "    \"../Ontologies/pmdco_core.ttl\",\n",
    "    \"../Ontologies/nfdicore_2.ttl\",\n",
    "    # # # # \"../Ontologies/bfo.owl\", #### using this ---->  long time to proccess!\n",
    "    \"../Ontologies/emmo.ttl\",\n",
    "    # # # # \"../Ontologies/owlapi.xrdf\",\n",
    "    # # # \"../Ontologies/schemaorg.owl\",\n",
    "    # # # # \"../Ontologies/MaterialsMine.xrdf\",\n",
    "    # # # # '../Ontologies/emmo.owl', ### has problem of reading file\n",
    "    # # \"../Ontologies/Physical_Activity_Ontology_V2.owl\",\n",
    "    # # # # \"../Ontologies/Physical_Activity_Ontology_V2.xrdf\",\n",
    "    # # # # \"../Ontologies/oboe.owl\",\n",
    "    \"../Ontologies/fabio.ttl\",\n",
    "    # \"../Ontologies/MatWerk.xrdf\",\n",
    "    # \"../Ontologies/Materials_Data_Science.xrdf\",\n",
    "    # \"../Ontologies/Materials_Data_Science.ttl\",\n",
    "    # \"../Ontologies/ncit.owl\",\n",
    "    # Add more file paths as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class names to check\n",
    "# initial_class_names_to_check = [ 'Compression','AmperePerJoule','nfdi','stress', 'Advertiser+content_Article', 'Tensiletest']\n",
    "# initial_class_names_to_check = [ 'stress']\n",
    "\n",
    "initial_class_names_to_check = [\n",
    "    \"Material\",\n",
    "    \"Self-Healing Material\",\n",
    "    # \"Polymer\",\n",
    "    # \"Elastomer\",\n",
    "    \"Metal\",\n",
    "    \"Ceramic Matrix Composite\",\n",
    "    \"Cementitious Material\",\n",
    "    \"Repair Mechanism\",\n",
    "    \"Self-Sealing Phase\",\n",
    "    \"Self-Healing Phase\",\n",
    "    \"Mechanical Functionality\",\n",
    "    \"Mechanical Properties\",\n",
    "    \"Stiffness\",\n",
    "    \"Strength\",\n",
    "    \"Stimulus\",\n",
    "    \"Adhesive\",\n",
    "    \"Repair Agent\",\n",
    "    \"Particle\",\n",
    "    \"Bacterial Spore\",\n",
    "    \"Chemical Reaction\",\n",
    "    \"Biomimetic Material System\",\n",
    "    \"Self-Sealing Principle\",\n",
    "    \"Self-Healing Principle\",\n",
    "    \"Plant\",\n",
    "    \"External Wound\",\n",
    "    \"Internal Incision\",\n",
    "    \"Delosperma Cooperi\",\n",
    "    \"Leaf\",\n",
    "    \"Numerical Model\",\n",
    "    \"Analytical Model\",\n",
    "    # \"Self-Healing Polymer\",\n",
    "    \"Actuator\",\n",
    "    \"Multilayer Actuator\",\n",
    "    \"Mechanical Metamaterial\",\n",
    "    \"Unit Cell\",\n",
    "    \"Crack\",\n",
    "    \"Damage\",\n",
    "    \"Stress\",\n",
    "    \"Strain\",\n",
    "    \"Fluidic Feature\",\n",
    "    \"Porosity\",\n",
    "    \"Permeability\",\n",
    "    \"Mechanical Property\",\n",
    "    \"Geometrical Parameter\",\n",
    "    \"Nonlinear Finite Element Analysis\"\n",
    "]\n",
    "\n",
    "\n",
    "#### Define the output files\n",
    "output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "class_output_file = \"ontology_classes.csv\"\n",
    "relations_output_file = \"ontology_relations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered class data has been saved to ontology_classes.csv\n",
      "Filtered class relations have been saved to ontology_relations.csv\n",
      "\n",
      "Initial class names found in the output:\n",
      "Class 'Material' found in:\n",
      "Class 'Self-Healing Material' not found in the output.\n",
      "Class 'Metal' found in:\n",
      "Class 'Ceramic Matrix Composite' not found in the output.\n",
      "Class 'Cementitious Material' not found in the output.\n",
      "Class 'Repair Mechanism' not found in the output.\n",
      "Class 'Self-Sealing Phase' not found in the output.\n",
      "Class 'Self-Healing Phase' not found in the output.\n",
      "Class 'Mechanical Functionality' not found in the output.\n",
      "Class 'Mechanical Properties' not found in the output.\n",
      "Class 'Stiffness' found in:\n",
      "Class 'Strength' found in:\n",
      "Class 'Stimulus' not found in the output.\n",
      "Class 'Adhesive' not found in the output.\n",
      "Class 'Repair Agent' not found in the output.\n",
      "Class 'Particle' found in:\n",
      "Class 'Bacterial Spore' not found in the output.\n",
      "Class 'Chemical Reaction' found in:\n",
      "Class 'Biomimetic Material System' not found in the output.\n",
      "Class 'Self-Sealing Principle' not found in the output.\n",
      "Class 'Self-Healing Principle' not found in the output.\n",
      "Class 'Plant' found in:\n",
      "Class 'External Wound' not found in the output.\n",
      "Class 'Internal Incision' not found in the output.\n",
      "Class 'Delosperma Cooperi' not found in the output.\n",
      "Class 'Leaf' not found in the output.\n",
      "Class 'Numerical Model' not found in the output.\n",
      "Class 'Analytical Model' not found in the output.\n",
      "Class 'Actuator' not found in the output.\n",
      "Class 'Multilayer Actuator' not found in the output.\n",
      "Class 'Mechanical Metamaterial' not found in the output.\n",
      "Class 'Unit Cell' found in:\n",
      "Class 'Crack' found in:\n",
      "Class 'Damage' not found in the output.\n",
      "Class 'Stress' found in:\n",
      "Class 'Strain' found in:\n",
      "Class 'Fluidic Feature' not found in the output.\n",
      "Class 'Porosity' found in:\n",
      "Class 'Permeability' found in:\n",
      "Class 'Mechanical Property' found in:\n",
      "Class 'Geometrical Parameter' not found in the output.\n",
      "Class 'Nonlinear Finite Element Analysis' not found in the output.\n",
      "\n",
      "Saving class hierarchy to CSV file:\n",
      "https://w3id.org/emmo#EMMO_4207e895_8b83_4318_996a_72cfb32acd94 Material is subClassOf https://w3id.org/emmo#EMMO_6e9cb807_fc68_4bcf_b3ba_5fccc887c644 OrdinaryMatter (from )\n",
      "https://w3id.org/emmo#EMMO_4207e895_8b83_4318_996a_72cfb32acd94 Material is subClassOf https://w3id.org/emmo#EMMO_bc37743c_37c4_4ec7_9d58_d1aae5567352 Substance (from )\n",
      "  https://w3id.org/emmo#EMMO_bc37743c_37c4_4ec7_9d58_d1aae5567352 Substance is subClassOf https://w3id.org/emmo#EMMO_57d977ab_0036_4779_b59a_e47620afdb9c CompositePhysicalObject (from )\n",
      "  https://w3id.org/emmo#EMMO_bc37743c_37c4_4ec7_9d58_d1aae5567352 Substance is subClassOf https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance (from )\n",
      "    https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance is subClassOf https://w3id.org/emmo#EMMO_38b579de_4331_40e0_803d_09efa298e726 PhysicalObject (from )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://w3id.org/pmd/co/Stiffness Stiffness is subClassOf https://w3id.org/pmd/co/ValueObject Value Object (from A :ValueObject is a simple entity which represents a specific value. This value can be a numerical, textual, or a more complex data structure. If a literal value is to be specified, the :value datatype property has to be used. In cases where the value is represented by a resource (e.g. URI), the :resource object property has to be used.\n",
      "\n",
      "A value object, respectively its value, is always associated with an entity of type :Process, :ProcessingNode, or :Object (e.g. :Specimen). The value is meant to be a charactaristic of the associated entity. To express this association it is indended to use the :participant object property.\n",
      "\n",
      "A value object might also refer to a certain unit. The :unit property might be used (e.g. with QUDT ontology).\n",
      "\n",
      "Instances of a value object might be specified as a specific Parameter, namely a SetPoint (nominal value), or Measurement. With :Setpoint the intend is to express, that the value is meant to be some preset, setting or nominal value. :Measurement expresses, that the value has been measured or determined somehow (see example).\n",
      "\n",
      "Instances of a value object might also be specified in a specific DataScope (:Metadata, :PrimaryData, :SecondaryData).)\n",
      "  https://w3id.org/pmd/co/ValueObject Value Object is subClassOf http://www.w3.org/ns/prov#Entity  (from )\n",
      "  https://w3id.org/pmd/co/ValueObject Value Object is equivalentClass Complex class expression  (from Complex class expression)\n",
      "http://materialsmine.org/ns/Particle Particle is subClassOf http://materialsmine.org/ns/Nanomaterial Nanomaterial (from materials of which a single unit is sized (in at least one dimension) between 1 and 1000 nanometres (109 meter) but is usually 1100 nm)\n",
      "  http://materialsmine.org/ns/Nanomaterial Nanomaterial is subClassOf http://semanticscience.org/resource/MaterialEntity Material Entity (from A material entity is a physical entity that is spatially extended, exists as a whole at any point in time and has mass. A material entity is a physical entity that is spatially extended, exists as a whole at any point in time and has mass.)\n",
      "    http://semanticscience.org/resource/MaterialEntity Material Entity is subClassOf http://semanticscience.org/resource/Object object (from An object is an entity that is wholly identifiable at any instant of time during which it exists.)\n",
      "      https://w3id.org/emmo#EMMO_6f5af708_f825_4feb_a0d1_a8d813d3022b Object is equivalentClass Complex class expression  (from Complex class expression)\n",
      "      https://w3id.org/pmd/co/Object Object is subClassOf http://www.w3.org/ns/prov#Entity  (from )\n",
      "      http://semanticscience.org/resource/Object object is subClassOf http://semanticscience.org/resource/Entity entity (from Every thing is an entity.)\n",
      "        http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing  (from )\n",
      "  https://w3id.org/emmo#EMMO_5d659e25_a508_43ed_903c_3707c7c7cd4b NanoMaterial is subClassOf https://w3id.org/emmo#EMMO_e4e80813_f379_4091_b017_ee059811f806 SizeDefinedMaterial (from )\n",
      "    https://w3id.org/emmo#EMMO_e4e80813_f379_4091_b017_ee059811f806 SizeDefinedMaterial is subClassOf https://w3id.org/emmo#EMMO_4207e895_8b83_4318_996a_72cfb32acd94 Material (from )\n",
      "      https://w3id.org/emmo#EMMO_4207e895_8b83_4318_996a_72cfb32acd94 Material is subClassOf https://w3id.org/emmo#EMMO_6e9cb807_fc68_4bcf_b3ba_5fccc887c644 OrdinaryMatter (from )\n",
      "      https://w3id.org/emmo#EMMO_4207e895_8b83_4318_996a_72cfb32acd94 Material is subClassOf https://w3id.org/emmo#EMMO_bc37743c_37c4_4ec7_9d58_d1aae5567352 Substance (from )\n",
      "        https://w3id.org/emmo#EMMO_bc37743c_37c4_4ec7_9d58_d1aae5567352 Substance is subClassOf https://w3id.org/emmo#EMMO_57d977ab_0036_4779_b59a_e47620afdb9c CompositePhysicalObject (from )\n",
      "        https://w3id.org/emmo#EMMO_bc37743c_37c4_4ec7_9d58_d1aae5567352 Substance is subClassOf https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance (from )\n",
      "          https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance is subClassOf https://w3id.org/emmo#EMMO_38b579de_4331_40e0_803d_09efa298e726 PhysicalObject (from )\n",
      "https://w3id.org/pmd/co/Particle Particle is subClassOf https://w3id.org/pmd/co/Object Object (from A discernable, tangible or simulated entity that is processed in a process by a processing node.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  https://w3id.org/emmo#EMMO_6f5af708_f825_4feb_a0d1_a8d813d3022b Object is equivalentClass Complex class expression  (from Complex class expression)\n",
      "  https://w3id.org/pmd/co/Object Object is subClassOf http://www.w3.org/ns/prov#Entity  (from )\n",
      "  http://semanticscience.org/resource/Object object is subClassOf http://semanticscience.org/resource/Entity entity (from Every thing is an entity.)\n",
      "    http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing  (from )\n",
      "http://semanticscience.org/resource/ChemicalReaction chemical reaction is subClassOf http://semanticscience.org/resource/ChemicalInteraction chemical interaction (from A chemical interaction is a biochemical process in which chemical entities interact through some set of attractive forces.)\n",
      "  http://semanticscience.org/resource/ChemicalInteraction chemical interaction is subClassOf http://semanticscience.org/resource/Interacting interacting (from interacting is a process characterized by the interaction between two or more entities.)\n",
      "    http://semanticscience.org/resource/Interacting interacting is subClassOf http://semanticscience.org/resource/Process process (from A process is an entity that is identifiable only through the unfolding of time, has temporal parts, and unless otherwise specified/predicted, cannot be identified from any instant of time in which it exists.)\n",
      "      https://w3id.org/pmd/co/Process Process is subClassOf http://www.w3.org/ns/prov#Activity  (from )\n",
      "      http://semanticscience.org/resource/Process process is subClassOf http://semanticscience.org/resource/Entity entity (from Every thing is an entity.)\n",
      "        http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing  (from )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://materialsmine.org/ns/Stress Stress is subClassOf http://materialsmine.org/ns/MechanicalProperty Mechanical Property (from A materials property related to the response of a material under some external applied load.)\n",
      "  http://materialsmine.org/ns/MechanicalProperty Mechanical Property is subClassOf http://semanticscience.org/resource/Quantity Amount (from A quantity is an informational entity that gives the magnitude of a property.)\n",
      "    http://semanticscience.org/resource/Quantity Amount is subClassOf http://semanticscience.org/resource/MeasurementValue measurement value (from A measurement value is a quantitative description that reflects the magnitude of some attribute.)\n",
      "      http://semanticscience.org/resource/MeasurementValue measurement value is subClassOf http://semanticscience.org/resource/Number number (from A number is a tensor of rank 0.)\n",
      "        http://semanticscience.org/resource/Number number is subClassOf http://semanticscience.org/resource/Scalar scalar (from a scalar is a rank 0 tensor and is an element of a field that is used to define a vector space.)\n",
      "          http://semanticscience.org/resource/Scalar scalar is subClassOf http://semanticscience.org/resource/Tensor tensor (from a tensor is a n-dimensional array.)\n",
      "            http://semanticscience.org/resource/Tensor tensor is subClassOf http://semanticscience.org/resource/MathematicalEntity mathematical entity (from A mathematical entity is an information content entity that are components of a mathematical system or can be defined in mathematical terms.)\n",
      "              http://semanticscience.org/resource/MathematicalEntity mathematical entity is subClassOf http://semanticscience.org/resource/InformationContentEntity information content entity (from information content entity is an object that requires some background knowledge or procedure to correctly interpret.)\n",
      "                http://semanticscience.org/resource/InformationContentEntity information content entity is subClassOf http://semanticscience.org/resource/Object object (from An object is an entity that is wholly identifiable at any instant of time during which it exists.)\n",
      "                  https://w3id.org/emmo#EMMO_6f5af708_f825_4feb_a0d1_a8d813d3022b Object is equivalentClass Complex class expression  (from Complex class expression)\n",
      "                  https://w3id.org/pmd/co/Object Object is subClassOf http://www.w3.org/ns/prov#Entity  (from )\n",
      "                  http://semanticscience.org/resource/Object object is subClassOf http://semanticscience.org/resource/Entity entity (from Every thing is an entity.)\n",
      "                    http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing  (from )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    http://semanticscience.org/resource/Quantity Amount is equivalentClass Complex class expression  (from Complex class expression)\n",
      "https://w3id.org/emmo#EMMO_d1917609_db5e_4b8a_9b76_ef1d6f860a81 Stress is subClassOf https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 ISQDerivedQuantity (from )\n",
      "  https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 ISQDerivedQuantity is subClassOf https://w3id.org/emmo#EMMO_71f6ab56_342c_484b_bbe0_de86b7367cb3 DerivedQuantity (from )\n",
      "  https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 ISQDerivedQuantity is subClassOf https://w3id.org/emmo#EMMO_f35cff4d_dc09_44cf_a729_22fb79e3bfb2 InternationalSystemOfQuantity (from )\n",
      "    https://w3id.org/emmo#EMMO_f35cff4d_dc09_44cf_a729_22fb79e3bfb2 InternationalSystemOfQuantity is subClassOf https://w3id.org/emmo#EMMO_9c407ac0_fd4c_4178_8763_95fad9fe29ec StandardizedPhysicalQuantity (from )\n",
      "      https://w3id.org/emmo#EMMO_9c407ac0_fd4c_4178_8763_95fad9fe29ec StandardizedPhysicalQuantity is subClassOf https://w3id.org/emmo#EMMO_02c0621e_a527_4790_8a0f_2bb51973c819 PhysicalQuantity (from In the same system of quantities, dim B = ML3 is the quantity dimension of mass concentration of component B, and ML3 is also the quantity dimension of mass density, .\n",
      "ISO 80000-1 Measured or simulated 'physical propertiy'-s are always defined by a physical law, connected to a physical entity through a model perspective and measurement is done according to the same model.\n",
      "\n",
      "Systems of units suggests that this is the correct approach, since except for the fundamental units (length, time, charge) every other unit is derived by mathematical relations between these fundamental units, implying a physical laws or definitions. Measurement units of quantities of the same quantity dimension may be designated by the same name and symbol even when the quantities are not of the same kind.\n",
      "\n",
      "For example, joule per kelvin and J/K are respectively the name and symbol of both a measurement unit of heat capacity and a measurement unit of entropy, which are generally not considered to be quantities of the same kind.\n",
      "\n",
      "However, in some cases special measurement unit names are restricted to be used with quantities of specific kind only.\n",
      "\n",
      "For example, the measurement unit second to the power minus one (1/s) is called hertz (Hz) when used for frequencies and becquerel (Bq) when used for activities of radionuclides.\n",
      "\n",
      "As another example, the joule (J) is used as a unit of energy, but never as a unit of moment of force, i.e. the newton metre (N  m).  quantities of the same kind have the same quantity dimension,\n",
      " quantities of different quantity dimensions are always of different kinds, and\n",
      " quantities having the same quantity dimension are not necessarily of the same kind.\n",
      "ISO 80000-1)\n",
      "https://w3id.org/pmd/co/Stress Stress is subClassOf https://w3id.org/pmd/co/ValueObject Value Object (from A :ValueObject is a simple entity which represents a specific value. This value can be a numerical, textual, or a more complex data structure. If a literal value is to be specified, the :value datatype property has to be used. In cases where the value is represented by a resource (e.g. URI), the :resource object property has to be used.\n",
      "\n",
      "A value object, respectively its value, is always associated with an entity of type :Process, :ProcessingNode, or :Object (e.g. :Specimen). The value is meant to be a charactaristic of the associated entity. To express this association it is indended to use the :participant object property.\n",
      "\n",
      "A value object might also refer to a certain unit. The :unit property might be used (e.g. with QUDT ontology).\n",
      "\n",
      "Instances of a value object might be specified as a specific Parameter, namely a SetPoint (nominal value), or Measurement. With :Setpoint the intend is to express, that the value is meant to be some preset, setting or nominal value. :Measurement expresses, that the value has been measured or determined somehow (see example).\n",
      "\n",
      "Instances of a value object might also be specified in a specific DataScope (:Metadata, :PrimaryData, :SecondaryData).)\n",
      "  https://w3id.org/pmd/co/ValueObject Value Object is subClassOf http://www.w3.org/ns/prov#Entity  (from )\n",
      "  https://w3id.org/pmd/co/ValueObject Value Object is equivalentClass Complex class expression  (from Complex class expression)\n",
      "https://w3id.org/pmd/co/Stress Stress is equivalentClass Complex class expression Intersection of Restriction on relates to some Area and Restriction on relates to some Force (from Complex class expression)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://materialsmine.org/ns/Strain Strain is subClassOf http://materialsmine.org/ns/MechanicalProperty Mechanical Property (from A materials property related to the response of a material under some external applied load.)\n",
      "  http://materialsmine.org/ns/MechanicalProperty Mechanical Property is subClassOf http://semanticscience.org/resource/Quantity Amount (from A quantity is an informational entity that gives the magnitude of a property.)\n",
      "    http://semanticscience.org/resource/Quantity Amount is subClassOf http://semanticscience.org/resource/MeasurementValue measurement value (from A measurement value is a quantitative description that reflects the magnitude of some attribute.)\n",
      "      http://semanticscience.org/resource/MeasurementValue measurement value is subClassOf http://semanticscience.org/resource/Number number (from A number is a tensor of rank 0.)\n",
      "        http://semanticscience.org/resource/Number number is subClassOf http://semanticscience.org/resource/Scalar scalar (from a scalar is a rank 0 tensor and is an element of a field that is used to define a vector space.)\n",
      "          http://semanticscience.org/resource/Scalar scalar is subClassOf http://semanticscience.org/resource/Tensor tensor (from a tensor is a n-dimensional array.)\n",
      "            http://semanticscience.org/resource/Tensor tensor is subClassOf http://semanticscience.org/resource/MathematicalEntity mathematical entity (from A mathematical entity is an information content entity that are components of a mathematical system or can be defined in mathematical terms.)\n",
      "              http://semanticscience.org/resource/MathematicalEntity mathematical entity is subClassOf http://semanticscience.org/resource/InformationContentEntity information content entity (from information content entity is an object that requires some background knowledge or procedure to correctly interpret.)\n",
      "                http://semanticscience.org/resource/InformationContentEntity information content entity is subClassOf http://semanticscience.org/resource/Object object (from An object is an entity that is wholly identifiable at any instant of time during which it exists.)\n",
      "                  https://w3id.org/emmo#EMMO_6f5af708_f825_4feb_a0d1_a8d813d3022b Object is equivalentClass Complex class expression  (from Complex class expression)\n",
      "                  https://w3id.org/pmd/co/Object Object is subClassOf http://www.w3.org/ns/prov#Entity  (from )\n",
      "                  http://semanticscience.org/resource/Object object is subClassOf http://semanticscience.org/resource/Entity entity (from Every thing is an entity.)\n",
      "                    http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing  (from )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    http://semanticscience.org/resource/Quantity Amount is equivalentClass Complex class expression  (from Complex class expression)\n",
      "https://w3id.org/emmo#EMMO_acf636d4_9ac2_4ce3_960a_d54338e6cae3 Strain is subClassOf https://w3id.org/emmo#EMMO_faab3f84_e475_4a46_af9c_7d249f0b9aef RatioQuantity (from Quantities defined as ratios `Q=A/B` having equal dimensions in numerator and denominator are dimensionless quantities but still have a physical dimension defined as dim(A)/dim(B).\n",
      "\n",
      "Johansson, Ingvar (2010). \"Metrological thinking needs the notions of parametric quantities, units and dimensions\". Metrologia. 47 (3): 219230. doi:10.1088/0026-1394/47/3/012. ISSN 0026-1394.)\n",
      "  https://w3id.org/emmo#EMMO_faab3f84_e475_4a46_af9c_7d249f0b9aef RatioQuantity is subClassOf https://w3id.org/emmo#EMMO_a66427d1_9932_4363_9ec5_7d91f2bfda1e ISQDimensionlessQuantity (from )\n",
      "    https://w3id.org/emmo#EMMO_a66427d1_9932_4363_9ec5_7d91f2bfda1e ISQDimensionlessQuantity is subClassOf https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 ISQDerivedQuantity (from )\n",
      "      https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 ISQDerivedQuantity is subClassOf https://w3id.org/emmo#EMMO_71f6ab56_342c_484b_bbe0_de86b7367cb3 DerivedQuantity (from )\n",
      "      https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 ISQDerivedQuantity is subClassOf https://w3id.org/emmo#EMMO_f35cff4d_dc09_44cf_a729_22fb79e3bfb2 InternationalSystemOfQuantity (from )\n",
      "        https://w3id.org/emmo#EMMO_f35cff4d_dc09_44cf_a729_22fb79e3bfb2 InternationalSystemOfQuantity is subClassOf https://w3id.org/emmo#EMMO_9c407ac0_fd4c_4178_8763_95fad9fe29ec StandardizedPhysicalQuantity (from )\n",
      "          https://w3id.org/emmo#EMMO_9c407ac0_fd4c_4178_8763_95fad9fe29ec StandardizedPhysicalQuantity is subClassOf https://w3id.org/emmo#EMMO_02c0621e_a527_4790_8a0f_2bb51973c819 PhysicalQuantity (from In the same system of quantities, dim B = ML3 is the quantity dimension of mass concentration of component B, and ML3 is also the quantity dimension of mass density, .\n",
      "ISO 80000-1 Measured or simulated 'physical propertiy'-s are always defined by a physical law, connected to a physical entity through a model perspective and measurement is done according to the same model.\n",
      "\n",
      "Systems of units suggests that this is the correct approach, since except for the fundamental units (length, time, charge) every other unit is derived by mathematical relations between these fundamental units, implying a physical laws or definitions. Measurement units of quantities of the same quantity dimension may be designated by the same name and symbol even when the quantities are not of the same kind.\n",
      "\n",
      "For example, joule per kelvin and J/K are respectively the name and symbol of both a measurement unit of heat capacity and a measurement unit of entropy, which are generally not considered to be quantities of the same kind.\n",
      "\n",
      "However, in some cases special measurement unit names are restricted to be used with quantities of specific kind only.\n",
      "\n",
      "For example, the measurement unit second to the power minus one (1/s) is called hertz (Hz) when used for frequencies and becquerel (Bq) when used for activities of radionuclides.\n",
      "\n",
      "As another example, the joule (J) is used as a unit of energy, but never as a unit of moment of force, i.e. the newton metre (N  m).  quantities of the same kind have the same quantity dimension,\n",
      " quantities of different quantity dimensions are always of different kinds, and\n",
      " quantities having the same quantity dimension are not necessarily of the same kind.\n",
      "ISO 80000-1)\n",
      "http://semanticscience.org/resource/Strain strain is subClassOf http://semanticscience.org/resource/Organism organism (from A biological organisn is a biological entity that consists of one or more cells and is capable of genomic replication (independently or not).)\n",
      "  http://semanticscience.org/resource/Organism organism is subClassOf http://semanticscience.org/resource/BiologicalEntity biological entity (from A biological entity is a heterogeneous substance that contains genomic material or is the product of a biological process.)\n",
      "    http://semanticscience.org/resource/BiologicalEntity biological entity is subClassOf http://semanticscience.org/resource/HeterogeneousSubstance heterogeneous substance (from A heterogeneous substance is a chemical substance that is composed of more than one different kind of component.)\n",
      "      http://semanticscience.org/resource/HeterogeneousSubstance heterogeneous substance is subClassOf http://semanticscience.org/resource/ChemicalSubstance chemical substance (from A chemical substance is a chemical entity composed of two or more weakly (non-covalently) interacting chemical entities.)\n",
      "        http://semanticscience.org/resource/ChemicalSubstance chemical substance is subClassOf http://semanticscience.org/resource/ChemicalEntity chemical entity (from A chemical entity is a material entity that pertains to chemistry.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          http://semanticscience.org/resource/ChemicalEntity chemical entity is subClassOf http://semanticscience.org/resource/MaterialEntity Material Entity (from A material entity is a physical entity that is spatially extended, exists as a whole at any point in time and has mass. A material entity is a physical entity that is spatially extended, exists as a whole at any point in time and has mass.)\n",
      "            http://semanticscience.org/resource/MaterialEntity Material Entity is subClassOf http://semanticscience.org/resource/Object object (from An object is an entity that is wholly identifiable at any instant of time during which it exists.)\n",
      "              https://w3id.org/emmo#EMMO_6f5af708_f825_4feb_a0d1_a8d813d3022b Object is equivalentClass Complex class expression  (from Complex class expression)\n",
      "              https://w3id.org/pmd/co/Object Object is subClassOf http://www.w3.org/ns/prov#Entity  (from )\n",
      "              http://semanticscience.org/resource/Object object is subClassOf http://semanticscience.org/resource/Entity entity (from Every thing is an entity.)\n",
      "                http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing  (from )\n",
      "          https://w3id.org/emmo#EMMO_47338839_6cca_4a8e_b565_3c4d5517e2c0 ChemicalEntity is subClassOf https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance (from )\n",
      "            https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance is subClassOf https://w3id.org/emmo#EMMO_38b579de_4331_40e0_803d_09efa298e726 PhysicalObject (from )\n",
      "          https://w3id.org/emmo#EMMO_21205421_5783_4d3e_81e5_10c5d894a88a ChemicalEntity is subClassOf https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance (from )\n",
      "            https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance is subClassOf https://w3id.org/emmo#EMMO_38b579de_4331_40e0_803d_09efa298e726 PhysicalObject (from )\n",
      "          https://w3id.org/emmo#EMMO_21205421_5783_4d3e_81e5_10c5d894a88a ChemicalEntity is subClassOf https://w3id.org/emmo#EMMO_8b1367d6_0133_4b56_acc1_fa8b058169e3 CompositePhysicalParticle (from )\n",
      "            https://w3id.org/emmo#EMMO_8b1367d6_0133_4b56_acc1_fa8b058169e3 CompositePhysicalParticle is subClassOf https://w3id.org/emmo#EMMO_38b579de_4331_40e0_803d_09efa298e726 PhysicalObject (from )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        http://semanticscience.org/resource/ChemicalSubstance chemical substance is equivalentClass Complex class expression  (from Complex class expression)\n",
      "        https://w3id.org/emmo#EMMO_df96cbb6_b5ee_4222_8eab_b3675df24bea ChemicalSubstance is subClassOf https://w3id.org/emmo#EMMO_bc37743c_37c4_4ec7_9d58_d1aae5567352 Substance (from )\n",
      "          https://w3id.org/emmo#EMMO_bc37743c_37c4_4ec7_9d58_d1aae5567352 Substance is subClassOf https://w3id.org/emmo#EMMO_57d977ab_0036_4779_b59a_e47620afdb9c CompositePhysicalObject (from )\n",
      "          https://w3id.org/emmo#EMMO_bc37743c_37c4_4ec7_9d58_d1aae5567352 Substance is subClassOf https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance (from )\n",
      "            https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance is subClassOf https://w3id.org/emmo#EMMO_38b579de_4331_40e0_803d_09efa298e726 PhysicalObject (from )\n",
      "        https://w3id.org/emmo#EMMO_3397f270_dfc1_4500_8f6f_4d0d85ac5f71 ChemicalSubstance is subClassOf https://w3id.org/emmo#EMMO_21205421_5783_4d3e_81e5_10c5d894a88a ChemicalEntity (from Molecular entity is used as a general term for singular entities, irrespective of their nature, while chemical species stands for sets or ensembles of molecular entities.\n",
      "\n",
      "Note that the name of a compound may refer to the respective molecular entity or to the chemical species,)\n",
      "          http://semanticscience.org/resource/ChemicalEntity chemical entity is subClassOf http://semanticscience.org/resource/MaterialEntity Material Entity (from A material entity is a physical entity that is spatially extended, exists as a whole at any point in time and has mass. A material entity is a physical entity that is spatially extended, exists as a whole at any point in time and has mass.)\n",
      "            http://semanticscience.org/resource/MaterialEntity Material Entity is subClassOf http://semanticscience.org/resource/Object object (from An object is an entity that is wholly identifiable at any instant of time during which it exists.)\n",
      "              https://w3id.org/emmo#EMMO_6f5af708_f825_4feb_a0d1_a8d813d3022b Object is equivalentClass Complex class expression  (from Complex class expression)\n",
      "              https://w3id.org/pmd/co/Object Object is subClassOf http://www.w3.org/ns/prov#Entity  (from )\n",
      "              http://semanticscience.org/resource/Object object is subClassOf http://semanticscience.org/resource/Entity entity (from Every thing is an entity.)\n",
      "                http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing  (from )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          https://w3id.org/emmo#EMMO_47338839_6cca_4a8e_b565_3c4d5517e2c0 ChemicalEntity is subClassOf https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance (from )\n",
      "            https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance is subClassOf https://w3id.org/emmo#EMMO_38b579de_4331_40e0_803d_09efa298e726 PhysicalObject (from )\n",
      "          https://w3id.org/emmo#EMMO_21205421_5783_4d3e_81e5_10c5d894a88a ChemicalEntity is subClassOf https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance (from )\n",
      "            https://w3id.org/emmo#EMMO_5b2222df_4da6_442f_8244_96e9e45887d1 PhysicalSubstance is subClassOf https://w3id.org/emmo#EMMO_38b579de_4331_40e0_803d_09efa298e726 PhysicalObject (from )\n",
      "          https://w3id.org/emmo#EMMO_21205421_5783_4d3e_81e5_10c5d894a88a ChemicalEntity is subClassOf https://w3id.org/emmo#EMMO_8b1367d6_0133_4b56_acc1_fa8b058169e3 CompositePhysicalParticle (from )\n",
      "            https://w3id.org/emmo#EMMO_8b1367d6_0133_4b56_acc1_fa8b058169e3 CompositePhysicalParticle is subClassOf https://w3id.org/emmo#EMMO_38b579de_4331_40e0_803d_09efa298e726 PhysicalObject (from )\n",
      "  http://semanticscience.org/resource/Organism organism is equivalentClass Complex class expression  (from Complex class expression)\n",
      "https://w3id.org/emmo#EMMO_3a6578ac_aee0_43b9_9bc6_1eb208c8c9a9 Porosity is subClassOf https://w3id.org/emmo#EMMO_faab3f84_e475_4a46_af9c_7d249f0b9aef RatioQuantity (from Quantities defined as ratios `Q=A/B` having equal dimensions in numerator and denominator are dimensionless quantities but still have a physical dimension defined as dim(A)/dim(B).\n",
      "\n",
      "Johansson, Ingvar (2010). \"Metrological thinking needs the notions of parametric quantities, units and dimensions\". Metrologia. 47 (3): 219230. doi:10.1088/0026-1394/47/3/012. ISSN 0026-1394.)\n",
      "  https://w3id.org/emmo#EMMO_faab3f84_e475_4a46_af9c_7d249f0b9aef RatioQuantity is subClassOf https://w3id.org/emmo#EMMO_a66427d1_9932_4363_9ec5_7d91f2bfda1e ISQDimensionlessQuantity (from )\n",
      "    https://w3id.org/emmo#EMMO_a66427d1_9932_4363_9ec5_7d91f2bfda1e ISQDimensionlessQuantity is subClassOf https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 ISQDerivedQuantity (from )\n",
      "      https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 ISQDerivedQuantity is subClassOf https://w3id.org/emmo#EMMO_71f6ab56_342c_484b_bbe0_de86b7367cb3 DerivedQuantity (from )\n",
      "      https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 ISQDerivedQuantity is subClassOf https://w3id.org/emmo#EMMO_f35cff4d_dc09_44cf_a729_22fb79e3bfb2 InternationalSystemOfQuantity (from )\n",
      "        https://w3id.org/emmo#EMMO_f35cff4d_dc09_44cf_a729_22fb79e3bfb2 InternationalSystemOfQuantity is subClassOf https://w3id.org/emmo#EMMO_9c407ac0_fd4c_4178_8763_95fad9fe29ec StandardizedPhysicalQuantity (from )\n",
      "          https://w3id.org/emmo#EMMO_9c407ac0_fd4c_4178_8763_95fad9fe29ec StandardizedPhysicalQuantity is subClassOf https://w3id.org/emmo#EMMO_02c0621e_a527_4790_8a0f_2bb51973c819 PhysicalQuantity (from In the same system of quantities, dim B = ML3 is the quantity dimension of mass concentration of component B, and ML3 is also the quantity dimension of mass density, .\n",
      "ISO 80000-1 Measured or simulated 'physical propertiy'-s are always defined by a physical law, connected to a physical entity through a model perspective and measurement is done according to the same model.\n",
      "\n",
      "Systems of units suggests that this is the correct approach, since except for the fundamental units (length, time, charge) every other unit is derived by mathematical relations between these fundamental units, implying a physical laws or definitions. Measurement units of quantities of the same quantity dimension may be designated by the same name and symbol even when the quantities are not of the same kind.\n",
      "\n",
      "For example, joule per kelvin and J/K are respectively the name and symbol of both a measurement unit of heat capacity and a measurement unit of entropy, which are generally not considered to be quantities of the same kind.\n",
      "\n",
      "However, in some cases special measurement unit names are restricted to be used with quantities of specific kind only.\n",
      "\n",
      "For example, the measurement unit second to the power minus one (1/s) is called hertz (Hz) when used for frequencies and becquerel (Bq) when used for activities of radionuclides.\n",
      "\n",
      "As another example, the joule (J) is used as a unit of energy, but never as a unit of moment of force, i.e. the newton metre (N  m).  quantities of the same kind have the same quantity dimension,\n",
      " quantities of different quantity dimensions are always of different kinds, and\n",
      " quantities having the same quantity dimension are not necessarily of the same kind.\n",
      "ISO 80000-1)\n",
      "https://w3id.org/emmo#EMMO_09663630_1b84_4202_91e6_e641104f579e Permeability is subClassOf https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 ISQDerivedQuantity (from )\n",
      "  https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 ISQDerivedQuantity is subClassOf https://w3id.org/emmo#EMMO_71f6ab56_342c_484b_bbe0_de86b7367cb3 DerivedQuantity (from )\n",
      "  https://w3id.org/emmo#EMMO_2946d40b_24a1_47fa_8176_e3f79bb45064 ISQDerivedQuantity is subClassOf https://w3id.org/emmo#EMMO_f35cff4d_dc09_44cf_a729_22fb79e3bfb2 InternationalSystemOfQuantity (from )\n",
      "    https://w3id.org/emmo#EMMO_f35cff4d_dc09_44cf_a729_22fb79e3bfb2 InternationalSystemOfQuantity is subClassOf https://w3id.org/emmo#EMMO_9c407ac0_fd4c_4178_8763_95fad9fe29ec StandardizedPhysicalQuantity (from )\n",
      "      https://w3id.org/emmo#EMMO_9c407ac0_fd4c_4178_8763_95fad9fe29ec StandardizedPhysicalQuantity is subClassOf https://w3id.org/emmo#EMMO_02c0621e_a527_4790_8a0f_2bb51973c819 PhysicalQuantity (from In the same system of quantities, dim B = ML3 is the quantity dimension of mass concentration of component B, and ML3 is also the quantity dimension of mass density, .\n",
      "ISO 80000-1 Measured or simulated 'physical propertiy'-s are always defined by a physical law, connected to a physical entity through a model perspective and measurement is done according to the same model.\n",
      "\n",
      "Systems of units suggests that this is the correct approach, since except for the fundamental units (length, time, charge) every other unit is derived by mathematical relations between these fundamental units, implying a physical laws or definitions. Measurement units of quantities of the same quantity dimension may be designated by the same name and symbol even when the quantities are not of the same kind.\n",
      "\n",
      "For example, joule per kelvin and J/K are respectively the name and symbol of both a measurement unit of heat capacity and a measurement unit of entropy, which are generally not considered to be quantities of the same kind.\n",
      "\n",
      "However, in some cases special measurement unit names are restricted to be used with quantities of specific kind only.\n",
      "\n",
      "For example, the measurement unit second to the power minus one (1/s) is called hertz (Hz) when used for frequencies and becquerel (Bq) when used for activities of radionuclides.\n",
      "\n",
      "As another example, the joule (J) is used as a unit of energy, but never as a unit of moment of force, i.e. the newton metre (N  m).  quantities of the same kind have the same quantity dimension,\n",
      " quantities of different quantity dimensions are always of different kinds, and\n",
      " quantities having the same quantity dimension are not necessarily of the same kind.\n",
      "ISO 80000-1)\n",
      "https://w3id.org/emmo#EMMO_09663630_1b84_4202_91e6_e641104f579e Permeability is subClassOf https://w3id.org/emmo#EMMO_602397bd_e302_42a6_be33_fe67ea81933a Intensive (from Note that not all physical quantities can be categorised as being either intensive or extensive. For example the square root of the mass.)\n",
      "  https://w3id.org/emmo#EMMO_602397bd_e302_42a6_be33_fe67ea81933a Intensive is subClassOf https://w3id.org/emmo#EMMO_79751276_b2d0_4e2f_bbd4_99d412f43d55 CategorizedPhysicalQuantity (from )\n",
      "    https://w3id.org/emmo#EMMO_79751276_b2d0_4e2f_bbd4_99d412f43d55 CategorizedPhysicalQuantity is subClassOf https://w3id.org/emmo#EMMO_02c0621e_a527_4790_8a0f_2bb51973c819 PhysicalQuantity (from In the same system of quantities, dim B = ML3 is the quantity dimension of mass concentration of component B, and ML3 is also the quantity dimension of mass density, .\n",
      "ISO 80000-1 Measured or simulated 'physical propertiy'-s are always defined by a physical law, connected to a physical entity through a model perspective and measurement is done according to the same model.\n",
      "\n",
      "Systems of units suggests that this is the correct approach, since except for the fundamental units (length, time, charge) every other unit is derived by mathematical relations between these fundamental units, implying a physical laws or definitions. Measurement units of quantities of the same quantity dimension may be designated by the same name and symbol even when the quantities are not of the same kind.\n",
      "\n",
      "For example, joule per kelvin and J/K are respectively the name and symbol of both a measurement unit of heat capacity and a measurement unit of entropy, which are generally not considered to be quantities of the same kind.\n",
      "\n",
      "However, in some cases special measurement unit names are restricted to be used with quantities of specific kind only.\n",
      "\n",
      "For example, the measurement unit second to the power minus one (1/s) is called hertz (Hz) when used for frequencies and becquerel (Bq) when used for activities of radionuclides.\n",
      "\n",
      "As another example, the joule (J) is used as a unit of energy, but never as a unit of moment of force, i.e. the newton metre (N  m).  quantities of the same kind have the same quantity dimension,\n",
      " quantities of different quantity dimensions are always of different kinds, and\n",
      " quantities having the same quantity dimension are not necessarily of the same kind.\n",
      "ISO 80000-1)\n",
      "https://w3id.org/emmo#EMMO_09663630_1b84_4202_91e6_e641104f579e Permeability is subClassOf https://w3id.org/emmo#EMMO_af794e9d_dc7d_4756_83e1_2cd0e2ec864e ElectromagneticQuantity (from )\n",
      "  https://w3id.org/emmo#EMMO_af794e9d_dc7d_4756_83e1_2cd0e2ec864e ElectromagneticQuantity is subClassOf https://w3id.org/emmo#EMMO_2ce04004_62cf_4394_b6a2_b45fce1aebfe ISO80000Categorised (from )\n",
      "    https://w3id.org/emmo#EMMO_2ce04004_62cf_4394_b6a2_b45fce1aebfe ISO80000Categorised is subClassOf https://w3id.org/emmo#EMMO_79751276_b2d0_4e2f_bbd4_99d412f43d55 CategorizedPhysicalQuantity (from )\n",
      "      https://w3id.org/emmo#EMMO_79751276_b2d0_4e2f_bbd4_99d412f43d55 CategorizedPhysicalQuantity is subClassOf https://w3id.org/emmo#EMMO_02c0621e_a527_4790_8a0f_2bb51973c819 PhysicalQuantity (from In the same system of quantities, dim B = ML3 is the quantity dimension of mass concentration of component B, and ML3 is also the quantity dimension of mass density, .\n",
      "ISO 80000-1 Measured or simulated 'physical propertiy'-s are always defined by a physical law, connected to a physical entity through a model perspective and measurement is done according to the same model.\n",
      "\n",
      "Systems of units suggests that this is the correct approach, since except for the fundamental units (length, time, charge) every other unit is derived by mathematical relations between these fundamental units, implying a physical laws or definitions. Measurement units of quantities of the same quantity dimension may be designated by the same name and symbol even when the quantities are not of the same kind.\n",
      "\n",
      "For example, joule per kelvin and J/K are respectively the name and symbol of both a measurement unit of heat capacity and a measurement unit of entropy, which are generally not considered to be quantities of the same kind.\n",
      "\n",
      "However, in some cases special measurement unit names are restricted to be used with quantities of specific kind only.\n",
      "\n",
      "For example, the measurement unit second to the power minus one (1/s) is called hertz (Hz) when used for frequencies and becquerel (Bq) when used for activities of radionuclides.\n",
      "\n",
      "As another example, the joule (J) is used as a unit of energy, but never as a unit of moment of force, i.e. the newton metre (N  m).  quantities of the same kind have the same quantity dimension,\n",
      " quantities of different quantity dimensions are always of different kinds, and\n",
      " quantities having the same quantity dimension are not necessarily of the same kind.\n",
      "ISO 80000-1)\n",
      "http://materialsmine.org/ns/MechanicalProperty Mechanical Property is subClassOf http://semanticscience.org/resource/Quantity Amount (from A quantity is an informational entity that gives the magnitude of a property.)\n",
      "  http://semanticscience.org/resource/Quantity Amount is subClassOf http://semanticscience.org/resource/MeasurementValue measurement value (from A measurement value is a quantitative description that reflects the magnitude of some attribute.)\n",
      "    http://semanticscience.org/resource/MeasurementValue measurement value is subClassOf http://semanticscience.org/resource/Number number (from A number is a tensor of rank 0.)\n",
      "      http://semanticscience.org/resource/Number number is subClassOf http://semanticscience.org/resource/Scalar scalar (from a scalar is a rank 0 tensor and is an element of a field that is used to define a vector space.)\n",
      "        http://semanticscience.org/resource/Scalar scalar is subClassOf http://semanticscience.org/resource/Tensor tensor (from a tensor is a n-dimensional array.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          http://semanticscience.org/resource/Tensor tensor is subClassOf http://semanticscience.org/resource/MathematicalEntity mathematical entity (from A mathematical entity is an information content entity that are components of a mathematical system or can be defined in mathematical terms.)\n",
      "            http://semanticscience.org/resource/MathematicalEntity mathematical entity is subClassOf http://semanticscience.org/resource/InformationContentEntity information content entity (from information content entity is an object that requires some background knowledge or procedure to correctly interpret.)\n",
      "              http://semanticscience.org/resource/InformationContentEntity information content entity is subClassOf http://semanticscience.org/resource/Object object (from An object is an entity that is wholly identifiable at any instant of time during which it exists.)\n",
      "                https://w3id.org/emmo#EMMO_6f5af708_f825_4feb_a0d1_a8d813d3022b Object is equivalentClass Complex class expression  (from Complex class expression)\n",
      "                https://w3id.org/pmd/co/Object Object is subClassOf http://www.w3.org/ns/prov#Entity  (from )\n",
      "                http://semanticscience.org/resource/Object object is subClassOf http://semanticscience.org/resource/Entity entity (from Every thing is an entity.)\n",
      "                  http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing  (from )\n",
      "  http://semanticscience.org/resource/Quantity Amount is equivalentClass Complex class expression  (from Complex class expression)\n",
      "Class hierarchy has been saved to class_hierarchy.csv\n"
     ]
    }
   ],
   "source": [
    "process_ontology(ontology_files, initial_class_names_to_check, output_hierarchy_file, class_output_file, relations_output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace, URIRef, Literal, BNode\n",
    "\n",
    "\n",
    "directory = '.'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        os.remove(os.path.join(directory, filename))\n",
    "\n",
    "\n",
    "# Define namespaces (assuming these are already defined in your script)\n",
    "ex = Namespace(\"http://example.org/ontology/\")\n",
    "sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "materialsmine = Namespace(\"http://materialsmine.org/ns/\")\n",
    "bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "xml = Namespace(\"http://www.w3.org/XML/1998/namespace\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "isPartOf = dcterms.isPartOf\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
    "    s = s.replace('...', '')\n",
    "    return s\n",
    "\n",
    "def get_class_label(g, cls):\n",
    "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "    return labels[0] if labels else None\n",
    "\n",
    "def get_class_descriptions(g, cls):\n",
    "    descriptions = list(g.objects(cls, DCTERMS.description)) + list(g.objects(cls, SKOS.definition)) + list(g.objects(cls, RDFS.comment))\n",
    "    return \" \".join([str(desc) for desc in descriptions if desc is not None]) if descriptions else None\n",
    "\n",
    "\n",
    "def get_complex_expression_label(g, node):\n",
    "    if (node, RDF.type, OWL.Restriction) in g:\n",
    "        prop = list(g.objects(node, OWL.onProperty))\n",
    "        val = list(g.objects(node, OWL.someValuesFrom))\n",
    "        if prop and val:\n",
    "            prop_label = get_class_label(g, prop[0])\n",
    "            val_label = get_class_label(g, val[0])\n",
    "            return f\"Restriction on {prop_label} some {val_label}\"\n",
    "    elif (node, RDF.type, OWL.Class) in g:\n",
    "        intersection = list(g.objects(node, OWL.intersectionOf))\n",
    "        if intersection:\n",
    "            components = []\n",
    "            for item in g.items(intersection[0]):\n",
    "                if isinstance(item, URIRef):\n",
    "                    component_label = get_class_label(g, item)\n",
    "                    if component_label:\n",
    "                        components.append(component_label)\n",
    "                elif isinstance(item, BNode):\n",
    "                    restriction_label = get_complex_expression_label(g, item)\n",
    "                    if restriction_label:\n",
    "                        components.append(restriction_label)\n",
    "            if components:\n",
    "                return f\"Intersection of {' and '.join(components)}\"\n",
    "    return None\n",
    "\n",
    "def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "    if file_path.endswith('.ttl'):\n",
    "        file_format = 'ttl'\n",
    "    elif file_path.endswith('.owl'):\n",
    "        file_format = 'xml'\n",
    "    elif file_path.endswith('.xrdf'):\n",
    "        file_format = 'xml'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "    \n",
    "    g.parse(file_path, format=file_format)\n",
    "\n",
    "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "    data = []\n",
    "    relations = []\n",
    "    found_class_labels = set()\n",
    "\n",
    "    for cls in classes:\n",
    "        if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "            labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "            description = get_class_descriptions(g, cls)\n",
    "\n",
    "            for label in labels:\n",
    "                if label is not None:\n",
    "                    normalized_label = normalize_string(label)\n",
    "                    found_class_labels.add(normalized_label)\n",
    "\n",
    "                    if normalized_label in normalized_class_names_to_check:\n",
    "                        # Check if already processed in this iteration\n",
    "                        if str(cls) not in processed_classes:\n",
    "                            processed_classes.add(str(cls))\n",
    "                            data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, RDFS.subClassOf):\n",
    "                            if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, OWL.equivalentClass):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])                           \n",
    "                            else:\n",
    "                                # Handle blank nodes for equivalentClass\n",
    "                                obj_label = get_complex_expression_label(g, obj)\n",
    "                                obj_description = \"Complex class expression\"\n",
    "\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])\n",
    "\n",
    "                        for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "            \n",
    "\n",
    "    return data, relations, found_class_labels\n",
    "\n",
    "\n",
    "def filter_relations(all_relations, initial_class_names_to_check):\n",
    "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
    "\n",
    "\n",
    "def print_hierarchy(class_name, relations, g, writer):\n",
    "    def recursive_print(class_name, depth=0):\n",
    "        for relation in relations:\n",
    "            if normalize_string(relation[2]) == normalize_string(class_name):\n",
    "                subject_description = get_class_descriptions(g, URIRef(relation[1]))\n",
    "                object_description = get_class_descriptions(g, URIRef(relation[4]))\n",
    "                writer.writerow([relation[1], relation[2], subject_description if subject_description is not None else \"\", relation[3], relation[4], relation[5], object_description if object_description is not None else \"\", relation[0]])\n",
    "                indent = '  ' * depth\n",
    "                print(f\"{indent}{relation[1]} {relation[2]} is {relation[3]} {relation[4]} {relation} {relation[5]} (from {relation[0]})\")\n",
    "                recursive_print(relation[5], depth + 1)\n",
    "\n",
    "    recursive_print(class_name)\n",
    "\n",
    "\n",
    "output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "class_output_file = \"ontology_classes.csv\"\n",
    "relations_output_file = \"ontology_relations.csv\"\n",
    "\n",
    "all_data = []\n",
    "all_relations = []\n",
    "all_found_class_labels = set()\n",
    "\n",
    "class_names_to_check = initial_class_names_to_check\n",
    "\n",
    "max_iterations = 2\n",
    "iteration_count = 0\n",
    "g = Graph()\n",
    "processed_classes = set()\n",
    "processed_relations = set()\n",
    "last_class_name_written = None  # Track the last class name written\n",
    "\n",
    "\n",
    "while class_names_to_check and iteration_count < max_iterations:\n",
    "    iteration_count += 1\n",
    "    new_data = []\n",
    "    new_relations = []\n",
    "    new_found_class_labels = set()\n",
    "\n",
    "    for ontology_file in ontology_files:\n",
    "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check, g, processed_classes, processed_relations)\n",
    "        new_data.extend(file_data)\n",
    "        new_relations.extend(file_relations)\n",
    "        new_found_class_labels.update(found_class_labels)\n",
    "\n",
    "    all_data.extend(new_data)\n",
    "    all_relations.extend(new_relations)\n",
    "    all_found_class_labels.update(new_found_class_labels)\n",
    "\n",
    "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
    "\n",
    "    # Filter and save class data\n",
    "    filtered_data = [row for row in new_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
    "    with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_data:\n",
    "            current_class_name = filtered_data[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_data)\n",
    "\n",
    "    # Filter and save class relations\n",
    "    filtered_relations = filter_relations(new_relations, initial_class_names_to_check)\n",
    "    with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_relations:\n",
    "            current_class_name = filtered_relations[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_relations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
    "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
    "\n",
    "print(\"\\nInitial class names found in the output:\")\n",
    "for class_name in initial_class_names_to_check:\n",
    "    normalized_class_name = normalize_string(class_name)\n",
    "    found = False\n",
    "    for label in all_found_class_labels:\n",
    "        if normalized_class_name in label:\n",
    "            found = True\n",
    "            print(f\"Class '{class_name}' found in:\")\n",
    "            for ontology_file in ontology_files:\n",
    "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check, g, processed_classes, processed_relations)\n",
    "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
    "                if normalized_class_name in normalized_labels:\n",
    "                    print(f\"- {ontology_file}\")\n",
    "            break\n",
    "    if not found:\n",
    "        print(f\"Class '{class_name}' not found in the output.\")\n",
    "\n",
    "print(\"\\nSaving class hierarchy to CSV file:\")\n",
    "with open(output_hierarchy_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Class URI\", \"Class Name\", \"Class Description\", \"Relation Type\", \"Related Class URI\", \"Related Class Name\", \"Related Class Description\", \"File\"])\n",
    "    for class_name in initial_class_names_to_check:\n",
    "        normalized_class_name = normalize_string(class_name)\n",
    "        print_hierarchy(normalized_class_name, all_relations, g, writer)\n",
    "\n",
    "print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n",
    "\n",
    "def save_intersection_info_to_csv(data, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Inside your main loop where you process ontology files:\n",
    "intersection_data = [row for row in all_data if row[3].startswith(\"Intersection of\")]\n",
    "save_intersection_info_to_csv(intersection_data, \"intersection_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
