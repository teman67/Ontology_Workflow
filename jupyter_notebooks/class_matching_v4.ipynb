{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Starting v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered class data has been saved to ontology_classes.csv\n",
      "Filtered class relations have been saved to ontology_relations.csv\n",
      "\n",
      "Initial class names found in the output:\n",
      "Class 'Compression' found in:\n",
      "- ../Ontologies/materialsmine_converted.ttl\n",
      "- ../Ontologies/pmdco_core.ttl\n",
      "- ../Ontologies/nfdicore_2.ttl\n",
      "Class 'AmperePerJoule' not found in the output.\n",
      "Class 'nfdi' not found in the output.\n",
      "Class 'stress' found in:\n",
      "- ../Ontologies/materialsmine_converted.ttl\n",
      "- ../Ontologies/pmdco_core.ttl\n",
      "- ../Ontologies/nfdicore_2.ttl\n",
      "Class 'Advertiser+content_Article' not found in the output.\n",
      "Class 'Tensiletest' found in:\n",
      "- ../Ontologies/materialsmine_converted.ttl\n",
      "- ../Ontologies/pmdco_core.ttl\n",
      "- ../Ontologies/nfdicore_2.ttl\n",
      "\n",
      "Saving class hierarchy to CSV file:\n",
      "http://materialsmine.org/ns/Compression Compression is subClassOf http://materialsmine.org/ns/ViscoelasticProperty ['../Ontologies/materialsmine_converted.ttl', 'http://materialsmine.org/ns/Compression', 'Compression', 'subClassOf', 'http://materialsmine.org/ns/ViscoelasticProperty', 'Viscoelastic Property', 'Properties of materials that exhibit both viscous and elastic behaviors'] Viscoelastic Property (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://materialsmine.org/ns/ViscoelasticProperty Viscoelastic Property is subClassOf http://semanticscience.org/resource/Quantity ['../Ontologies/materialsmine_converted.ttl', 'http://materialsmine.org/ns/ViscoelasticProperty', 'Viscoelastic Property', 'subClassOf', 'http://semanticscience.org/resource/Quantity', 'Amount', 'A quantity is an informational entity that gives the magnitude of a property.'] Amount (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/Quantity Amount is subClassOf http://semanticscience.org/resource/MeasurementValue ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Quantity', 'Amount', 'subClassOf', 'http://semanticscience.org/resource/MeasurementValue', 'measurement value', 'A measurement value is a quantitative description that reflects the magnitude of some attribute.'] measurement value (from ../Ontologies/materialsmine_converted.ttl)\n",
      "      http://semanticscience.org/resource/MeasurementValue measurement value is subClassOf http://semanticscience.org/resource/Number ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/MeasurementValue', 'measurement value', 'subClassOf', 'http://semanticscience.org/resource/Number', 'number', 'A number is a tensor of rank 0.'] number (from ../Ontologies/materialsmine_converted.ttl)\n",
      "        http://semanticscience.org/resource/Number number is subClassOf http://semanticscience.org/resource/Scalar ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Number', 'number', 'subClassOf', 'http://semanticscience.org/resource/Scalar', 'scalar', 'a scalar is a rank 0 tensor and is an element of a field that is used to define a vector space.'] scalar (from ../Ontologies/materialsmine_converted.ttl)\n",
      "          http://semanticscience.org/resource/Scalar scalar is subClassOf http://semanticscience.org/resource/Tensor ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Scalar', 'scalar', 'subClassOf', 'http://semanticscience.org/resource/Tensor', 'tensor', 'a tensor is a n-dimensional array.'] tensor (from ../Ontologies/materialsmine_converted.ttl)\n",
      "            http://semanticscience.org/resource/Tensor tensor is subClassOf http://semanticscience.org/resource/MathematicalEntity ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Tensor', 'tensor', 'subClassOf', 'http://semanticscience.org/resource/MathematicalEntity', 'mathematical entity', 'A mathematical entity is an information content entity that are components of a mathematical system or can be defined in mathematical terms.'] mathematical entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "              http://semanticscience.org/resource/MathematicalEntity mathematical entity is subClassOf http://semanticscience.org/resource/InformationContentEntity ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/MathematicalEntity', 'mathematical entity', 'subClassOf', 'http://semanticscience.org/resource/InformationContentEntity', 'information content entity', 'information content entity is an object that requires some background knowledge or procedure to correctly interpret.'] information content entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                http://semanticscience.org/resource/InformationContentEntity information content entity is subClassOf http://semanticscience.org/resource/Object ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/InformationContentEntity', 'information content entity', 'subClassOf', 'http://semanticscience.org/resource/Object', 'object', 'An object is an entity that is wholly identifiable at any instant of time during which it exists.'] object (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                  http://semanticscience.org/resource/Object object is subClassOf http://semanticscience.org/resource/Entity ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Object', 'object', 'subClassOf', 'http://semanticscience.org/resource/Entity', 'entity', 'Every thing is an entity.'] entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                    http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Entity', 'entity', 'subClassOf', 'http://www.w3.org/2002/07/owl#Thing', '', '']  (from ../Ontologies/materialsmine_converted.ttl)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  https://w3id.org/pmd/co/Object Object is subClassOf http://www.w3.org/ns/prov#Entity ['../Ontologies/materialsmine_converted.ttl', 'https://w3id.org/pmd/co/Object', 'Object', 'subClassOf', 'http://www.w3.org/ns/prov#Entity', '', '']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/Quantity Amount is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Quantity', 'Amount', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/Quantity Amount is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Quantity', 'Amount', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "http://materialsmine.org/ns/Stress Stress is subClassOf http://materialsmine.org/ns/MechanicalProperty ['../Ontologies/materialsmine_converted.ttl', 'http://materialsmine.org/ns/Stress', 'Stress', 'subClassOf', 'http://materialsmine.org/ns/MechanicalProperty', 'Mechanical Property', 'A materials property related to the response of a material under some external applied load.'] Mechanical Property (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://materialsmine.org/ns/MechanicalProperty Mechanical Property is subClassOf http://semanticscience.org/resource/Quantity ['../Ontologies/materialsmine_converted.ttl', 'http://materialsmine.org/ns/MechanicalProperty', 'Mechanical Property', 'subClassOf', 'http://semanticscience.org/resource/Quantity', 'Amount', 'A quantity is an informational entity that gives the magnitude of a property.'] Amount (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/Quantity Amount is subClassOf http://semanticscience.org/resource/MeasurementValue ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Quantity', 'Amount', 'subClassOf', 'http://semanticscience.org/resource/MeasurementValue', 'measurement value', 'A measurement value is a quantitative description that reflects the magnitude of some attribute.'] measurement value (from ../Ontologies/materialsmine_converted.ttl)\n",
      "      http://semanticscience.org/resource/MeasurementValue measurement value is subClassOf http://semanticscience.org/resource/Number ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/MeasurementValue', 'measurement value', 'subClassOf', 'http://semanticscience.org/resource/Number', 'number', 'A number is a tensor of rank 0.'] number (from ../Ontologies/materialsmine_converted.ttl)\n",
      "        http://semanticscience.org/resource/Number number is subClassOf http://semanticscience.org/resource/Scalar ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Number', 'number', 'subClassOf', 'http://semanticscience.org/resource/Scalar', 'scalar', 'a scalar is a rank 0 tensor and is an element of a field that is used to define a vector space.'] scalar (from ../Ontologies/materialsmine_converted.ttl)\n",
      "          http://semanticscience.org/resource/Scalar scalar is subClassOf http://semanticscience.org/resource/Tensor ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Scalar', 'scalar', 'subClassOf', 'http://semanticscience.org/resource/Tensor', 'tensor', 'a tensor is a n-dimensional array.'] tensor (from ../Ontologies/materialsmine_converted.ttl)\n",
      "            http://semanticscience.org/resource/Tensor tensor is subClassOf http://semanticscience.org/resource/MathematicalEntity ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Tensor', 'tensor', 'subClassOf', 'http://semanticscience.org/resource/MathematicalEntity', 'mathematical entity', 'A mathematical entity is an information content entity that are components of a mathematical system or can be defined in mathematical terms.'] mathematical entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "              http://semanticscience.org/resource/MathematicalEntity mathematical entity is subClassOf http://semanticscience.org/resource/InformationContentEntity ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/MathematicalEntity', 'mathematical entity', 'subClassOf', 'http://semanticscience.org/resource/InformationContentEntity', 'information content entity', 'information content entity is an object that requires some background knowledge or procedure to correctly interpret.'] information content entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                http://semanticscience.org/resource/InformationContentEntity information content entity is subClassOf http://semanticscience.org/resource/Object ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/InformationContentEntity', 'information content entity', 'subClassOf', 'http://semanticscience.org/resource/Object', 'object', 'An object is an entity that is wholly identifiable at any instant of time during which it exists.'] object (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                  http://semanticscience.org/resource/Object object is subClassOf http://semanticscience.org/resource/Entity ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Object', 'object', 'subClassOf', 'http://semanticscience.org/resource/Entity', 'entity', 'Every thing is an entity.'] entity (from ../Ontologies/materialsmine_converted.ttl)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Entity', 'entity', 'subClassOf', 'http://www.w3.org/2002/07/owl#Thing', '', '']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "                  https://w3id.org/pmd/co/Object Object is subClassOf http://www.w3.org/ns/prov#Entity ['../Ontologies/materialsmine_converted.ttl', 'https://w3id.org/pmd/co/Object', 'Object', 'subClassOf', 'http://www.w3.org/ns/prov#Entity', '', '']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/Quantity Amount is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Quantity', 'Amount', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/Quantity Amount is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Quantity', 'Amount', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "https://w3id.org/pmd/co/Stress Stress is subClassOf https://w3id.org/pmd/co/ValueObject ['../Ontologies/pmdco_core.ttl', 'https://w3id.org/pmd/co/Stress', 'Stress', 'subClassOf', 'https://w3id.org/pmd/co/ValueObject', 'Value Object', 'A :ValueObject is a simple entity which represents a specific value. This value can be a numerical, textual, or a more complex data structure. If a literal value is to be specified, the :value datatype property has to be used. In cases where the value is represented by a resource (e.g. URI), the :resource object property has to be used.\\n\\nA value object, respectively its value, is always associated with an entity of type :Process, :ProcessingNode, or :Object (e.g. :Specimen). The value is meant to be a charactaristic of the associated entity. To express this association it is indended to use the :participant object property.\\n\\nA value object might also refer to a certain unit. The :unit property might be used (e.g. with QUDT ontology).\\n\\nInstances of a value object might be specified as a specific Parameter, namely a SetPoint (nominal value), or Measurement. With :Setpoint the intend is to express, that the value is meant to be some preset, setting or nominal value. :Measurement expresses, that the value has been measured or determined somehow (see example).\\n\\nInstances of a value object might also be specified in a specific DataScope (:Metadata, :PrimaryData, :SecondaryData).'] Value Object (from ../Ontologies/pmdco_core.ttl)\n",
      "  https://w3id.org/pmd/co/ValueObject Value Object is subClassOf http://www.w3.org/ns/prov#Entity ['../Ontologies/materialsmine_converted.ttl', 'https://w3id.org/pmd/co/ValueObject', 'Value Object', 'subClassOf', 'http://www.w3.org/ns/prov#Entity', '', '']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  https://w3id.org/pmd/co/ValueObject Value Object is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'https://w3id.org/pmd/co/ValueObject', 'Value Object', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  https://w3id.org/pmd/co/ValueObject Value Object is equivalentClass Complex class expression ['../Ontologies/pmdco_core.ttl', 'https://w3id.org/pmd/co/ValueObject', 'Value Object', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/pmdco_core.ttl)\n",
      "https://w3id.org/pmd/co/Stress Stress is equivalentClass Complex class expression ['../Ontologies/pmdco_core.ttl', 'https://w3id.org/pmd/co/Stress', 'Stress', 'equivalentClass', 'Complex class expression', 'Intersection of Restriction on relates to some Area and Restriction on relates to some Force', 'Complex class expression'] Intersection of Restriction on relates to some Area and Restriction on relates to some Force (from ../Ontologies/pmdco_core.ttl)\n",
      "https://w3id.org/pmd/co/TensileTest Tensile Test is subClassOf https://w3id.org/pmd/co/MechanicalTestingProcess ['../Ontologies/pmdco_core.ttl', 'https://w3id.org/pmd/co/TensileTest', 'Tensile Test', 'subClassOf', 'https://w3id.org/pmd/co/MechanicalTestingProcess', 'Mechanical Testing Process', 'Determinization of a mechanical property.'] Mechanical Testing Process (from ../Ontologies/pmdco_core.ttl)\n",
      "  https://w3id.org/pmd/co/MechanicalTestingProcess Mechanical Testing Process is subClassOf https://w3id.org/pmd/co/AnalysingProcess ['../Ontologies/materialsmine_converted.ttl', 'https://w3id.org/pmd/co/MechanicalTestingProcess', 'Mechanical Testing Process', 'subClassOf', 'https://w3id.org/pmd/co/AnalysingProcess', 'Analyseprozess', 'A process that is driven by the primary intent to gain new measurements\\nAn analysis process is either a transformative process or a non-transformative process.'] Analyseprozess (from ../Ontologies/materialsmine_converted.ttl)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    https://w3id.org/pmd/co/AnalysingProcess Analyseprozess is subClassOf https://w3id.org/pmd/co/Process ['../Ontologies/materialsmine_converted.ttl', 'https://w3id.org/pmd/co/AnalysingProcess', 'Analyseprozess', 'subClassOf', 'https://w3id.org/pmd/co/Process', 'Process', 'A series of actions or operations conducing to an end\\nIn PMD, a process is conducted via processing nodes and has a discernable duration as part of a workflow. A process consumes objects and parameters. A process potentially generates new objects and measurements. A process is either a transformative process or a non-transformative process with respect to objects processed via a processing node. There are primarily two types of distinguishable processes: manufacture process, analysis process. A process is a series of operations that are subordinate processes.'] Process (from ../Ontologies/materialsmine_converted.ttl)\n",
      "      https://w3id.org/pmd/co/Process Process is subClassOf http://www.w3.org/ns/prov#Activity ['../Ontologies/materialsmine_converted.ttl', 'https://w3id.org/pmd/co/Process', 'Process', 'subClassOf', 'http://www.w3.org/ns/prov#Activity', '', '']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "      http://semanticscience.org/resource/Process process is subClassOf http://semanticscience.org/resource/Entity ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Process', 'process', 'subClassOf', 'http://semanticscience.org/resource/Entity', 'entity', 'Every thing is an entity.'] entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "        http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Entity', 'entity', 'subClassOf', 'http://www.w3.org/2002/07/owl#Thing', '', '']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "https://w3id.org/pmd/co/TensileTest Tensile Test is equivalentClass Complex class expression ['../Ontologies/pmdco_core.ttl', 'https://w3id.org/pmd/co/TensileTest', 'Tensile Test', 'equivalentClass', 'Complex class expression', 'Restriction on has participant some Tensile Testing Machine', 'Complex class expression'] Restriction on has participant some Tensile Testing Machine (from ../Ontologies/pmdco_core.ttl)\n",
      "https://w3id.org/pmd/co/TensileTest Tensile Test is equivalentClass Complex class expression ['../Ontologies/pmdco_core.ttl', 'https://w3id.org/pmd/co/TensileTest', 'Tensile Test', 'equivalentClass', 'Complex class expression', 'Restriction on has participant some Prüfkörper', 'Complex class expression'] Restriction on has participant some Prüfkörper (from ../Ontologies/pmdco_core.ttl)\n",
      "Class hierarchy has been saved to class_hierarchy.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace, URIRef, Literal, BNode\n",
    "\n",
    "\n",
    "directory = '.'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        os.remove(os.path.join(directory, filename))\n",
    "\n",
    "\n",
    "# Define namespaces (assuming these are already defined in your script)\n",
    "ex = Namespace(\"http://example.org/ontology/\")\n",
    "sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "materialsmine = Namespace(\"http://materialsmine.org/ns/\")\n",
    "bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "xml = Namespace(\"http://www.w3.org/XML/1998/namespace\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "isPartOf = dcterms.isPartOf\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
    "    s = s.replace('...', '')\n",
    "    return s\n",
    "\n",
    "def get_class_label(g, cls):\n",
    "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "    return labels[0] if labels else None\n",
    "\n",
    "def get_class_descriptions(g, cls):\n",
    "    descriptions = list(g.objects(cls, DCTERMS.description)) + list(g.objects(cls, SKOS.definition)) + list(g.objects(cls, RDFS.comment))\n",
    "    return \" \".join([str(desc) for desc in descriptions if desc is not None]) if descriptions else None\n",
    "\n",
    "\n",
    "def get_complex_expression_label(g, node):\n",
    "    if (node, RDF.type, OWL.Restriction) in g:\n",
    "        prop = list(g.objects(node, OWL.onProperty))\n",
    "        val = list(g.objects(node, OWL.someValuesFrom))\n",
    "        if prop and val:\n",
    "            prop_label = get_class_label(g, prop[0])\n",
    "            val_label = get_class_label(g, val[0])\n",
    "            return f\"Restriction on {prop_label} some {val_label}\"\n",
    "    elif (node, RDF.type, OWL.Class) in g:\n",
    "        intersection = list(g.objects(node, OWL.intersectionOf))\n",
    "        if intersection:\n",
    "            components = []\n",
    "            for item in g.items(intersection[0]):\n",
    "                if isinstance(item, URIRef):\n",
    "                    component_label = get_class_label(g, item)\n",
    "                    if component_label:\n",
    "                        components.append(component_label)\n",
    "                elif isinstance(item, BNode):\n",
    "                    restriction_label = get_complex_expression_label(g, item)\n",
    "                    if restriction_label:\n",
    "                        components.append(restriction_label)\n",
    "            if components:\n",
    "                return f\"Intersection of {' and '.join(components)}\"\n",
    "    return None\n",
    "\n",
    "def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "    if file_path.endswith('.ttl'):\n",
    "        file_format = 'ttl'\n",
    "    elif file_path.endswith('.owl'):\n",
    "        file_format = 'xml'\n",
    "    elif file_path.endswith('.xrdf'):\n",
    "        file_format = 'xml'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "    \n",
    "    g.parse(file_path, format=file_format)\n",
    "\n",
    "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "    data = []\n",
    "    relations = []\n",
    "    found_class_labels = set()\n",
    "\n",
    "    for cls in classes:\n",
    "        if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "            labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "            description = get_class_descriptions(g, cls)\n",
    "\n",
    "            for label in labels:\n",
    "                if label is not None:\n",
    "                    normalized_label = normalize_string(label)\n",
    "                    found_class_labels.add(normalized_label)\n",
    "\n",
    "                    if normalized_label in normalized_class_names_to_check:\n",
    "                        # Check if already processed in this iteration\n",
    "                        if str(cls) not in processed_classes:\n",
    "                            processed_classes.add(str(cls))\n",
    "                            data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, RDFS.subClassOf):\n",
    "                            if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, OWL.equivalentClass):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])                           \n",
    "                            else:\n",
    "                                # Handle blank nodes for equivalentClass\n",
    "                                obj_label = get_complex_expression_label(g, obj)\n",
    "                                obj_description = \"Complex class expression\"\n",
    "\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])\n",
    "\n",
    "                        for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "            \n",
    "\n",
    "    return data, relations, found_class_labels\n",
    "\n",
    "\n",
    "def filter_relations(all_relations, initial_class_names_to_check):\n",
    "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
    "\n",
    "\n",
    "def print_hierarchy(class_name, relations, g, writer):\n",
    "    def recursive_print(class_name, depth=0):\n",
    "        for relation in relations:\n",
    "            if normalize_string(relation[2]) == normalize_string(class_name):\n",
    "                subject_description = get_class_descriptions(g, URIRef(relation[1]))\n",
    "                object_description = get_class_descriptions(g, URIRef(relation[4]))\n",
    "                writer.writerow([relation[1], relation[2], subject_description if subject_description is not None else \"\", relation[3], relation[4], relation[5], object_description if object_description is not None else \"\", relation[0]])\n",
    "                indent = '  ' * depth\n",
    "                print(f\"{indent}{relation[1]} {relation[2]} is {relation[3]} {relation[4]} {relation} {relation[5]} (from {relation[0]})\")\n",
    "                recursive_print(relation[5], depth + 1)\n",
    "\n",
    "    recursive_print(class_name)\n",
    "\n",
    "\n",
    "output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "class_output_file = \"ontology_classes.csv\"\n",
    "relations_output_file = \"ontology_relations.csv\"\n",
    "\n",
    "all_data = []\n",
    "all_relations = []\n",
    "all_found_class_labels = set()\n",
    "\n",
    "class_names_to_check = initial_class_names_to_check\n",
    "\n",
    "max_iterations = 2\n",
    "iteration_count = 0\n",
    "g = Graph()\n",
    "processed_classes = set()\n",
    "processed_relations = set()\n",
    "last_class_name_written = None  # Track the last class name written\n",
    "\n",
    "\n",
    "while class_names_to_check and iteration_count < max_iterations:\n",
    "    iteration_count += 1\n",
    "    new_data = []\n",
    "    new_relations = []\n",
    "    new_found_class_labels = set()\n",
    "\n",
    "    for ontology_file in ontology_files:\n",
    "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check, g, processed_classes, processed_relations)\n",
    "        new_data.extend(file_data)\n",
    "        new_relations.extend(file_relations)\n",
    "        new_found_class_labels.update(found_class_labels)\n",
    "\n",
    "    all_data.extend(new_data)\n",
    "    all_relations.extend(new_relations)\n",
    "    all_found_class_labels.update(new_found_class_labels)\n",
    "\n",
    "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
    "\n",
    "    # Filter and save class data\n",
    "    filtered_data = [row for row in new_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
    "    with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_data:\n",
    "            current_class_name = filtered_data[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_data)\n",
    "\n",
    "    # Filter and save class relations\n",
    "    filtered_relations = filter_relations(new_relations, initial_class_names_to_check)\n",
    "    with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_relations:\n",
    "            current_class_name = filtered_relations[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_relations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
    "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
    "\n",
    "print(\"\\nInitial class names found in the output:\")\n",
    "for class_name in initial_class_names_to_check:\n",
    "    normalized_class_name = normalize_string(class_name)\n",
    "    found = False\n",
    "    for label in all_found_class_labels:\n",
    "        if normalized_class_name in label:\n",
    "            found = True\n",
    "            print(f\"Class '{class_name}' found in:\")\n",
    "            for ontology_file in ontology_files:\n",
    "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check, g, processed_classes, processed_relations)\n",
    "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
    "                if normalized_class_name in normalized_labels:\n",
    "                    print(f\"- {ontology_file}\")\n",
    "            break\n",
    "    if not found:\n",
    "        print(f\"Class '{class_name}' not found in the output.\")\n",
    "\n",
    "print(\"\\nSaving class hierarchy to CSV file:\")\n",
    "with open(output_hierarchy_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Class URI\", \"Class Name\", \"Class Description\", \"Relation Type\", \"Related Class URI\", \"Related Class Name\", \"Related Class Description\", \"File\"])\n",
    "    for class_name in initial_class_names_to_check:\n",
    "        normalized_class_name = normalize_string(class_name)\n",
    "        print_hierarchy(normalized_class_name, all_relations, g, writer)\n",
    "\n",
    "print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n",
    "\n",
    "def save_intersection_info_to_csv(data, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Inside your main loop where you process ontology files:\n",
    "intersection_data = [row for row in all_data if row[3].startswith(\"Intersection of\")]\n",
    "save_intersection_info_to_csv(intersection_data, \"intersection_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace, URIRef, Literal, BNode\n",
    "\n",
    "\n",
    "directory = '.'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        os.remove(os.path.join(directory, filename))\n",
    "\n",
    "\n",
    "# Define namespaces (assuming these are already defined in your script)\n",
    "ex = Namespace(\"http://example.org/ontology/\")\n",
    "sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "materialsmine = Namespace(\"http://materialsmine.org/ns/\")\n",
    "bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "xml = Namespace(\"http://www.w3.org/XML/1998/namespace\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "isPartOf = dcterms.isPartOf\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
    "    s = s.replace('...', '')\n",
    "    return s\n",
    "\n",
    "def get_class_label(g, cls):\n",
    "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "    return labels[0] if labels else None\n",
    "\n",
    "def get_class_descriptions(g, cls):\n",
    "    descriptions = list(g.objects(cls, DCTERMS.description)) + list(g.objects(cls, SKOS.definition)) + list(g.objects(cls, RDFS.comment))\n",
    "    return \" \".join([str(desc) for desc in descriptions if desc is not None]) if descriptions else None\n",
    "\n",
    "\n",
    "def get_complex_expression_label(g, node):\n",
    "    if (node, RDF.type, OWL.Restriction) in g:\n",
    "        prop = list(g.objects(node, OWL.onProperty))\n",
    "        val = list(g.objects(node, OWL.someValuesFrom))\n",
    "        if prop and val:\n",
    "            prop_label = get_class_label(g, prop[0])\n",
    "            val_label = get_class_label(g, val[0])\n",
    "            return f\"Restriction on {prop_label} some {val_label}\"\n",
    "    elif (node, RDF.type, OWL.Class) in g:\n",
    "        intersection = list(g.objects(node, OWL.intersectionOf))\n",
    "        if intersection:\n",
    "            components = []\n",
    "            for item in g.items(intersection[0]):\n",
    "                if isinstance(item, URIRef):\n",
    "                    component_label = get_class_label(g, item)\n",
    "                    if component_label:\n",
    "                        components.append(component_label)\n",
    "                elif isinstance(item, BNode):\n",
    "                    restriction_label = get_complex_expression_label(g, item)\n",
    "                    if restriction_label:\n",
    "                        components.append(restriction_label)\n",
    "            if components:\n",
    "                return f\"Intersection of {' and '.join(components)}\"\n",
    "    return None\n",
    "\n",
    "def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "    if file_path.endswith('.ttl'):\n",
    "        file_format = 'ttl'\n",
    "    elif file_path.endswith('.owl'):\n",
    "        file_format = 'xml'\n",
    "    elif file_path.endswith('.xrdf'):\n",
    "        file_format = 'xml'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "    \n",
    "    g.parse(file_path, format=file_format)\n",
    "\n",
    "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "    data = []\n",
    "    relations = []\n",
    "    found_class_labels = set()\n",
    "\n",
    "    for cls in classes:\n",
    "        if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "            labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "            description = get_class_descriptions(g, cls)\n",
    "\n",
    "            for label in labels:\n",
    "                if label is not None:\n",
    "                    normalized_label = normalize_string(label)\n",
    "                    found_class_labels.add(normalized_label)\n",
    "\n",
    "                    if normalized_label in normalized_class_names_to_check:\n",
    "                        # Check if already processed in this iteration\n",
    "                        if str(cls) not in processed_classes:\n",
    "                            processed_classes.add(str(cls))\n",
    "                            data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, RDFS.subClassOf):\n",
    "                            if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, OWL.equivalentClass):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])                           \n",
    "                            else:\n",
    "                                # Handle blank nodes for equivalentClass\n",
    "                                obj_label = get_complex_expression_label(g, obj)\n",
    "                                obj_description = \"Complex class expression\"\n",
    "\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])\n",
    "\n",
    "                        for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "            \n",
    "\n",
    "    return data, relations, found_class_labels\n",
    "\n",
    "\n",
    "def filter_relations(all_relations, initial_class_names_to_check):\n",
    "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
    "\n",
    "\n",
    "def print_hierarchy(class_name, relations, g, writer):\n",
    "    def recursive_print(class_name, depth=0):\n",
    "        for relation in relations:\n",
    "            if normalize_string(relation[2]) == normalize_string(class_name):\n",
    "                subject_description = get_class_descriptions(g, URIRef(relation[1]))\n",
    "                object_description = get_class_descriptions(g, URIRef(relation[4]))\n",
    "                writer.writerow([relation[1], relation[2], subject_description if subject_description is not None else \"\", relation[3], relation[4], relation[5], object_description if object_description is not None else \"\", relation[0]])\n",
    "                indent = '  ' * depth\n",
    "                print(f\"{indent}{relation[1]} {relation[2]} is {relation[3]} {relation[4]} {relation} {relation[5]} (from {relation[0]})\")\n",
    "                recursive_print(relation[5], depth + 1)\n",
    "\n",
    "    recursive_print(class_name)\n",
    "\n",
    "\n",
    "output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "class_output_file = \"ontology_classes.csv\"\n",
    "relations_output_file = \"ontology_relations.csv\"\n",
    "\n",
    "all_data = []\n",
    "all_relations = []\n",
    "all_found_class_labels = set()\n",
    "\n",
    "class_names_to_check = initial_class_names_to_check\n",
    "\n",
    "max_iterations = 2\n",
    "iteration_count = 0\n",
    "g = Graph()\n",
    "processed_classes = set()\n",
    "processed_relations = set()\n",
    "last_class_name_written = None  # Track the last class name written\n",
    "\n",
    "\n",
    "while class_names_to_check and iteration_count < max_iterations:\n",
    "    iteration_count += 1\n",
    "    new_data = []\n",
    "    new_relations = []\n",
    "    new_found_class_labels = set()\n",
    "\n",
    "    for ontology_file in ontology_files:\n",
    "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check, g, processed_classes, processed_relations)\n",
    "        new_data.extend(file_data)\n",
    "        new_relations.extend(file_relations)\n",
    "        new_found_class_labels.update(found_class_labels)\n",
    "\n",
    "    all_data.extend(new_data)\n",
    "    all_relations.extend(new_relations)\n",
    "    all_found_class_labels.update(new_found_class_labels)\n",
    "\n",
    "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
    "\n",
    "    # Filter and save class data\n",
    "    filtered_data = [row for row in new_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
    "    with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_data:\n",
    "            current_class_name = filtered_data[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_data)\n",
    "\n",
    "    # Filter and save class relations\n",
    "    filtered_relations = filter_relations(new_relations, initial_class_names_to_check)\n",
    "    with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_relations:\n",
    "            current_class_name = filtered_relations[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_relations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
    "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
    "\n",
    "print(\"\\nInitial class names found in the output:\")\n",
    "for class_name in initial_class_names_to_check:\n",
    "    normalized_class_name = normalize_string(class_name)\n",
    "    found = False\n",
    "    for label in all_found_class_labels:\n",
    "        if normalized_class_name in label:\n",
    "            found = True\n",
    "            print(f\"Class '{class_name}' found in:\")\n",
    "            for ontology_file in ontology_files:\n",
    "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check, g, processed_classes, processed_relations)\n",
    "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
    "                if normalized_class_name in normalized_labels:\n",
    "                    print(f\"- {ontology_file}\")\n",
    "            break\n",
    "    if not found:\n",
    "        print(f\"Class '{class_name}' not found in the output.\")\n",
    "\n",
    "print(\"\\nSaving class hierarchy to CSV file:\")\n",
    "with open(output_hierarchy_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Class URI\", \"Class Name\", \"Class Description\", \"Relation Type\", \"Related Class URI\", \"Related Class Name\", \"Related Class Description\", \"File\"])\n",
    "    for class_name in initial_class_names_to_check:\n",
    "        normalized_class_name = normalize_string(class_name)\n",
    "        print_hierarchy(normalized_class_name, all_relations, g, writer)\n",
    "\n",
    "print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n",
    "\n",
    "def save_intersection_info_to_csv(data, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Inside your main loop where you process ontology files:\n",
    "intersection_data = [row for row in all_data if row[3].startswith(\"Intersection of\")]\n",
    "save_intersection_info_to_csv(intersection_data, \"intersection_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class names to check\n",
    "initial_class_names_to_check = [ 'Compression','AmperePerJoule','nfdi','stress', 'Advertiser+content_Article', 'Tensiletest']\n",
    "# initial_class_names_to_check = [ 'TermVariant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of ontology files to process\n",
    "ontology_files = [\n",
    "    # \"../Ontologies/materialsmine.ttl\", ### is not complete!\n",
    "    \"../Ontologies/materialsmine_converted.ttl\",\n",
    "    \"../Ontologies/pmdco_core.ttl\",\n",
    "    \"../Ontologies/nfdicore_2.ttl\",\n",
    "    # \"../Ontologies/bfo.owl\", #### using this ---->  long time to proccess!\n",
    "    # \"../Ontologies/emmo.ttl\",\n",
    "    # \"../Ontologies/owlapi.xrdf\",\n",
    "    # \"../Ontologies/schemaorg.owl\",\n",
    "    # \"../Ontologies/MaterialsMine.xrdf\",\n",
    "    # '../Ontologies/emmo.owl', ### has problem of reading file\n",
    "    # \"../Ontologies/Physical_Activity_Ontology_V2.owl\",\n",
    "    # \"../Ontologies/Physical_Activity_Ontology_V2.xrdf\",\n",
    "    # \"../Ontologies/oboe.owl\",\n",
    "    \"../Ontologies/fabio.ttl\",\n",
    "    # Add more file paths as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace, URIRef, Literal, BNode\n",
    "\n",
    "\n",
    "directory = '.'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        os.remove(os.path.join(directory, filename))\n",
    "\n",
    "\n",
    "# Define namespaces (assuming these are already defined in your script)\n",
    "ex = Namespace(\"http://example.org/ontology/\")\n",
    "sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "materialsmine = Namespace(\"http://materialsmine.org/ns/\")\n",
    "bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "xml = Namespace(\"http://www.w3.org/XML/1998/namespace\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "isPartOf = dcterms.isPartOf\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
    "    s = s.replace('...', '')\n",
    "    return s\n",
    "\n",
    "def get_class_label(g, cls):\n",
    "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "    return labels[0] if labels else None\n",
    "\n",
    "def get_class_descriptions(g, cls):\n",
    "    descriptions = list(g.objects(cls, DCTERMS.description)) + list(g.objects(cls, SKOS.definition)) + list(g.objects(cls, RDFS.comment))\n",
    "    return \" \".join([str(desc) for desc in descriptions if desc is not None]) if descriptions else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_complex_expression_label(g, node):\n",
    "#     if (node, RDF.type, OWL.Restriction) in g:\n",
    "#         prop = list(g.objects(node, OWL.onProperty))\n",
    "#         val = list(g.objects(node, OWL.someValuesFrom))\n",
    "#         if prop and val:\n",
    "#             prop_label = get_class_label(g, prop[0])\n",
    "#             val_label = get_class_label(g, val[0])\n",
    "#             return f\"Restriction on {prop_label} some {val_label}\"\n",
    "#     elif (node, RDF.type, OWL.Class) in g:\n",
    "#         intersection = list(g.objects(node, OWL.intersectionOf))\n",
    "#         if intersection:\n",
    "#             components = []\n",
    "#             for item in g.items(intersection[0]):\n",
    "#                 if isinstance(item, URIRef):\n",
    "#                     component_label = get_class_label(g, item)\n",
    "#                     if component_label:\n",
    "#                         components.append(component_label)\n",
    "#                 elif isinstance(item, BNode):\n",
    "#                     restriction_label = get_complex_expression_label(g, item)\n",
    "#                     if restriction_label:\n",
    "#                         components.append(restriction_label)\n",
    "#             if components:\n",
    "#                 return f\"Intersection of {' and '.join(components)}\"\n",
    "#     return None\n",
    "\n",
    "def get_complex_expression_label(g, node):\n",
    "    if (node, RDF.type, OWL.Restriction) in g:\n",
    "        prop = list(g.objects(node, OWL.onProperty))\n",
    "        val = list(g.objects(node, OWL.someValuesFrom))\n",
    "        if prop and val:\n",
    "            prop_label = get_class_label(g, prop[0])\n",
    "            val_label = get_class_label(g, val[0])\n",
    "            return f\"Restriction on {prop_label} some {val_label}\"\n",
    "    elif (node, RDF.type, OWL.Class) in g:\n",
    "        equivalent_classes = list(g.objects(node, OWL.equivalentClass))\n",
    "        if equivalent_classes:\n",
    "            for equivalent_class in equivalent_classes:\n",
    "                if isinstance(equivalent_class, BNode):\n",
    "                    intersections = list(g.objects(equivalent_class, OWL.intersectionOf))\n",
    "                    if intersections:\n",
    "                        components = []\n",
    "                        for intersection in g.items(intersections[0]):\n",
    "                            if isinstance(intersection, URIRef):\n",
    "                                component_label = get_class_label(g, intersection)\n",
    "                                if component_label:\n",
    "                                    components.append(component_label)\n",
    "                            elif isinstance(intersection, BNode):\n",
    "                                restriction_labels = []\n",
    "                                for restriction_item in g.items(intersection):\n",
    "                                    if isinstance(restriction_item, BNode):\n",
    "                                        restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                        if restriction_label:\n",
    "                                            restriction_labels.append(restriction_label)\n",
    "                                if restriction_labels:\n",
    "                                    components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                        if components:\n",
    "                            return f\"Equivalent to {' and '.join(components)}\"\n",
    "                else:\n",
    "                    return get_complex_expression_label(g, equivalent_class)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "#     if file_path.endswith('.ttl'):\n",
    "#         file_format = 'ttl'\n",
    "#     elif file_path.endswith('.owl'):\n",
    "#         file_format = 'xml'\n",
    "#     elif file_path.endswith('.xrdf'):\n",
    "#         file_format = 'xml'\n",
    "#     else:\n",
    "#         raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "    \n",
    "#     g.parse(file_path, format=file_format)\n",
    "\n",
    "#     normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "#     classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "#     data = []\n",
    "#     relations = []\n",
    "#     found_class_labels = set()\n",
    "\n",
    "#     for cls in classes:\n",
    "#         if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "#             labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "#             description = get_class_descriptions(g, cls)\n",
    "\n",
    "#             for label in labels:\n",
    "#                 if label is not None:\n",
    "#                     normalized_label = normalize_string(label)\n",
    "#                     found_class_labels.add(normalized_label)\n",
    "\n",
    "#                     if normalized_label in normalized_class_names_to_check:\n",
    "#                         # Check if already processed in this iteration\n",
    "#                         if str(cls) not in processed_classes:\n",
    "#                             processed_classes.add(str(cls))\n",
    "#                             data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "#                         for obj in g.objects(cls, RDFS.subClassOf):\n",
    "#                             if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "#                                 obj_label = get_class_label(g, obj)\n",
    "#                                 obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "#                                 # Check if already processed in this iteration\n",
    "#                                 if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "#                                     processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "#                                     relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "#                         for obj in g.objects(cls, OWL.equivalentClass):\n",
    "#                             if isinstance(obj, URIRef):\n",
    "#                                 obj_label = get_class_label(g, obj)\n",
    "#                                 obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "#                                 # Check if already processed in this iteration\n",
    "#                                 if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "#                                     processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "#                                     relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "#                             else:\n",
    "#                                 # Handle blank nodes for equivalentClass\n",
    "#                                 obj_label = get_complex_expression_label(g, obj)\n",
    "#                                 obj_description = \"Complex class expression\"\n",
    "\n",
    "#                                 if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "#                                     processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "#                                     relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "#                         for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "#                             if isinstance(obj, URIRef):\n",
    "#                                 obj_label = get_class_label(g, obj)\n",
    "#                                 obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "#                                 # Check if already processed in this iteration\n",
    "#                                 if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "#                                     processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "#                                     relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "#             # Check for owl:intersectionOf\n",
    "#             intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "#             for intersection in intersections:\n",
    "#                 if isinstance(intersection, BNode):\n",
    "#                     components = []\n",
    "#                     for item in g.items(intersection):\n",
    "#                         if isinstance(item, URIRef):\n",
    "#                             component_label = get_class_label(g, item)\n",
    "#                             if component_label:\n",
    "#                                 components.append(component_label)\n",
    "#                         elif isinstance(item, BNode):\n",
    "#                             restriction_labels = []\n",
    "#                             for restriction_item in g.items(item):\n",
    "#                                 if isinstance(restriction_item, BNode):\n",
    "#                                     restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "#                                     if restriction_label:\n",
    "#                                         restriction_labels.append(restriction_label)\n",
    "#                             if restriction_labels:\n",
    "#                                 components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                    \n",
    "#                     if components:\n",
    "#                         data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])\n",
    "\n",
    "#     return data, relations, found_class_labels\n",
    "\n",
    "\n",
    "def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "    if file_path.endswith('.ttl'):\n",
    "        file_format = 'ttl'\n",
    "    elif file_path.endswith('.owl'):\n",
    "        file_format = 'xml'\n",
    "    elif file_path.endswith('.xrdf'):\n",
    "        file_format = 'xml'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "    \n",
    "    g.parse(file_path, format=file_format)\n",
    "\n",
    "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "    data = []\n",
    "    relations = []\n",
    "    found_class_labels = set()\n",
    "\n",
    "    for cls in classes:\n",
    "        if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "            labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "            description = get_class_descriptions(g, cls)\n",
    "\n",
    "            for label in labels:\n",
    "                if label is not None:\n",
    "                    normalized_label = normalize_string(label)\n",
    "                    found_class_labels.add(normalized_label)\n",
    "\n",
    "                    if normalized_label in normalized_class_names_to_check:\n",
    "                        # Check if already processed in this iteration\n",
    "                        if str(cls) not in processed_classes:\n",
    "                            processed_classes.add(str(cls))\n",
    "                            data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, RDFS.subClassOf):\n",
    "                            if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, OWL.equivalentClass):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                                    # Handle owl:intersectionOf\n",
    "                                    intersections = list(g.objects(obj, OWL.intersectionOf))\n",
    "                                    if intersections:\n",
    "                                        components = []\n",
    "                                        for intersection in g.items(intersections[0]):\n",
    "                                            if isinstance(intersection, URIRef):\n",
    "                                                component_label = get_class_label(g, intersection)\n",
    "                                                if component_label:\n",
    "                                                    components.append(component_label)\n",
    "                                            elif isinstance(intersection, BNode):\n",
    "                                                restriction_labels = []\n",
    "                                                for restriction_item in g.items(intersection):\n",
    "                                                    if isinstance(restriction_item, BNode):\n",
    "                                                        restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                        if restriction_label:\n",
    "                                                            restriction_labels.append(restriction_label)\n",
    "                                                if restriction_labels:\n",
    "                                                    components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "\n",
    "                                        if components:\n",
    "                                            data.append([file_path, str(cls), \"\", f\"Equivalent to {' and '.join(components)}\"])\n",
    "\n",
    "                            else:\n",
    "                                # Handle blank nodes for equivalentClass\n",
    "                                obj_label = get_complex_expression_label(g, obj)\n",
    "                                obj_description = \"Complex class expression\"\n",
    "\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                                    # Handle owl:intersectionOf\n",
    "                                    intersections = list(g.objects(obj, OWL.intersectionOf))\n",
    "                                    if intersections:\n",
    "                                        components = []\n",
    "                                        for intersection in g.items(intersections[0]):\n",
    "                                            if isinstance(intersection, URIRef):\n",
    "                                                component_label = get_class_label(g, intersection)\n",
    "                                                if component_label:\n",
    "                                                    components.append(component_label)\n",
    "                                            elif isinstance(intersection, BNode):\n",
    "                                                restriction_labels = []\n",
    "                                                for restriction_item in g.items(intersection):\n",
    "                                                    if isinstance(restriction_item, BNode):\n",
    "                                                        restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                        if restriction_label:\n",
    "                                                            restriction_labels.append(restriction_label)\n",
    "                                                if restriction_labels:\n",
    "                                                    components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "\n",
    "                                        if components:\n",
    "                                            data.append([file_path, str(cls), \"\", f\"Equivalent to {' and '.join(components)}\"])\n",
    "\n",
    "                        for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "    return data, relations, found_class_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_relations(all_relations, initial_class_names_to_check):\n",
    "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hierarchy(class_name, relations, g, writer):\n",
    "    def recursive_print(class_name, depth=0):\n",
    "        for relation in relations:\n",
    "            if normalize_string(relation[2]) == normalize_string(class_name):\n",
    "                subject_description = get_class_descriptions(g, URIRef(relation[1]))\n",
    "                object_description = get_class_descriptions(g, URIRef(relation[4]))\n",
    "                writer.writerow([relation[1], relation[2], subject_description if subject_description is not None else \"\", relation[3], relation[4], relation[5], object_description if object_description is not None else \"\", relation[0]])\n",
    "                indent = '  ' * depth\n",
    "                print(f\"{indent}{relation[1]} {relation[2]} is {relation[3]} {relation[4]} {relation[5]} (from {relation[0]})\")\n",
    "                recursive_print(relation[5], depth + 1)\n",
    "\n",
    "    recursive_print(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "class_output_file = \"ontology_classes.csv\"\n",
    "relations_output_file = \"ontology_relations.csv\"\n",
    "\n",
    "all_data = []\n",
    "all_relations = []\n",
    "all_found_class_labels = set()\n",
    "\n",
    "class_names_to_check = initial_class_names_to_check\n",
    "\n",
    "max_iterations = 2\n",
    "iteration_count = 0\n",
    "g = Graph()\n",
    "processed_classes = set()\n",
    "processed_relations = set()\n",
    "last_class_name_written = None  # Track the last class name written"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "while class_names_to_check and iteration_count < max_iterations:\n",
    "    iteration_count += 1\n",
    "    new_data = []\n",
    "    new_relations = []\n",
    "    new_found_class_labels = set()\n",
    "\n",
    "    for ontology_file in ontology_files:\n",
    "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check, g, processed_classes, processed_relations)\n",
    "        new_data.extend(file_data)\n",
    "        new_relations.extend(file_relations)\n",
    "        new_found_class_labels.update(found_class_labels)\n",
    "\n",
    "    all_data.extend(new_data)\n",
    "    all_relations.extend(new_relations)\n",
    "    all_found_class_labels.update(new_found_class_labels)\n",
    "\n",
    "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
    "\n",
    "    # Filter and save class data\n",
    "    filtered_data = [row for row in new_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
    "    with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_data:\n",
    "            current_class_name = filtered_data[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_data)\n",
    "\n",
    "    # Filter and save class relations\n",
    "    filtered_relations = filter_relations(new_relations, initial_class_names_to_check)\n",
    "    with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_relations:\n",
    "            current_class_name = filtered_relations[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered class data has been saved to ontology_classes.csv\n",
      "Filtered class relations have been saved to ontology_relations.csv\n",
      "\n",
      "Initial class names found in the output:\n",
      "Class 'function' found in:\n",
      "- ../Ontologies/materialsmine_converted.ttl\n",
      "- ../Ontologies/pmdco_core.ttl\n",
      "- ../Ontologies/nfdicore_2.ttl\n",
      "- ../Ontologies/fabio.ttl\n",
      "\n",
      "Saving class hierarchy to CSV file:\n",
      "http://semanticscience.org/resource/Function function is subClassOf http://semanticscience.org/resource/Capability capability (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://semanticscience.org/resource/Capability capability is subClassOf http://semanticscience.org/resource/RealizableEntity realizable entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/RealizableEntity realizable entity is subClassOf http://semanticscience.org/resource/Attribute attribute (from ../Ontologies/materialsmine_converted.ttl)\n",
      "      http://semanticscience.org/resource/Attribute attribute is subClassOf http://semanticscience.org/resource/Entity entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "        http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "Class hierarchy has been saved to class_hierarchy.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
    "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
    "\n",
    "print(\"\\nInitial class names found in the output:\")\n",
    "for class_name in initial_class_names_to_check:\n",
    "    normalized_class_name = normalize_string(class_name)\n",
    "    found = False\n",
    "    for label in all_found_class_labels:\n",
    "        if normalized_class_name in label:\n",
    "            found = True\n",
    "            print(f\"Class '{class_name}' found in:\")\n",
    "            for ontology_file in ontology_files:\n",
    "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check, g, processed_classes, processed_relations)\n",
    "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
    "                if normalized_class_name in normalized_labels:\n",
    "                    print(f\"- {ontology_file}\")\n",
    "            break\n",
    "    if not found:\n",
    "        print(f\"Class '{class_name}' not found in the output.\")\n",
    "\n",
    "print(\"\\nSaving class hierarchy to CSV file:\")\n",
    "with open(output_hierarchy_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Class URI\", \"Class Name\", \"Class Description\", \"Relation Type\", \"Related Class URI\", \"Related Class Name\", \"Related Class Description\", \"File\"])\n",
    "    for class_name in initial_class_names_to_check:\n",
    "        normalized_class_name = normalize_string(class_name)\n",
    "        print_hierarchy(normalized_class_name, all_relations, g, writer)\n",
    "\n",
    "print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n",
    "\n",
    "# def save_intersection_info_to_csv(data, output_file):\n",
    "#     with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "#         for row in data:\n",
    "#             writer.writerow(row)\n",
    "\n",
    "def save_intersection_info_to_csv(data, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "        for row in data:\n",
    "            if row[3].startswith(\"Intersection of\"):\n",
    "                writer.writerow(row)\n",
    "\n",
    "\n",
    "\n",
    "# Inside your main loop where you process ontology files:\n",
    "intersection_data = [row for row in all_data if row[3].startswith(\"Intersection of\")]\n",
    "save_intersection_info_to_csv(intersection_data, \"intersection_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class names to check\n",
    "# initial_class_names_to_check = [ 'Compression','AmperePerJoule','nfdi','stress', 'Advertiser+content_Article', 'Tensiletest']\n",
    "initial_class_names_to_check = [ 'function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of ontology files to process\n",
    "ontology_files = [\n",
    "    # \"../Ontologies/materialsmine.ttl\", ### is not complete!\n",
    "    \"../Ontologies/materialsmine_converted.ttl\",\n",
    "    \"../Ontologies/pmdco_core.ttl\",\n",
    "    \"../Ontologies/nfdicore_2.ttl\",\n",
    "    # \"../Ontologies/bfo.owl\", #### using this ---->  long time to proccess!\n",
    "    # \"../Ontologies/emmo.ttl\",\n",
    "    # \"../Ontologies/owlapi.xrdf\",\n",
    "    # \"../Ontologies/schemaorg.owl\",\n",
    "    # \"../Ontologies/MaterialsMine.xrdf\",\n",
    "    # '../Ontologies/emmo.owl', ### has problem of reading file\n",
    "    # \"../Ontologies/Physical_Activity_Ontology_V2.owl\",\n",
    "    # \"../Ontologies/Physical_Activity_Ontology_V2.xrdf\",\n",
    "    # \"../Ontologies/oboe.owl\",\n",
    "    \"../Ontologies/fabio.ttl\",\n",
    "    # Add more file paths as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered class data has been saved to ontology_classes.csv\n",
      "Filtered class relations have been saved to ontology_relations.csv\n",
      "\n",
      "Initial class names found in the output:\n",
      "Class 'function' found in:\n",
      "- ../Ontologies/materialsmine_converted.ttl\n",
      "- ../Ontologies/pmdco_core.ttl\n",
      "- ../Ontologies/nfdicore_2.ttl\n",
      "- ../Ontologies/fabio.ttl\n",
      "\n",
      "Saving class hierarchy to CSV file:\n",
      "http://semanticscience.org/resource/Function function is subClassOf http://semanticscience.org/resource/Capability ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Function', 'function', 'subClassOf', 'http://semanticscience.org/resource/Capability', 'capability', 'A capability is a realizable entity whose basis lies in one or more parts or qualities and reflects possibility of an entity to behave in a specified way under certain conditions or in response to a certain stimulus (trigger).'] capability (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://semanticscience.org/resource/Capability capability is subClassOf http://semanticscience.org/resource/RealizableEntity ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Capability', 'capability', 'subClassOf', 'http://semanticscience.org/resource/RealizableEntity', 'realizable entity', 'A realizable entity is an attribute that is exhibited under some condition and is realized in some process.'] realizable entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/RealizableEntity realizable entity is subClassOf http://semanticscience.org/resource/Attribute ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/RealizableEntity', 'realizable entity', 'subClassOf', 'http://semanticscience.org/resource/Attribute', 'attribute', 'An attribute is a characteristic of some entity.'] attribute (from ../Ontologies/materialsmine_converted.ttl)\n",
      "      http://semanticscience.org/resource/Attribute attribute is subClassOf http://semanticscience.org/resource/Entity ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Attribute', 'attribute', 'subClassOf', 'http://semanticscience.org/resource/Entity', 'entity', 'Every thing is an entity.'] entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "        http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Entity', 'entity', 'subClassOf', 'http://www.w3.org/2002/07/owl#Thing', '', '']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "Class hierarchy has been saved to class_hierarchy.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace, URIRef, Literal, BNode\n",
    "\n",
    "\n",
    "directory = '.'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        os.remove(os.path.join(directory, filename))\n",
    "\n",
    "\n",
    "# Define namespaces (assuming these are already defined in your script)\n",
    "ex = Namespace(\"http://example.org/ontology/\")\n",
    "sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "materialsmine = Namespace(\"http://materialsmine.org/ns/\")\n",
    "bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "xml = Namespace(\"http://www.w3.org/XML/1998/namespace\")\n",
    "foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "isPartOf = dcterms.isPartOf\n",
    "DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "\n",
    "def normalize_string(s):\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[_\\-+\\s]+', '', s)\n",
    "    s = s.replace('...', '')\n",
    "    return s\n",
    "\n",
    "def get_class_label(g, cls):\n",
    "    labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "    return labels[0] if labels else None\n",
    "\n",
    "def get_class_descriptions(g, cls):\n",
    "    descriptions = list(g.objects(cls, DCTERMS.description)) + list(g.objects(cls, SKOS.definition)) + list(g.objects(cls, RDFS.comment))\n",
    "    return \" \".join([str(desc) for desc in descriptions if desc is not None]) if descriptions else None\n",
    "\n",
    "\n",
    "def get_complex_expression_label(g, node):\n",
    "    if (node, RDF.type, OWL.Restriction) in g:\n",
    "        prop = list(g.objects(node, OWL.onProperty))\n",
    "        val = list(g.objects(node, OWL.someValuesFrom))\n",
    "        if prop and val:\n",
    "            prop_label = get_class_label(g, prop[0])\n",
    "            val_label = get_class_label(g, val[0])\n",
    "            return f\"Restriction on {prop_label} some {val_label}\"\n",
    "    elif (node, RDF.type, OWL.Class) in g:\n",
    "        intersection = list(g.objects(node, OWL.intersectionOf))\n",
    "        if intersection:\n",
    "            components = []\n",
    "            for item in g.items(intersection[0]):\n",
    "                if isinstance(item, URIRef):\n",
    "                    component_label = get_class_label(g, item)\n",
    "                    if component_label:\n",
    "                        components.append(component_label)\n",
    "                elif isinstance(item, BNode):\n",
    "                    restriction_label = get_complex_expression_label(g, item)\n",
    "                    if restriction_label:\n",
    "                        components.append(restriction_label)\n",
    "            if components:\n",
    "                return f\"Intersection of {' and '.join(components)}\"\n",
    "    return None\n",
    "\n",
    "def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "    if file_path.endswith('.ttl'):\n",
    "        file_format = 'ttl'\n",
    "    elif file_path.endswith('.owl'):\n",
    "        file_format = 'xml'\n",
    "    elif file_path.endswith('.xrdf'):\n",
    "        file_format = 'xml'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "    \n",
    "    g.parse(file_path, format=file_format)\n",
    "\n",
    "    normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "    classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "    data = []\n",
    "    relations = []\n",
    "    found_class_labels = set()\n",
    "\n",
    "    for cls in classes:\n",
    "        if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "            labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "            description = get_class_descriptions(g, cls)\n",
    "\n",
    "            for label in labels:\n",
    "                if label is not None:\n",
    "                    normalized_label = normalize_string(label)\n",
    "                    found_class_labels.add(normalized_label)\n",
    "\n",
    "                    if normalized_label in normalized_class_names_to_check:\n",
    "                        # Check if already processed in this iteration\n",
    "                        if str(cls) not in processed_classes:\n",
    "                            processed_classes.add(str(cls))\n",
    "                            data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, RDFS.subClassOf):\n",
    "                            if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                        for obj in g.objects(cls, OWL.equivalentClass):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])                           \n",
    "                            else:\n",
    "                                # Handle blank nodes for equivalentClass\n",
    "                                obj_label = get_complex_expression_label(g, obj)\n",
    "                                obj_description = \"Complex class expression\"\n",
    "\n",
    "                                if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                    # Check for owl:intersectionOf\n",
    "                                    intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                    for intersection in intersections:\n",
    "                                        if isinstance(intersection, BNode):\n",
    "                                            components = []\n",
    "                                            for item in g.items(intersection):\n",
    "                                                if isinstance(item, URIRef):\n",
    "                                                    component_label = get_class_label(g, item)\n",
    "                                                    if component_label:\n",
    "                                                        components.append(component_label)\n",
    "                                                elif isinstance(item, BNode):\n",
    "                                                    restriction_labels = []\n",
    "                                                    for restriction_item in g.items(item):\n",
    "                                                        if isinstance(restriction_item, BNode):\n",
    "                                                            restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                            if restriction_label:\n",
    "                                                                restriction_labels.append(restriction_label)\n",
    "                                                    if restriction_labels:\n",
    "                                                        components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                            \n",
    "                                            if components:\n",
    "                                                data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])\n",
    "\n",
    "                        for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "                            if isinstance(obj, URIRef):\n",
    "                                obj_label = get_class_label(g, obj)\n",
    "                                obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                # Check if already processed in this iteration\n",
    "                                if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "                                    processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "                                    relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "            \n",
    "\n",
    "    return data, relations, found_class_labels\n",
    "\n",
    "\n",
    "def filter_relations(all_relations, initial_class_names_to_check):\n",
    "    normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
    "\n",
    "\n",
    "def print_hierarchy(class_name, relations, g, writer):\n",
    "    def recursive_print(class_name, depth=0):\n",
    "        for relation in relations:\n",
    "            if normalize_string(relation[2]) == normalize_string(class_name):\n",
    "                subject_description = get_class_descriptions(g, URIRef(relation[1]))\n",
    "                object_description = get_class_descriptions(g, URIRef(relation[4]))\n",
    "                writer.writerow([relation[1], relation[2], subject_description if subject_description is not None else \"\", relation[3], relation[4], relation[5], object_description if object_description is not None else \"\", relation[0]])\n",
    "                indent = '  ' * depth\n",
    "                print(f\"{indent}{relation[1]} {relation[2]} is {relation[3]} {relation[4]} {relation} {relation[5]} (from {relation[0]})\")\n",
    "                recursive_print(relation[5], depth + 1)\n",
    "\n",
    "    recursive_print(class_name)\n",
    "\n",
    "\n",
    "output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "class_output_file = \"ontology_classes.csv\"\n",
    "relations_output_file = \"ontology_relations.csv\"\n",
    "\n",
    "all_data = []\n",
    "all_relations = []\n",
    "all_found_class_labels = set()\n",
    "\n",
    "class_names_to_check = initial_class_names_to_check\n",
    "\n",
    "max_iterations = 2\n",
    "iteration_count = 0\n",
    "g = Graph()\n",
    "processed_classes = set()\n",
    "processed_relations = set()\n",
    "last_class_name_written = None  # Track the last class name written\n",
    "\n",
    "\n",
    "while class_names_to_check and iteration_count < max_iterations:\n",
    "    iteration_count += 1\n",
    "    new_data = []\n",
    "    new_relations = []\n",
    "    new_found_class_labels = set()\n",
    "\n",
    "    for ontology_file in ontology_files:\n",
    "        file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check, g, processed_classes, processed_relations)\n",
    "        new_data.extend(file_data)\n",
    "        new_relations.extend(file_relations)\n",
    "        new_found_class_labels.update(found_class_labels)\n",
    "\n",
    "    all_data.extend(new_data)\n",
    "    all_relations.extend(new_relations)\n",
    "    all_found_class_labels.update(new_found_class_labels)\n",
    "\n",
    "    class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
    "    class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
    "\n",
    "    # Filter and save class data\n",
    "    filtered_data = [row for row in new_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
    "    with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_data:\n",
    "            current_class_name = filtered_data[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_data)\n",
    "\n",
    "    # Filter and save class relations\n",
    "    filtered_relations = filter_relations(new_relations, initial_class_names_to_check)\n",
    "    with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if filtered_relations:\n",
    "            current_class_name = filtered_relations[0][2]  # Get the class name from the first row\n",
    "            if current_class_name != last_class_name_written:\n",
    "                # writer.writerow(['------'])  # Write separator\n",
    "                last_class_name_written = current_class_name\n",
    "        writer.writerows(filtered_relations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Filtered class data has been saved to {class_output_file}\")\n",
    "print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
    "\n",
    "print(\"\\nInitial class names found in the output:\")\n",
    "for class_name in initial_class_names_to_check:\n",
    "    normalized_class_name = normalize_string(class_name)\n",
    "    found = False\n",
    "    for label in all_found_class_labels:\n",
    "        if normalized_class_name in label:\n",
    "            found = True\n",
    "            print(f\"Class '{class_name}' found in:\")\n",
    "            for ontology_file in ontology_files:\n",
    "                file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check, g, processed_classes, processed_relations)\n",
    "                normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
    "                if normalized_class_name in normalized_labels:\n",
    "                    print(f\"- {ontology_file}\")\n",
    "            break\n",
    "    if not found:\n",
    "        print(f\"Class '{class_name}' not found in the output.\")\n",
    "\n",
    "print(\"\\nSaving class hierarchy to CSV file:\")\n",
    "with open(output_hierarchy_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Class URI\", \"Class Name\", \"Class Description\", \"Relation Type\", \"Related Class URI\", \"Related Class Name\", \"Related Class Description\", \"File\"])\n",
    "    for class_name in initial_class_names_to_check:\n",
    "        normalized_class_name = normalize_string(class_name)\n",
    "        print_hierarchy(normalized_class_name, all_relations, g, writer)\n",
    "\n",
    "print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n",
    "\n",
    "def save_intersection_info_to_csv(data, output_file):\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Inside your main loop where you process ontology files:\n",
    "intersection_data = [row for row in all_data if row[3].startswith(\"Intersection of\")]\n",
    "save_intersection_info_to_csv(intersection_data, \"intersection_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from rdflib import Graph, RDF, RDFS, OWL, SKOS, Namespace, URIRef, Literal, BNode\n",
    "\n",
    "# Define namespaces and helper functions here (same as in your original code)...\n",
    "\n",
    "def process_ontology(ontology_files, initial_class_names_to_check, output_hierarchy_file, class_output_file, relations_output_file):\n",
    "    \n",
    "\n",
    "    directory = '.'\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            os.remove(os.path.join(directory, filename))\n",
    "\n",
    "\n",
    "    # Define namespaces (assuming these are already defined in your script)\n",
    "    ex = Namespace(\"http://example.org/ontology/\")\n",
    "    sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "    skos = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "    owl = Namespace(\"http://www.w3.org/2002/07/owl#\")\n",
    "    rdfs = Namespace(\"http://www.w3.org/2000/01/rdf-schema#\")\n",
    "    materialsmine = Namespace(\"http://materialsmine.org/ns/\")\n",
    "    bibo = Namespace(\"http://purl.org/ontology/bibo/\")\n",
    "    rdf = Namespace(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\")\n",
    "    xsd = Namespace(\"http://www.w3.org/2001/XMLSchema#\")\n",
    "    xml = Namespace(\"http://www.w3.org/XML/1998/namespace\")\n",
    "    foaf = Namespace(\"http://xmlns.com/foaf/0.1/\")\n",
    "    dcterms = Namespace(\"http://purl.org/dc/terms/\")\n",
    "    isPartOf = dcterms.isPartOf\n",
    "    DCTERMS = Namespace(\"http://purl.org/dc/terms/\")\n",
    "\n",
    "    def normalize_string(s):\n",
    "        s = s.lower()\n",
    "        s = re.sub(r'[_\\-+\\s]+', '', s)\n",
    "        s = s.replace('...', '')\n",
    "        return s\n",
    "\n",
    "    def get_class_label(g, cls):\n",
    "        labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "        return labels[0] if labels else None\n",
    "\n",
    "    def get_class_descriptions(g, cls):\n",
    "        descriptions = list(g.objects(cls, DCTERMS.description)) + list(g.objects(cls, SKOS.definition)) + list(g.objects(cls, RDFS.comment))\n",
    "        return \" \".join([str(desc) for desc in descriptions if desc is not None]) if descriptions else None\n",
    "\n",
    "\n",
    "    def get_complex_expression_label(g, node):\n",
    "        if (node, RDF.type, OWL.Restriction) in g:\n",
    "            prop = list(g.objects(node, OWL.onProperty))\n",
    "            val = list(g.objects(node, OWL.someValuesFrom))\n",
    "            if prop and val:\n",
    "                prop_label = get_class_label(g, prop[0])\n",
    "                val_label = get_class_label(g, val[0])\n",
    "                return f\"Restriction on {prop_label} some {val_label}\"\n",
    "        elif (node, RDF.type, OWL.Class) in g:\n",
    "            intersection = list(g.objects(node, OWL.intersectionOf))\n",
    "            if intersection:\n",
    "                components = []\n",
    "                for item in g.items(intersection[0]):\n",
    "                    if isinstance(item, URIRef):\n",
    "                        component_label = get_class_label(g, item)\n",
    "                        if component_label:\n",
    "                            components.append(component_label)\n",
    "                    elif isinstance(item, BNode):\n",
    "                        restriction_label = get_complex_expression_label(g, item)\n",
    "                        if restriction_label:\n",
    "                            components.append(restriction_label)\n",
    "                if components:\n",
    "                    return f\"Intersection of {' and '.join(components)}\"\n",
    "        return None\n",
    "\n",
    "    def load_and_collect_classes_and_relations(file_path, class_names_to_check, g, processed_classes, processed_relations):\n",
    "        if file_path.endswith('.ttl'):\n",
    "            file_format = 'ttl'\n",
    "        elif file_path.endswith('.owl'):\n",
    "            file_format = 'xml'\n",
    "        elif file_path.endswith('.xrdf'):\n",
    "            file_format = 'xml'\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Only .ttl and .owl files are supported.\")\n",
    "        \n",
    "        g.parse(file_path, format=file_format)\n",
    "\n",
    "        normalized_class_names_to_check = {normalize_string(name) for name in class_names_to_check}\n",
    "\n",
    "        classes = set(g.subjects(RDF.type, OWL.Class)).union(g.subjects(RDF.type, RDFS.Class))\n",
    "\n",
    "        data = []\n",
    "        relations = []\n",
    "        found_class_labels = set()\n",
    "\n",
    "        for cls in classes:\n",
    "            if isinstance(cls, URIRef):  # Check if the subject is a URI\n",
    "                labels = list(g.objects(cls, SKOS.altLabel)) + list(g.objects(cls, SKOS.prefLabel)) + list(g.objects(cls, RDFS.label))\n",
    "                description = get_class_descriptions(g, cls)\n",
    "\n",
    "                for label in labels:\n",
    "                    if label is not None:\n",
    "                        normalized_label = normalize_string(label)\n",
    "                        found_class_labels.add(normalized_label)\n",
    "\n",
    "                        if normalized_label in normalized_class_names_to_check:\n",
    "                            # Check if already processed in this iteration\n",
    "                            if str(cls) not in processed_classes:\n",
    "                                processed_classes.add(str(cls))\n",
    "                                data.append([file_path, str(cls), str(label), str(description) if description is not None else \"\"])\n",
    "\n",
    "                            for obj in g.objects(cls, RDFS.subClassOf):\n",
    "                                if isinstance(obj, URIRef):  # Check if the object is a URI\n",
    "                                    obj_label = get_class_label(g, obj)\n",
    "                                    obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                    # Check if already processed in this iteration\n",
    "                                    if (str(cls), 'subClassOf', str(obj)) not in processed_relations:\n",
    "                                        processed_relations.add((str(cls), 'subClassOf', str(obj)))\n",
    "                                        relations.append([file_path, str(cls), str(label), 'subClassOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                            for obj in g.objects(cls, OWL.equivalentClass):\n",
    "                                if isinstance(obj, URIRef):\n",
    "                                    obj_label = get_class_label(g, obj)\n",
    "                                    obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                    # Check if already processed in this iteration\n",
    "                                    if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                        processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                        relations.append([file_path, str(cls), str(label), 'equivalentClass', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                        # Check for owl:intersectionOf\n",
    "                                        intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                        for intersection in intersections:\n",
    "                                            if isinstance(intersection, BNode):\n",
    "                                                components = []\n",
    "                                                for item in g.items(intersection):\n",
    "                                                    if isinstance(item, URIRef):\n",
    "                                                        component_label = get_class_label(g, item)\n",
    "                                                        if component_label:\n",
    "                                                            components.append(component_label)\n",
    "                                                    elif isinstance(item, BNode):\n",
    "                                                        restriction_labels = []\n",
    "                                                        for restriction_item in g.items(item):\n",
    "                                                            if isinstance(restriction_item, BNode):\n",
    "                                                                restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                                if restriction_label:\n",
    "                                                                    restriction_labels.append(restriction_label)\n",
    "                                                        if restriction_labels:\n",
    "                                                            components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                                \n",
    "                                                if components:\n",
    "                                                    data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])                           \n",
    "                                else:\n",
    "                                    # Handle blank nodes for equivalentClass\n",
    "                                    obj_label = get_complex_expression_label(g, obj)\n",
    "                                    obj_description = \"Complex class expression\"\n",
    "\n",
    "                                    if (str(cls), 'equivalentClass', str(obj)) not in processed_relations:\n",
    "                                        processed_relations.add((str(cls), 'equivalentClass', str(obj)))\n",
    "                                        relations.append([file_path, str(cls), str(label), 'equivalentClass', \"Complex class expression\", str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "                                        # Check for owl:intersectionOf\n",
    "                                        intersections = list(g.objects(cls, OWL.intersectionOf))\n",
    "                                        for intersection in intersections:\n",
    "                                            if isinstance(intersection, BNode):\n",
    "                                                components = []\n",
    "                                                for item in g.items(intersection):\n",
    "                                                    if isinstance(item, URIRef):\n",
    "                                                        component_label = get_class_label(g, item)\n",
    "                                                        if component_label:\n",
    "                                                            components.append(component_label)\n",
    "                                                    elif isinstance(item, BNode):\n",
    "                                                        restriction_labels = []\n",
    "                                                        for restriction_item in g.items(item):\n",
    "                                                            if isinstance(restriction_item, BNode):\n",
    "                                                                restriction_label = get_complex_expression_label(g, restriction_item)\n",
    "                                                                if restriction_label:\n",
    "                                                                    restriction_labels.append(restriction_label)\n",
    "                                                        if restriction_labels:\n",
    "                                                            components.append(\"Intersection of \" + \" and \".join(restriction_labels))\n",
    "                                                \n",
    "                                                if components:\n",
    "                                                    data.append([file_path, str(cls), \"\", f\"Intersection of {' and '.join(components)}\"])\n",
    "\n",
    "                            for obj in g.objects(cls, DCTERMS.isPartOf):\n",
    "                                if isinstance(obj, URIRef):\n",
    "                                    obj_label = get_class_label(g, obj)\n",
    "                                    obj_description = get_class_descriptions(g, obj)\n",
    "\n",
    "                                    # Check if already processed in this iteration\n",
    "                                    if (str(cls), 'isPartOf', str(obj)) not in processed_relations:\n",
    "                                        processed_relations.add((str(cls), 'isPartOf', str(obj)))\n",
    "                                        relations.append([file_path, str(cls), str(label), 'isPartOf', str(obj), str(obj_label) if obj_label is not None else \"\", str(obj_description) if obj_description is not None else \"\"])\n",
    "\n",
    "                \n",
    "\n",
    "        return data, relations, found_class_labels\n",
    "\n",
    "\n",
    "    def filter_relations(all_relations, initial_class_names_to_check):\n",
    "        normalized_initial_class_names = {normalize_string(name) for name in initial_class_names_to_check}\n",
    "        return [relation for relation in all_relations if normalize_string(relation[2]) in normalized_initial_class_names or normalize_string(relation[5]) in normalized_initial_class_names]\n",
    "\n",
    "\n",
    "    def print_hierarchy(class_name, relations, g, writer):\n",
    "        def recursive_print(class_name, depth=0):\n",
    "            for relation in relations:\n",
    "                if normalize_string(relation[2]) == normalize_string(class_name):\n",
    "                    subject_description = get_class_descriptions(g, URIRef(relation[1]))\n",
    "                    object_description = get_class_descriptions(g, URIRef(relation[4]))\n",
    "                    writer.writerow([relation[1], relation[2], subject_description if subject_description is not None else \"\", relation[3], relation[4], relation[5], object_description if object_description is not None else \"\", relation[0]])\n",
    "                    indent = '  ' * depth\n",
    "                    print(f\"{indent}{relation[1]} {relation[2]} is {relation[3]} {relation[4]} {relation} {relation[5]} (from {relation[0]})\")\n",
    "                    recursive_print(relation[5], depth + 1)\n",
    "\n",
    "        recursive_print(class_name)\n",
    "\n",
    "\n",
    "    output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "    class_output_file = \"ontology_classes.csv\"\n",
    "    relations_output_file = \"ontology_relations.csv\"\n",
    "\n",
    "    all_data = []\n",
    "    all_relations = []\n",
    "    all_found_class_labels = set()\n",
    "\n",
    "    class_names_to_check = initial_class_names_to_check\n",
    "\n",
    "    max_iterations = 10\n",
    "    iteration_count = 0\n",
    "    g = Graph()\n",
    "    processed_classes = set()\n",
    "    processed_relations = set()\n",
    "    last_class_name_written = None  # Track the last class name written\n",
    "\n",
    "\n",
    "    while class_names_to_check and iteration_count < max_iterations:\n",
    "        iteration_count += 1\n",
    "        new_data = []\n",
    "        new_relations = []\n",
    "        new_found_class_labels = set()\n",
    "\n",
    "        for ontology_file in ontology_files:\n",
    "            file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, class_names_to_check, g, processed_classes, processed_relations)\n",
    "            new_data.extend(file_data)\n",
    "            new_relations.extend(file_relations)\n",
    "            new_found_class_labels.update(found_class_labels)\n",
    "\n",
    "        all_data.extend(new_data)\n",
    "        all_relations.extend(new_relations)\n",
    "        all_found_class_labels.update(new_found_class_labels)\n",
    "\n",
    "        class_names_to_check = {str(label) for label in new_found_class_labels} - {normalize_string(name) for name in initial_class_names_to_check}\n",
    "        class_names_to_check = [normalize_string(name) for name in class_names_to_check]\n",
    "\n",
    "        # Filter and save class data\n",
    "        filtered_data = [row for row in new_data if normalize_string(row[2]) in {normalize_string(name) for name in initial_class_names_to_check}]\n",
    "        with open(class_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            if filtered_data:\n",
    "                current_class_name = filtered_data[0][2]  # Get the class name from the first row\n",
    "                if current_class_name != last_class_name_written:\n",
    "                    # writer.writerow(['------'])  # Write separator\n",
    "                    last_class_name_written = current_class_name\n",
    "            writer.writerows(filtered_data)\n",
    "\n",
    "        # Filter and save class relations\n",
    "        filtered_relations = filter_relations(new_relations, initial_class_names_to_check)\n",
    "        with open(relations_output_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            if filtered_relations:\n",
    "                current_class_name = filtered_relations[0][2]  # Get the class name from the first row\n",
    "                if current_class_name != last_class_name_written:\n",
    "                    # writer.writerow(['------'])  # Write separator\n",
    "                    last_class_name_written = current_class_name\n",
    "            writer.writerows(filtered_relations)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"Filtered class data has been saved to {class_output_file}\")\n",
    "    print(f\"Filtered class relations have been saved to {relations_output_file}\")\n",
    "\n",
    "    print(\"\\nInitial class names found in the output:\")\n",
    "    for class_name in initial_class_names_to_check:\n",
    "        normalized_class_name = normalize_string(class_name)\n",
    "        found = False\n",
    "        for label in all_found_class_labels:\n",
    "            if normalized_class_name in label:\n",
    "                found = True\n",
    "                print(f\"Class '{class_name}' found in:\")\n",
    "                for ontology_file in ontology_files:\n",
    "                    file_data, file_relations, found_class_labels = load_and_collect_classes_and_relations(ontology_file, initial_class_names_to_check, g, processed_classes, processed_relations)\n",
    "                    normalized_labels = [normalize_string(l) for l in found_class_labels]\n",
    "                    if normalized_class_name in normalized_labels:\n",
    "                        print(f\"- {ontology_file}\")\n",
    "                break\n",
    "        if not found:\n",
    "            print(f\"Class '{class_name}' not found in the output.\")\n",
    "\n",
    "    print(\"\\nSaving class hierarchy to CSV file:\")\n",
    "    with open(output_hierarchy_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Class URI\", \"Class Name\", \"Class Description\", \"Relation Type\", \"Related Class URI\", \"Related Class Name\", \"Related Class Description\", \"File\"])\n",
    "        for class_name in initial_class_names_to_check:\n",
    "            normalized_class_name = normalize_string(class_name)\n",
    "            print_hierarchy(normalized_class_name, all_relations, g, writer)\n",
    "\n",
    "    print(f\"Class hierarchy has been saved to {output_hierarchy_file}\")\n",
    "\n",
    "    def save_intersection_info_to_csv(data, output_file):\n",
    "        with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"File\", \"Class URI\", \"Class Name\", \"Intersection Description\"])\n",
    "            for row in data:\n",
    "                writer.writerow(row)\n",
    "\n",
    "    # Inside your main loop where you process ontology files:\n",
    "    intersection_data = [row for row in all_data if row[3].startswith(\"Intersection of\")]\n",
    "    save_intersection_info_to_csv(intersection_data, \"intersection_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of ontology files to process\n",
    "ontology_files = [\n",
    "    # # \"../Ontologies/materialsmine.ttl\", ### is not complete!\n",
    "    \"../Ontologies/materialsmine_converted.ttl\",\n",
    "    # \"../Ontologies/pmdco_core.ttl\",\n",
    "    # \"../Ontologies/nfdicore_2.ttl\",\n",
    "    # # # \"../Ontologies/bfo.owl\", #### using this ---->  long time to proccess!\n",
    "    # \"../Ontologies/emmo.ttl\",\n",
    "    # # # \"../Ontologies/owlapi.xrdf\",\n",
    "    # # \"../Ontologies/schemaorg.owl\",\n",
    "    # # # \"../Ontologies/MaterialsMine.xrdf\",\n",
    "    # # # '../Ontologies/emmo.owl', ### has problem of reading file\n",
    "    # # # \"../Ontologies/Physical_Activity_Ontology_V2.owl\",\n",
    "    # # # \"../Ontologies/Physical_Activity_Ontology_V2.xrdf\",\n",
    "    # # # \"../Ontologies/oboe.owl\",\n",
    "    # \"../Ontologies/fabio.ttl\",\n",
    "    # \"../Ontologies/MatWerk.xrdf\",\n",
    "    # \"../Ontologies/Materials_Data_Science.xrdf\",\n",
    "    # \"../Ontologies/Materials_Data_Science.ttl\",\n",
    "    # \"../Ontologies/ncit.owl\",\n",
    "    # Add more file paths as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of class names to check\n",
    "# initial_class_names_to_check = [ 'Compression','AmperePerJoule','nfdi','stress', 'Advertiser+content_Article', 'Tensiletest']\n",
    "initial_class_names_to_check = [ 'drug']\n",
    "\n",
    "#### Define the output files\n",
    "output_hierarchy_file = \"class_hierarchy.csv\"\n",
    "class_output_file = \"ontology_classes.csv\"\n",
    "relations_output_file = \"ontology_relations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered class data has been saved to ontology_classes.csv\n",
      "Filtered class relations have been saved to ontology_relations.csv\n",
      "\n",
      "Initial class names found in the output:\n",
      "Class 'drug' found in:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n",
      "Complex class expression does not look like a valid URI, trying to serialize this will break.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ../Ontologies/materialsmine_converted.ttl\n",
      "\n",
      "Saving class hierarchy to CSV file:\n",
      "http://semanticscience.org/resource/Drug drug is subClassOf http://semanticscience.org/resource/ChemicalSubstance ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Drug', 'drug', 'subClassOf', 'http://semanticscience.org/resource/ChemicalSubstance', 'chemical substance', 'A chemical substance is a chemical entity composed of two or more weakly (non-covalently) interacting chemical entities.'] chemical substance (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://semanticscience.org/resource/ChemicalSubstance chemical substance is subClassOf http://semanticscience.org/resource/ChemicalEntity ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/ChemicalSubstance', 'chemical substance', 'subClassOf', 'http://semanticscience.org/resource/ChemicalEntity', 'chemical entity', 'A chemical entity is a material entity that pertains to chemistry.'] chemical entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "    http://semanticscience.org/resource/ChemicalEntity chemical entity is subClassOf http://semanticscience.org/resource/MaterialEntity ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/ChemicalEntity', 'chemical entity', 'subClassOf', 'http://semanticscience.org/resource/MaterialEntity', 'Material Entity', 'A material entity is a physical entity that is spatially extended, exists as a whole at any point in time and has mass. A material entity is a physical entity that is spatially extended, exists as a whole at any point in time and has mass.'] Material Entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "      http://semanticscience.org/resource/MaterialEntity Material Entity is subClassOf http://semanticscience.org/resource/Object ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/MaterialEntity', 'Material Entity', 'subClassOf', 'http://semanticscience.org/resource/Object', 'object', 'An object is an entity that is wholly identifiable at any instant of time during which it exists.'] object (from ../Ontologies/materialsmine_converted.ttl)\n",
      "        http://semanticscience.org/resource/Object object is subClassOf http://semanticscience.org/resource/Entity ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Object', 'object', 'subClassOf', 'http://semanticscience.org/resource/Entity', 'entity', 'Every thing is an entity.'] entity (from ../Ontologies/materialsmine_converted.ttl)\n",
      "          http://semanticscience.org/resource/Entity entity is subClassOf http://www.w3.org/2002/07/owl#Thing ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/Entity', 'entity', 'subClassOf', 'http://www.w3.org/2002/07/owl#Thing', '', '']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://semanticscience.org/resource/ChemicalSubstance chemical substance is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/ChemicalSubstance', 'chemical substance', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://semanticscience.org/resource/ChemicalSubstance chemical substance is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/ChemicalSubstance', 'chemical substance', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://semanticscience.org/resource/ChemicalSubstance chemical substance is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/ChemicalSubstance', 'chemical substance', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://semanticscience.org/resource/ChemicalSubstance chemical substance is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/ChemicalSubstance', 'chemical substance', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://semanticscience.org/resource/ChemicalSubstance chemical substance is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/ChemicalSubstance', 'chemical substance', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://semanticscience.org/resource/ChemicalSubstance chemical substance is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/ChemicalSubstance', 'chemical substance', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://semanticscience.org/resource/ChemicalSubstance chemical substance is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/ChemicalSubstance', 'chemical substance', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://semanticscience.org/resource/ChemicalSubstance chemical substance is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/ChemicalSubstance', 'chemical substance', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://semanticscience.org/resource/ChemicalSubstance chemical substance is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/ChemicalSubstance', 'chemical substance', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "  http://semanticscience.org/resource/ChemicalSubstance chemical substance is equivalentClass Complex class expression ['../Ontologies/materialsmine_converted.ttl', 'http://semanticscience.org/resource/ChemicalSubstance', 'chemical substance', 'equivalentClass', 'Complex class expression', '', 'Complex class expression']  (from ../Ontologies/materialsmine_converted.ttl)\n",
      "Class hierarchy has been saved to class_hierarchy.csv\n"
     ]
    }
   ],
   "source": [
    "process_ontology(ontology_files, initial_class_names_to_check, output_hierarchy_file, class_output_file, relations_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
